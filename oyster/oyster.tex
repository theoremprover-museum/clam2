
% begin ProTex

% @(#)$Id: oyster.pl,v 1.33 2008/05/22 16:55:16 smaill Exp $
% 
% $Log: oyster.pl,v $
% Revision 1.33  2008/05/22 16:55:16  smaill
% move tab code to oyster
%
% Revision 1.32  2008/05/21 14:14:15  smaill
% update for sicstus4
%
% Revision 1.31  2005/05/09 17:59:01  smaill
% Double comment symbols needed for commented out code;
% some formatting changes.
%
% Revision 1.30  2005/04/26 14:03:24  smaill
% *** empty log message ***
%
% Revision 1.29  2005/02/18 21:49:30  smaill
% revise to work under linux and sicstus 3.10
%
% Revision 1.28  2002/07/16 13:53:39  smaill
% Update for latex2e,
% tidy operator declarations etc.
%
% Revision 1.27  2000/01/07 18:42:17  smaill
% fix makefile for documentation
%
% Revision 1.26  1999/02/02 09:59:26  img
% change to mark/1 so that copy/1 doesnt kill proof on failure
%
% Revision 1.25  1998/08/27 07:19:05  img
% unify/2: cases for ground terms
%
% Revision 1.24  1998/06/25 11:29:24  img
% version no
%
% Revision 1.23  1998/06/25 11:27:02  img
% unify/2 added; bug in writeclause fixed
%
% Revision 1.22  1998/03/04 14:30:26  img
% *** empty log message ***
%
% Revision 1.21  1997/11/12 16:52:04  img
% sorted out autoloading
%
% Revision 1.20  1997/06/27 12:59:04  dream
% Prevent backtracking in writep/2.
%
% Revision 1.19  1997/06/10 10:53:11  dream
% revision number updated
%
% Revision 1.18  1997/06/10 10:51:24  dream
% cdef interface awkward for atomic definitions
%
% Revision 1.17  1997/06/09 16:40:35  dream
% bindings updated; fail on illegal syntax in definitions
%
% Revision 1.16  1997/01/14 09:56:01  dream
% Typo in # intro rule
%
% Revision 1.15  1996/12/06 14:58:47  img
% Typo (from before computers were invented).
%
% Revision 1.14  1996/11/30 10:27:18  img
% substituted/5: explicit occurs check (eg s(a=b in c,S,[m,x],A=A in C)
% succeeded).  rewrite/2: allow extraction from incomplete proofs for
% rewriting.
%
% Revision 1.13  1996/10/14 15:34:36  dream
% Typos in quotient elimination rule (spotted by Smaill).
%
% Revision 1.12  1996/07/05  10:37:37  dream
% valeries removed
%
% Revision 1.11  1996/07/05  10:15:49  dream
% Reintroduced rules for arithmetic.
%
% Revision 1.10  1996/07/02  12:15:05  img
% version 1.10
%
% Revision 1.9  1996/07/02 12:13:25  img
% Yet more bugs; spotted by Jason.  Problems remain in s/4.
%
% Revision 1.8  1995/12/22 16:28:48  img
% typos/ommissions
%
% Revision 1.7  1995/11/25  13:31:43  dream
% added oyster_version/1.  general tidying up for the manual
% 
% Revision 1.6  1995/11/12  13:58:32  smaill
% Add clause to deal with folding of defs with {def} syntax.
% 
% Revision 1.5  1995/10/30  12:53:07  img
% syntax check on problem files
% 
% Revision 1.4  1995/08/23  15:22:50  img
% make autoloading less enthusiastic
% 
% Revision 1.3  1995/08/23  15:06:42  img
% added simple autoloading mechanism
% 
% Revision 1.2  1995/07/18  10:08:45  dream
% freevarinterm/1: case for rec type missing;  added op for <=>
% 
% Revision 1.1  1994/10/26  18:39:29  smaill
% Initial revision
 \documentclass[11pt]{report}
 \usepackage{a4-9,fancyheadings,amsmath,latexsym}
 \usepackage{makeidx}
 \addtolength{\headheight}{2pt}
 \makeindex 
 \setcounter{tocdepth}{1}
 
 % Macros for creating index:
 \newcommand{\bs}{\symbol{'134}}
 \newcommand{\inv}[1]{\index{#1}}
 \newcommand{\ulinv}[1]{\index{#1@\texttt{#1}}}
 \newcommand{\bfinv}[1]{\index{#1@\textbf{#1}}}
 \newcommand{\bfulinv}[1]{\index{#1@\ul{\textbf{#1}}}}
 
 \title{{\huge The Oyster\\ Proof Development System}}
 \author{Christian Horn}
 
 \begin{document}
 \maketitle
 \begin{abstract}
 This report describes a logical system called Oyster, based on
 intuitionistic type theory, and a prototype implementation
 \footnote{The prototype implementation is jointly distributed by
 the University of Edinburgh and the Humboldt-University at Berlin} 
 in the form of a logic programming system. Oyster is a synthesis of
 the ideas of constructive logic, {\sc Martin L\"{o}f} type theory,
 {\sc Constable's} refinement logic and logic programming. It is
 a rational reconstruction of the Nuprl (pronounced ``nu-pearl'')
 system built at Cornell.
 This document presents the system exactly in its internal form,
 i.e. it \emph{is} the formatted source code itself. Although
 this implies some difficulties in the presentation of the
 material, it has the important advantage, that there is no difference
 between the logic documented and the logic implemented.
 In fact this document is not only a reference manual, but the
 precise and executable formal specification of a logical system:
 perhaps one step towards increasing the reliability of theorem
 proving and, more generally, of reasoning systems.
 \ulinv{info}
\begin{sf}\begin{tabbing}
\hspace{4em}oyster\_\hspace{0.1em}version('\$Id: oyster.pl,v 1.33 2008/05/22 16:55:16 smaill Exp \$').\\[-0.15ex]
\hspace{4em}info :- oyster\_\hspace{0.1em}version(X),\\[-0.15ex]
\hspace{8em}write('Oyster release '),\\[-0.15ex]
\hspace{8em}write(X),nl.\\[-0.7ex]

\end{tabbing}\end{sf}

 \vfill
 \begin{center} \copyright 1988 Christian Horn \end{center}
 \end{abstract}
  
  
 \begin{tabbing}\\[5ex]{\Large Acknowledgements}\\\end{tabbing}
  
 This research was carried out during a visit of the author 
 at the \emph{Department of Artificial Intelligence} of the
 \emph{University of Edinburgh}. This work was financially supported
 by a grant from \emph{The British Council}. 
 It was the influence of \emph{Alan Bundy}, who led me to the ideas
 of intuitionistic type theory, and the fascinating ideas
 floating around in his \emph{Mathematical Reasoning Group}, 
 which encouraged me to do this work.
 Thanks to all those who gave their time to discuss the ideas,
 to read various drafts of this papers and to fix up a lot of
 bugs in the implementation, in particular to Frank van Harmelen,
 Alan Smaill and Andrew Stevens.  
 Thanks go to my former
 home institution, the \emph{Department of Mathematics} of the
 \emph{Humboldt-University at Berlin}, in particular to those who 
 have made this visit possible.
  
 \vspace{30ex}
 \newpage
 \pagestyle{fancy}
 \pagenumbering{roman}
 \tableofcontents
  
 \chapter{Introduction}
 \pagenumbering{arabic}
 \section{The Oyster System}
   
 Oyster is an \emph{Interactive Proof Editor} for goal directed
 backward chaining proofs. It is not an automatic theorem proving
 system. As a \emph{programming environment} it 
 combines a \emph{structure editor} with a \emph{verification condition
 generator}, but it is neither a program synthesiser nor an automatic
 program verification system. Oyster is a \emph{framework} for
 developing application oriented intelligent systems, which integrate
 facilities for creating new theories, proving theorems, synthesising
 and running programs. Oyster provides the kernel functions needed
 for such systems and a meta language, which supports the 
 development of higher level strategies for theorem proving 
 as well as for program synthesis. 
  
 The main idea behind the Oyster development was that by using an 
 appropriate \emph{metalanguage} it should be possible 
 to reformulate the current knowledge about
 theorem proving and program synthesis, in the hope of 
 discovering more general principles.
 Oyster uses \emph{Edinburgh Prolog} as a meta language, because
 it is a well-known, modern, expressive, and widely used language,
 which is especially suited for this purpose because of its
 unification and backtracking mechanism.
 Prolog is suitable as a command language as well as a language
 for implementing a specialised user interface.
 There already exist a large number of AI systems, written in
 Prolog, which could be used directly for applying heuristics and 
 learning on the level of the meta theory.
  
 Oyster provides a set of built-in interface predicates 
 for basic operations on the proof tree including the application
 of a single inference step. First experiments with Oyster
 have shown that already these simple operations along with with the 
 possibility of stringing them together into new commands using the
 Prolog mechanisms of unification and backtracking forms a
 very powerful command language. The extent of the 
 full expressiveness of this command language is one open research
 topic. In this document we have included only some small examples
 of the use of Prolog as a meta level language, to give the reader
 at least a feeling for the potentials of this approach.
 Appendix A summarises the built-in predicates, which support the
 use of Prolog as a meta-language.
  
 Type theoretic terms are represented as Prolog expressions
 using the built in operator declarations of Prolog. This
 allows us to apply the Prolog unification mechanisms directly
 to type theoretic terms. There are special built-in predicates
 providing substitution and higher order unification on 
 type theoretic terms. 
  
 In any stage of the proof development process it is possible
 to access the \emph{extract term} of the proof constructed
 so far. Open subgoals of the proof, insofar as they have any
 constructive significance and are not only wellformedness goals,
 correspond to Prolog variables in the extract term.
  
 There is a built-in evaluator for type theoretic terms,
 which allows the direct execution of Oyster programs. 
 This evaluator is a two place Prolog predicate, which may be used
 as part of a control predicate. This opens the possibility
 of using the extract term of meta level theorems directly      
 for controlling object level reasoning processes. 
 With further development of the Oyster language 
 it could become possible to replace Prolog as a control and meta 
 language by Oyster itself. If we have reached this point,
 then we are near to the next generation of programming languages
 and systems.
  
 
 \section{The User Interface}
 
 The implementation of the Oyster system could be considered as an 
 extension of Prolog by an \emph{abstract data type},
 providing some low level interface predicates for building
 more advanced programming and theorem proving environments.
 We use an operational specification for this abstract data type 
 in terms of a ``fictive'' two layer Prolog implementation, which is
 not directly accessible to the user. The basic layer describes 
 the internal representation of the proof tree and elementary
 operations on the proof tree (like positioning,
 assignment and extraction operations of subtrees).
 In section 2.2 we give a Prolog definition of these basic operations,
 but they should be considered as an implementation modell
 only. The second layer consists of the interface predicates
 described throughout this chapter and the rule base given in 
 the next chapter. The interface predicates are given in 
 terms of an operational specification using Prolog extended by
 the elementary operations of the first layer.
 
 \section{Representing Theorems}
 
 This section describes the representation of theorems and 
 type theoretic terms in Prolog by means
 of operator declarations and summarises the implications of
 this approach for the user. The main structure of the terms
 is identical with the representation in the Nuprl system,
 however there are some small differences mostly related to
 the use of Prolog as implementation language. For the interpretation
 of the terms, please refer to the next chapter (\emph{Rule Base}).
 The aim of this section is only to give an overview and a
 summary of the syntax.  The predicate $syntax(H,X)$ is used
 to check whether or not $X$ is a type theoretic term under the
 assumption of the declarations and definitions in $H$.
 \begin{itemize}
 \item
 Theorems are terms of the form $H ==> G$,
 where $H$ is a possibly empty
 (Prolog) list of hypotheses $H_{i}$ and  $G$ is the goal to be proven.
 Hypotheses are \emph{definitions}, references to other \emph{theorems},
 or \emph{assumptions}.
 \item
 \emph{Definitions} have the form $d(x,y,...) <==> t_{x,y,...}$,
 where $d$ is an arbitrary identifier,  $x,y,...$ form a
 possibly empty parameter list and $t_{x,y,...}$ is any type
 theoretic term with free variables $x,y,...$.
 Definitions can also be defined globally using the $create\_def$ 
 \ulinv{create\_def} predicate.   The following example illustrate
 its use:
 \begin{small}\begin{verbatim}
    | ?- create_def( user ).
    |: plus(x,y) <==> x+y.
 
    yes
 \end{verbatim}\end{small}
 
 Calling $save\_def( Name, Filename )$ will save the defined term $Name:  $
 into the UNIX file $Filename$.
 The current defs can be determined by backtracking with 
 $current\_def(X)$, and the def $Name:  $ erased with $erase\_def(Name)$.
 \item
 References to \emph{theorems} have the form 
 $v:H$$==>$$G$ or $v:H$$==>$$G\; \mbox{\it ext} \; E$ , where
 $H$ and $G$ are a list of hypothesis and the goal of the
 theorem again, and $E$ is the extract term derived from that
 proof. The theorem name $v$ is used only locally, but should reflect
 the common interpretation of the theorem.
 These theorem references have been introduced to document the
 relations between theorems. 
 They depict the fact that the proof of the current theorem 
 refers only to the theorems mentioned in the hypothesis list;
 and it may refer either only to the fact that these theorems are
 valid or it may refer to the proof construction of these theorems too.
 A library system on top of the current Oyster system has
 to prevent circular reasoning over theorems.
 \item
 \emph{Assumptions} are of the form 
 $v:T_i$ stating that the type $T_i$
 is inhabited by the element $v$, which may be read as:"$v$ is 
 declared to be of the type $T_i$" (and in so far it is guaranteed
 that $T_i$ is inhabited at least by $v$) or "$v$ is the name of an
 assumption represented by $T_i$" (and $v$ is a symbolic name for
 a proof of $T_i$). 
 \item
 The goal $G$ is an arbitrary type, i.e. a type
 theoretic term belonging to some
 universe. The aim of the proof is to show, that $G$ is inhabited,
 by explicitely constructing a member. This construction process
 might be characterized as stepwise refinement proof yielding
 the extract term $E$, which is guaranteed to be a member of $G$.
 \item
 Type theoretic variables are written as sequences of
 letters and digits and underscores, starting with a small letter.
 If necessary variables are modified by adding underscores.
 Completely new variables are generated from the sequence 
 $v0, v1, v2,...\;$. Although the system keeps track of the
 variables used so far, you should generally avoid these variables
 to prevent confusion.
 \item
 Universes are written in the form  $u(i)$, where i is a
 positive integer.
 The basic types \emph{atom, void, pnat} and \emph{int} are
 written as they are.
 \item
 Atoms ``\dots'' are written as Prolog terms of the form 
 \hbox{$atom('...')$}, to avoid ambiguities between
 type theoretic atoms and other constructs represented by
 Prolog atoms. The test of equality of atoms is a basic
 operation, therefore there is a decision operator for atoms 
 in the form \hbox{$atom\_eq(a,b,s,t)$}.
 \item
 There is one impossibility operator of the form \emph{any(x)}
 which maps a proof of a contradiction into any type.
 \item
 The type $pnat$ represents the natural numbers with Peano
 arithmetic. The elements of $pnat$ have the form $0$ or $s(...)$,
 where $s(...)$ is the \emph{successor} function on natural numbers.
 Inductive definition terms have the form $p\_ind(a,b,[x,y,t])$.
 The decision operators have the form
 $pnat\_eq(a,b,s,t)$ , $pless(a,b,s,t)$.
 \item
 Integers are encoded as ordinary integer numbers in Prolog.
 The integer operations $-a$, $a+b$, $a-b$, $a*b$, $a/b$, and
 $a\; mod\; b$
 as well as the ordering relation $a<b$ and $a<=b$ are written 
 as usual.
 The decision operators have the form
 $int\_eq(a,b,s,t)$ , $less(a,b,s,t)$.
 Inductive definition terms have the form $ind(a,[x,y,s],b,[u,v,t])$.
 \item
 List types have the form \emph{A list}, where $A$ is the
 base type. The empty list 
 has the form $nil$ and the usual list construction operation 
 is written in the form $a::b$, with $a$ being an element of $A$ 
 and $b$ being an element of the list type.
 List induction terms have the 
 form \hbox{$list\_ind(a,s,[x,y,z,t])$}.
 \item
 Disjoint union types are written in the form 
 \emph{A$\backslash$B}, where $A$ and $B$ are arbitrary types.
 The injection operators have the form \emph{inl(a)} 
 and \emph{inr(b)}, with $a$ and $b$ being terms of the type $A$ or
 $B$ respectively. The general decision operator has the form
 \hbox{$decide(u,[x,s],[y,t])$}.
 \item
 The product types have the form \emph{A\#B} or \emph{x:A\#B},
 with $A$ and $B$ being types and $x$ being a free variable in $B$,
 which becomes bound in the product type.
 Their elements are pairs of the form $a\&b$, where $a$ and $b$ are
 arbitrary terms of type $A$ and $B$ respectively, and the 
 generalised projection operator is written
 in the form \emph{spread(a,[x,y,t])}.
 \item
 The function types $A \rightarrow B$ and $x:A\rightarrow B$ have
 the form $A=>B$ and $x:A=>B$;
 $\lambda$-terms have to be written in the form $lambda(x,b)$,
 where $b$ is an arbitrary term of the type $B$ and $x$ is a
 free variable in $B$ which is assumed to vary over $A$. $x$ 
 becomes bound in the $\lambda$-term.
 Function application terms have the form $f\; of\; a$, where
 $f$ is an arbitrary term (member) of a function type and 
 $a$ is a term of the domain type of that function type.
 \item
 Quotient types have the form \hbox{$A///[x,y,E]$}, where $A$ is the
 basic type and $E$ is an equivalence relation in the free variables
 $x$ and $y$, which become bound in the quotient type. The equivalence
 classes are written in the form $\{x\}$ for arbitrary $x$ in $A$.
 \item
 Set types are written in the form $\{x:A\backslash B\}$, where
 $A$ is the base type and $B$ is a type with the free variable $x$
 defining the characteristic property of the set. $x$ becomes bound
 in the set term.
 \item
 Recursive types have the form $rec(z,A\backslash B)$ 
 where $A$ and $B$ are types and 
 $z$ is a free variable in $B$, which does not appear in $A$.
 Type induction terms are written in the form
 \hbox{$rec\_ind(r,[h,i,t])$}.
 \item
 Equalities and membership relations have the form \emph{a=b in t} and 
 \emph{a in t}, respectively.
 Multiterm equalities are not allowed.
 \item
 The \emph{extract term} of a theorem, reflecting the algorithmic ideas
 behind the proof of that theorem, is written in the form
 $term\_of(t)$ where $t$ is the name of a theorem referred to.
 All theorems used have to be declared in the hypothesis 
 list of the top level goal. If you make proper use of the form
 of the extract term (for example by rewriting or evaluating the
 extract term), ensure that the reference in the hypothesis list
 really contains the extract term.
 \end{itemize}
 The priority and associativity of the operators is best described
 by their Prolog declarations.
  
 \inv{operator declarations}
 \ulinv{ext} \inv{$==>$} \inv{$<==>$} \inv{$:$} \inv{$=>$}
 \inv{$\#$} \ulinv{\bs} \inv{$///$} \inv{$\leadsto$}
 \inv{$in$} \inv{$=$} \inv{$<$} \inv{$<=$} \inv{$+$}
 \inv{$-$}  \inv{$*$} \inv{$/$} \ulinv{mod}
 \inv{$\&$} \inv{$::$} \ulinv{of} \ulinv{list}
\begin{sf}\begin{tabbing}
?-\\[-0.15ex]
\hspace{1em}op(950,xfx,[ext]),\\[-0.15ex]
\hspace{1em}op(900,fx, [==$>$]),\\[-0.15ex]
\hspace{1em}op(900,xfx,[==$>$, $<$==$>$]),\\[-0.15ex]
\hspace{1em}op(850,xfy,[$<$=$>$]),\\[-0.15ex]
\hspace{1em}op(850,xfy,[:, =$>$, \#, $\backslash$, ///]),\\[-0.15ex]
\hspace{1em}op(700,yfx,[in, =, $<$, $<$*]),\\[-0.15ex]
\hspace{1em}op(500,yfx,[+, -]),\\[-0.15ex]
\hspace{1em}op(500,fx, [-]),\\[-0.15ex]
\hspace{1em}op(400,yfx,[*, /, mod]),\\[-0.15ex]
\hspace{1em}op(300,xfy,[\&, ::]),\\[-0.15ex]
\hspace{1em}op(250,yfx,[of]),\\[-0.15ex]
\hspace{1em}op(200,xf, [list]).
\end{tabbing}\end{sf}

 
 \section{Representing Proof Trees}
 
 The Oyster systems works internally with an explicit representation
 of (partial) proof trees in form of Prolog terms $\pi(H==>G,R,E,S)$ 
 which are for each theorem $t$ assigned to the global variable 
 $\vartheta_{theorem}(t)$.\footnote
 {The use of global variables, although not typical for
 Prolog, is essential for this
 implementation. Thats why we have introduced the 
 shorthand notations ':=' for assignment and '=:' for dereferencing
 of variable values. As a result of this global storage strategy, it 
 sometimes happens that the database gets cluttered with intermediate 
 datastructures. The predicate $cleandatabase$ removes all these intermediate
 datastructures. Obviously, this predicate should {\bf never} be called 
 inside a proof, but only at top-level, to repair damage after things have 
 gone wrong
 \inv{operator declarations} 
\begin{sf}\begin{tabbing}
?-op(900,xfx,[':=','=:']).\\[-0.7ex]
\\[-0.15ex]
?-dynamic dynvalue/2.\\[-0.7ex]

\end{tabbing}\end{sf}

 Autoloading of unknown syntax via the Clam library mechanism
\begin{sf}\begin{tabbing}
?-dynamic autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass/1, autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass2/1, autoloading\_\hspace{0.1em}def/1.\\[-0.15ex]
autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass(no).\\[-0.15ex]
autoload\_\hspace{0.1em}defs(yes) :-\\[-0.15ex]
\hspace{2em}retractall(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass(\_\hspace{0.1em})),\\[-0.15ex]
\hspace{2em}assert(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass(yes)).\\[-0.15ex]
autoload\_\hspace{0.1em}defs(no) :-\\[-0.15ex]
\hspace{2em}retractall(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass(\_\hspace{0.1em})),\\[-0.15ex]
\hspace{2em}assert(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass(no)).\\[-0.15ex]
autoload\_\hspace{0.1em}defs(\_\hspace{0.1em}) :-\\[-0.15ex]
\hspace{2em}write('Please use autoload\_\hspace{0.1em}defs(yes) or autoload\_\hspace{0.1em}defs(no)'),nl,\\[-0.15ex]
\hspace{2em}write('Currently, autoloading is set to '),\\[-0.15ex]
\hspace{2em}autoload\_\hspace{0.1em}defs(S),\\[-0.15ex]
\hspace{2em}write(S),nl.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{:=} \ulinv{=:} \ulinv{dynvalue}
\begin{sf}\begin{tabbing}
$\vartheta_{\it theorem}$(N) := \_\hspace{0.1em} :-\\[-0.15ex]
\hspace{2em}recorded(N,$\vartheta_{\it theorem}$(N,\_\hspace{0.1em}),R),erase(R),\\[-0.15ex]
\hspace{2em}recorded(ctheorem,N,RR),erase(RR),\\[-0.15ex]
\hspace{2em}fail.\\[-0.15ex]
$\vartheta_{\it theorem}$(N) := V :- \\[-0.15ex]
\hspace{2em}(var(V); recorda(N,$\vartheta_{\it theorem}$(N,V),\_\hspace{0.1em}),recorda(ctheorem,N,\_\hspace{0.1em})),!.\\[-0.7ex]
\\[-0.15ex]
$\vartheta_{\it pos}$(N) := \_\hspace{0.1em} :-\\[-0.15ex]
\hspace{2em}recorded(N,$\vartheta_{\it pos}$(N,\_\hspace{0.1em}),R),erase(R),fail.\\[-0.15ex]
$\vartheta_{\it pos}$(N) := V :- \\[-0.15ex]
\hspace{2em}(var(V); recorda(N,$\vartheta_{\it pos}$(N,V),\_\hspace{0.1em})),!.\\[-0.7ex]
\\[-0.15ex]
cdef(N) := \_\hspace{0.1em} :-\\[-0.15ex]
\hspace{2em}recorded(N,cdef(N,\_\hspace{0.1em}),R),erase(R),\\[-0.15ex]
\hspace{2em}recorded(cdef,N,RR), erase(RR),\\[-0.15ex]
\hspace{2em}fail.\\[-0.15ex]
cdef(N) := V :- \\[-0.15ex]
\hspace{2em}(var(V); recorda(N,cdef(N,V),\_\hspace{0.1em}),recorda(cdef,N,\_\hspace{0.1em})),!.\\[-0.7ex]
\\[-0.15ex]
V:=\_\hspace{0.1em} :- $\Theta_{-}^{'}$($\vartheta$(V,\_\hspace{0.1em})), fail.\\[-0.15ex]
V:=X :- (var(X); $\Theta_+$($\vartheta$(V,X))),!.\\[-0.7ex]
\\[-0.15ex]
$\vartheta_{\it theorem}$(N) =: X :-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}recorded(ctheorem,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}recorded(N,$\vartheta_{\it theorem}$(N,X),\_\hspace{0.1em}).\\[-0.15ex]
$\vartheta_{\it pos}$(N) =: X :-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}recorded(N,$\vartheta_{\it pos}$(N,X),\_\hspace{0.1em}).\\[-0.15ex]
cdef(N) =: X :-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}recorded(cdef,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}recorded(N,cdef(N,X),\_\hspace{0.1em}).\\[-0.15ex]
V=:X :- $\Theta_?$($\vartheta$(V,XX)),!,X=XX.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{cleandatabase}
\begin{sf}\begin{tabbing}
cleandatabase :-\\[-0.15ex]
\hspace{2em}recorded(ctheorem,T,R), functor(T,\_\hspace{0.1em},N), N$>$=1,\\[-0.15ex]
\hspace{2em}erase(R),\\[-0.15ex]
\hspace{2em}recorded(T,$\vartheta_{\it theorem}$(T,\_\hspace{0.1em}),R1), erase(R1),\\[-0.15ex]
\hspace{2em}recorded(T,$\vartheta_{\it pos}$(T,\_\hspace{0.1em}),R2), erase(R2),\\[-0.15ex]
\hspace{2em}$\Theta_-$($\vartheta$($\vartheta_{\it thm}$,T)),\\[-0.15ex]
\hspace{2em}fail.\\[-0.15ex]
cleandatabase.\\[-0.15ex]
\hspace{2em}
\end{tabbing}\end{sf}

 \ulinv{store} \ulinv{stored} \ulinv{unstore}
\begin{sf}\begin{tabbing}
$\Theta_+$($\vartheta$(X,Y)) :- recorda(X, $\vartheta$(X,Y), \_\hspace{0.1em}).\\[-0.15ex]
$\Theta_?$($\vartheta$(X,Y)) :- recorded(X, $\vartheta$(X,Y), \_\hspace{0.1em}).\\[-0.15ex]
$\Theta_-$($\vartheta$(X,Y)) :- recorded(X, $\vartheta$(X,Y), R), erase(R).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{unstoreall}
\begin{sf}\begin{tabbing}
$\Theta_{-}^{'}$(X):-$\Theta_-$(X),fail.\\[-0.15ex]
$\Theta_{-}^{'}$(\_\hspace{0.1em}).
\end{tabbing}\end{sf}

 } %end of latex footnote
 $H==>G$ is the theorem to be proved, $R$ is the refinement
 applied to the top level, $E$ the resulting extract term and
 $S$ the list of subproblems generated by that refinement.
 If a problem is still open, then $R$, $E$ and $S$ are 
 unbound Prolog variables. The list of subproblems again consists of 
 $\pi(H_i==>G_i,R_i,E_i,S_i)$ terms, each describing a subproblem.
 The hypothesis lists of subproblems contain only the
 increment to the hypotheses of the surrounding problem.
 In that sense the logic behaves strictly monotonically: The complete 
 hypothesis list for a certain node in the proof is computed
 during the process of accessing that node. 
 The extract term is stored only to the extend corresponding to
 the one refinement step carried out at that level. This extract
 term may contain Prolog variables, which correspond to the
 extract terms of some of the subproblems. Those subproblems
 which have an influence on  the extract term of the surrouding
 problem are stored in the form $\pi(H_i==>G_i,R_i,E_i,S_i)\;ext\;V_i$
 where $V_i$ is one of the Prolog variables appearing in the extract
 term $E$ of the surrounding problem. This means that the extract
 term corresponding to a whole subtree is computed only on request
 simply by recursively binding all variables $V_i$ to the 
 corresponding $E_i$
 \inv{$\triangle_{=:}$} \inv{$\vartheta_{\it universe}$} \inv{$\vartheta_{\it autotactic}$} 
\begin{sf}\begin{tabbing}
\hspace{1em}\\[-0.15ex]
$\triangle_{=:}$([],P,P).\\[-0.15ex]
$\triangle_{=:}$( [1$\mid$L], $\pi$(G,universe(I),E,S),S0):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it universe}$:=I, \\[-0.15ex]
\hspace{2em}$\triangle_{=:}$( [1$\mid$L],$\pi$(G,{\verb`~`},E,S),S0).\\[-0.15ex]
$\triangle_{=:}$( [1$\mid$L],$\pi$(G,autotactic(T),E,S),S0) :-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it autotactic}$:=T, \\[-0.15ex]
\hspace{2em}$\triangle_{=:}$([1$\mid$L],$\pi$(G,{\verb`~`},E,S),S0).\\[-0.15ex]
$\triangle_{=:}$( [N$\mid$L],$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S),$\pi$(HH==$>$G,R,E,Sx)):-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}$\triangle_{=:}$(N,S,SS),\\[-0.15ex]
\hspace{2em}$\triangle_{=:}$(L,SS,$\pi$(HH==$>$G,R,E,Sx)).\\[-0.7ex]
\\[-0.15ex]
$\triangle_{=:}$(N,L,\_\hspace{0.1em}) :- integer(N),var(L), !, fail.\\[-0.15ex]
$\triangle_{=:}$(1,[S \mbox{\it ext} \_\hspace{0.1em}$\mid$\_\hspace{0.1em}],S):-!.\\[-0.15ex]
$\triangle_{=:}$(1,[S$\mid$\_\hspace{0.1em}],S):-!.\\[-0.15ex]
$\triangle_{=:}$(N,[\_\hspace{0.1em}$\mid$L],X):-integer(N),N$>$1,N1 is N-1,!,$\triangle_{=:}$(N1,L,X).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{treeassign}
\begin{sf}\begin{tabbing}
$\triangle_{:=}$([],$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(\_\hspace{0.1em}==$>$G,R,E,S),$\pi$(H==$>$G,R,E,S)).\\[-0.15ex]
\hspace{2em}\\[-0.15ex]
$\triangle_{:=}$([P$\mid$L],$\pi$(G,R,E,S),N,$\pi$(G,R,E,T)):- \\[-0.15ex]
\hspace{2em}$\triangle_{=:}$(P,S,SS), $\triangle_{:=}$(L,SS,N,NN), $\triangle_{:=}$(P,S,NN,T).\\[-0.7ex]
\\[-0.15ex]
$\triangle_{:=}$(1,[\_\hspace{0.1em} \mbox{\it ext} E$\mid$T],N,[N \mbox{\it ext} E$\mid$T]):-!.\\[-0.15ex]
$\triangle_{:=}$(1,[\_\hspace{0.1em}$\mid$T],N,[N$\mid$T]).\\[-0.15ex]
$\triangle_{:=}$(I,[H$\mid$T],N,[H$\mid$S]):-integer(I),I$>$1,J is I-1,$\triangle_{:=}$(J,T,N,S).\\[-0.15ex]
\hspace{1em}
\end{tabbing}\end{sf}

 \ulinv{extractterm}
\begin{sf}\begin{tabbing}
$extract$($\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S),\_\hspace{0.1em}):-var(S),!.\\[-0.15ex]
$extract$($\pi$(\_\hspace{0.1em},\_\hspace{0.1em},E,S),T):-$extract$(E,S,T).\\[-0.7ex]
\\[-0.15ex]
$extract$(E,[],E).\\[-0.15ex]
$extract$(E,[P \mbox{\it ext} E0$\mid$S],EE):-$extract$(P,E0),!,$extract$(E,S,EE).\\[-0.15ex]
$extract$(E,[\_\hspace{0.1em}$\mid$S],EE):-$extract$(E,S,EE).\\[-0.7ex]

\end{tabbing}\end{sf}

 
 \section{Global Control Predicates}
 There exists no special library system as a part of Oyster. 
 The main idea of the system design was to supply all the basic
 operations which allow the independent implementation of
 possible different user interfaces on top of Oyster.
 Oyster assumes that theorems are stored
 in separate files. The user can load and save theorems independently. 
 Describing a problem means creating a
 file of the form  "$H==>G.$", where $H$ is a hypothesis list and
 $G$ is the goal to be proven  (don't forget
 the dot at the end! It's a Prolog term). Creating a theorem 
 means loading this problem description with the 
 $create\_thm(thm,file)$ predicate. Theorems can
 be created on-line using $create\_thm(thm,user)$.  Once a theorem 
 is created it can be saved and reloaded between the proof steps
 just as you want. 
 The $create\_thm$ and $load\_thm$ functions perform a rough
 structure check to avoid errors which result from loading totally 
 wrong files. Loading a theorem does not
 require reproving it. Therefore it seems to be adequate to 
 use the save and reload mechanism for version handling and
 runtime memory reorganisation. Tactics and your own proof development
 commands should be saved in project oriented Prolog source files
 and loaded using the common $consult(file)$ mechanism.
 If you are in any doubt whether your proof is still valid,
 for example after some confusion in your file system, you can
 force the system to reprove it.
 At least at the very end of a proof you should check it seriously.
  
 \ulinv{create\_thm}
\begin{sf}\begin{tabbing}
create\_\hspace{0.1em}thm(T,F):-\\[-0.15ex]
\hspace{2em}readfile(F,H==$>$G),\\[-0.15ex]
\hspace{2em}add\_\hspace{0.1em}thm( T, H==$>$G ).
\end{tabbing}\end{sf}

 \ulinv{add\_thm}
\begin{sf}\begin{tabbing}
add\_\hspace{0.1em}thm( T, H==$>$G) :-\\[-0.15ex]
\hspace{2em}retractall(autoloading\_\hspace{0.1em}def(\_\hspace{0.1em})),\\[-0.15ex]
\hspace{2em}(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass(yes) -$>$\\[-0.15ex]
\hspace{2em}assert(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass2(yes)); \\[-0.15ex]
\hspace{2em}retractall(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass2(\_\hspace{0.1em}))),     \\[-0.15ex]
\hspace{2em}syntax(H==$>$G),\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(T):=$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}$\vartheta_{\it pos}$(T):=[].
\end{tabbing}\end{sf}

 \ulinv{load\_thm}
\begin{sf}\begin{tabbing}
load\_\hspace{0.1em}thm(T,F):-\\[-0.15ex]
\hspace{2em}load\_\hspace{0.1em}thm(T,F,\_\hspace{0.1em}).\\[-0.15ex]
load\_\hspace{0.1em}thm(T,F,Q):-\\[-0.15ex]
\hspace{2em}readfile(F,$\pi$(H==$>$G,R,E,S)),\\[-0.15ex]
\hspace{2em}retractall(autoloading\_\hspace{0.1em}def(\_\hspace{0.1em})),\\[-0.15ex]
\hspace{2em}(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass(yes) -$>$\\[-0.15ex]
\hspace{2em}assert(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass2(yes)); \\[-0.15ex]
\hspace{2em}retractall(autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass2(\_\hspace{0.1em}))),     \\[-0.15ex]
\hspace{2em}syntax(H==$>$G),\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(T):=$\pi$(H==$>$G,R,E,S),$\vartheta_{\it pos}$(T):=[],\\[-0.15ex]
\hspace{2em}$status_0$($\pi$(H==$>$G,R,E,S),Q).
\end{tabbing}\end{sf}

 \ulinv{save\_thm}
\begin{sf}\begin{tabbing}
save\_\hspace{0.1em}thm(T,F):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(T)=:P,atom(F),tell(F),writep(0,P),write('.'),nl,told.
\end{tabbing}\end{sf}

 \ulinv{create\_def}
\begin{sf}\begin{tabbing}
create\_\hspace{0.1em}def( F ) :-\\[-0.15ex]
\hspace{2em}readfile(F,Head$<$==$>$Body),\\[-0.15ex]
\hspace{2em}add\_\hspace{0.1em}def( Head $<$==$>$ Body ).
\end{tabbing}\end{sf}

 \ulinv{add\_def}
  % First version to allow fast parsing of defs with no arguments.
 Not just speed. the expansion of definitions does not always respect
 bindings. for example, $y <==> atom(y)$ will cause $y:t=>\dots$ to be unfolded
 to $atom(y):t=>\dots$ etc.  
\begin{sf}\begin{tabbing}
add\_\hspace{0.1em}def( \{Name\} $<$==$>$ Body ) :-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Name),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}syntax( [], Body ),\\[-0.15ex]
\hspace{2em}cdef(Name) := (\{Name\} $<$==$>$ Body).\\[-0.15ex]
add\_\hspace{0.1em}def( Head $<$==$>$ Body ) :-\\[-0.15ex]
\hspace{2em}Head =.. [Name$\mid$Args],\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Name),\\[-0.15ex]
\hspace{2em}check\_\hspace{0.1em}set( Args ),  \% check for linearity of args\\[-0.15ex]
\hspace{2em}(bagof( VT, Arg\^{}(member(Arg,Args), VT = (Arg:dummy)), VarsHyps ) -$>$true;\\[-0.15ex]
\hspace{2em}VarsHyps = []),\\[-0.15ex]
\hspace{2em}syntax( VarsHyps, Body ),\\[-0.15ex]
\hspace{2em}cdef(Name) := (Head $<$==$>$ Body).\\[-0.7ex]
\\[-0.15ex]
check\_\hspace{0.1em}set([]).\\[-0.15ex]
check\_\hspace{0.1em}set([H$\mid$T]) :- $\backslash$+ member(H,T), check\_\hspace{0.1em}set(T).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{save\_def}
\begin{sf}\begin{tabbing}
save\_\hspace{0.1em}def(T,F) :-\\[-0.15ex]
\hspace{2em}cdef(T)=:P,atom(F),tell(F),writeq(P),write('.'),nl,told.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{current\_def}
\begin{sf}\begin{tabbing}
current\_\hspace{0.1em}def(X) :- cdef(X) =: \_\hspace{0.1em}.
\end{tabbing}\end{sf}

 \ulinv{erase\_def}
\begin{sf}\begin{tabbing}
erase\_\hspace{0.1em}def(D) :- cdef(D) := \_\hspace{0.1em}.
\end{tabbing}\end{sf}

 \ulinv{erasethm}
\begin{sf}\begin{tabbing}
erase\_\hspace{0.1em}thm(T) :- $\vartheta_{\it theorem}$(T) := \_\hspace{0.1em}.\\[-0.15ex]
\hspace{2em}\\[-0.7ex]

\end{tabbing}\end{sf}

 \small
 \ulinv{writep} \ulinv{writel}
\begin{sf}\begin{tabbing}
writep(\_\hspace{0.1em},$\pi$(H==$>$G,R,\_\hspace{0.1em},\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}var(R),write('$\pi$('),writeq(H==$>$G),write(',\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em})').\\[-0.15ex]
writep(N,$\pi$(H==$>$G,R,E,S)):-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(R), write('$\pi$('),writeq(H==$>$G),write(','),nl,\\[-0.15ex]
\hspace{2em}tab(N),writeq(R),write(','),writeq(E),write(','),nl,\\[-0.15ex]
\hspace{2em}tab(N),write('['),NN is N+1,writep(NN,S),nl,\\[-0.15ex]
\hspace{2em}tab(N),write('])').\\[-0.15ex]
writep(\_\hspace{0.1em},[]).\\[-0.15ex]
writep(N,[P \mbox{\it ext} E]):-!,writep(N,P),write(' \mbox{\it ext} '),writeq(E).\\[-0.15ex]
writep(N,[P]):-!,writep(N,P).\\[-0.15ex]
writep(N,[P \mbox{\it ext} E$\mid$T]):-\\[-0.15ex]
\hspace{2em}writep(N,P),write(' \mbox{\it ext} '),writeq(E),write(','),nl,tab(N),writep(N,T).\\[-0.15ex]
writep(N,[P$\mid$T]):-writep(N,P),write(','),nl,tab(N),writep(N,T).
\end{tabbing}\end{sf}

  % write list, one item per line, no indentation
\begin{sf}\begin{tabbing}
writel([]) :- write('[]').\\[-0.15ex]
writel([H]) :- !,write('['),write(H),write(']').\\[-0.15ex]
writel([H$\mid$T]) :- write('['),write(H),writel1(T),write(']').\\[-0.15ex]
writel1([]).\\[-0.15ex]
writel1([H$\mid$T]) :- write(','),nl,write(H),writel1(T).\\[-0.7ex]

\end{tabbing}\end{sf}

 \normalsize
 \ulinv{autotactic}
 The default autotactic is bound to the token ``defaultautotactic''.
 The default for the default is $idtac$, and can be changed by
 assigning to ``defaultautotactic'' with $:=$.
\begin{sf}\begin{tabbing}
?- defaultautotactic := idtac.\\[-0.7ex]

\end{tabbing}\end{sf}

 
 \section{Focusing}
 The first step after loading or creating some theorems is to select
 a theorem for further work. Selecting a theorem sets the current 
 working position (the \emph{focus}) on that point in the proof of the
 theorem where it was when the theorem was left last time.
 That means, you can switch between theorems without losing
 the position information. Every theorem has its own
 local focus, which is the current focus if the theorem is selected.
 If a theorem is created or loaded, the local focus is set at the top
 of that theorem.
 There are predicates for absolutely and relatively positioning
 the current focus (and therefore the local focus of the theorem
 selected).
 If the focus  moves around the proof tree, the value of
 global variables which correspond to properties of the
 proof tree (like the current autotactic, or the current universe
 universe level) are changed automatically according to the current
 position in the proof tree.
 \begin{itemize}
 \item
 $select(thm)$ selects a theorem for further work and sets the
 current focus to local focus of that theorem. 
 If you have forgotten to select
 a theorem most of the predicates will fail.
 $select(X)$ with a variable parameter gives you first the name 
 of the theorem currently selected (if any), and then (using 
 the ordinary Prolog backtracking mechanism) the names of all
 loaded theorems; $select$ without any parameter displays 
 the name of the currently selected theorem.
  
 \ulinv{select} \inv{$\vartheta_{\it theorem}$} \inv{$\vartheta_{\it pos}$}
\begin{sf}\begin{tabbing}
select(X):-var(X),$\vartheta_{\it thm}$=:T,!,(X=T;($\vartheta_{\it theorem}$(X) =: \_\hspace{0.1em},$\backslash$+X=T)).\\[-0.15ex]
select(X):-var(X),!,$\vartheta_{\it theorem}$(X) =: \_\hspace{0.1em}.\\[-0.15ex]
select(N):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(N)=:\_\hspace{0.1em}, $\vartheta_{\it thm}$:=N, $\vartheta_{\it pos}$(N)=:L,pos(L),$\vartheta_{\it status}$:=nonpure,\\[-0.15ex]
\hspace{2em}(functor(N,Name,Arity),\\[-0.15ex]
\hspace{2em}SA is Arity+1,\\[-0.15ex]
\hspace{2em}functor(NN,Name,SA),\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(NN) := \_\hspace{0.1em},\\[-0.15ex]
\hspace{2em}$\vartheta_{\it pos}$(NN) := \_\hspace{0.1em} ),!.\\[-0.15ex]
select:-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it thm}$=:X,!,\\[-0.15ex]
\hspace{2em}(X=..[XX,N],integer(N),select(XX),write(XX) ; write(X)),\\[-0.15ex]
\hspace{2em}tab(1).
\end{tabbing}\end{sf}

  
 \item
 $pos(x)$ can be used in two ways: If $x$ is not a fully instantiated
 list of integers, then it tries to match $x$ with the current 
 position. If $x$ is a list of integers $pos(x)$ switches the
 current focus to that position.  Positions are
 specified as tree coordinates,i.e. as a list of integers
 which describes the top-down way to the node in terms of
 the number of the sons to which one has to branch on that way.
 $pos$ without any parameter displays the current position.
  
 \ulinv{pos} \inv{cproblem}
\begin{sf}\begin{tabbing}
pos(P):-var(P),$\vartheta_{\it thm}$=:N,$\vartheta_{\it pos}$(N)=:P,!.\\[-0.15ex]
pos(P):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it thm}$=:N, $\vartheta_{\it theorem}$(N)=:X, $\vartheta_{\it universe}$:=1, \\[-0.15ex]
\hspace{2em}defaultautotactic =: AT, $\vartheta_{\it autotactic}$:=AT,\\[-0.15ex]
\hspace{2em}$\triangle_{=:}$(P,X,Y), $\vartheta_{\it pos}$(N):=P, $\vartheta_{\pi}$:=Y,!.\\[-0.15ex]
pos:-pos(P),!,write(P),tab(1).
\end{tabbing}\end{sf}

  
 \item
 $top$ resets the focus to the top of the current theorem;
  
 \ulinv{top}
\begin{sf}\begin{tabbing}
top:-pos([]),!.
\end{tabbing}\end{sf}

  
 \item
 $up$ moves the focus up one level, in the case of backtracking
 it tries to move further up;
  
 \ulinv{up}
\begin{sf}\begin{tabbing}
up:-pos(P),append(Q,[\_\hspace{0.1em}],P),(pos(Q);up).
\end{tabbing}\end{sf}

  
 \item
 $down(i)$ focuses down to the $i$-th subproblem, if there is
 one, and returns the focus in the case of backtracking to the 
 starting position. If it is not possible to go down to the $i$-th 
 subproblem, $down(i)$ fails.
 $down(X)$ may be used for generating the direct subgoals
 one after the other. $down(X)$ is a backtrackable
 predicate which resets the focus to the starting point.
 $down$ (without any parameter) is a shorthand
 notation for $down(\_)$.
  
 \ulinv{down}
\begin{sf}\begin{tabbing}
down(X):-\\[-0.15ex]
\hspace{2em}integer(X),pos(P),( append(P,[X],Q),pos(Q);(pos(P),!,fail) ).\\[-0.15ex]
down(X):-\\[-0.15ex]
\hspace{2em}var(X),pos(P),$\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S), $\backslash$+ var(S),\\[-0.15ex]
\hspace{2em}(generate\_\hspace{0.1em}sons(S,1,X),append(P,[X],Q),pos(Q);pos(P),!,fail).\\[-0.15ex]
down:-down(\_\hspace{0.1em}).
\end{tabbing}\end{sf}

  
 \item
 $next(X)$ sets the focus on the next unsolved subproblem in the
 subproof below the current position, and generates
 in the case of backtracking successively all other unsolved
 subproblems, until it resets the focus to the starting point and fails.
 The parameter is always bound to the position of the open problem 
 just found. $next$ (without any parameter) is a shorthand notation
 for $next(\_)$.
  
 \ulinv{next}
\begin{sf}\begin{tabbing}
next(Q):-\\[-0.15ex]
\hspace{2em}pos(P),P=Q,$\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em},R,\_\hspace{0.1em},\_\hspace{0.1em}),var(R),!.\\[-0.15ex]
next(QQ):-\\[-0.15ex]
\hspace{2em}pos(P), $\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S),\\[-0.15ex]
\hspace{2em}( generate\_\hspace{0.1em}sons(S,1,I), append(P,[I],Q), pos(Q), next(QQ) ; pos(P), fail ) .  \\[-0.15ex]
next:-next(\_\hspace{0.1em}).\\[-0.15ex]
next\_\hspace{0.1em}goal(G) :-\\[-0.15ex]
\hspace{2em}next\_\hspace{0.1em}goal(\_\hspace{0.1em},G,\_\hspace{0.1em}).\\[-0.15ex]
next\_\hspace{0.1em}goal(Q,G,Rule):-\\[-0.15ex]
\hspace{2em}pos(P),P=Q,$\vartheta_{\pi}$=:$\pi$(G,Rule,\_\hspace{0.1em},\_\hspace{0.1em}).\\[-0.15ex]
next\_\hspace{0.1em}goal(QQ,G,Rule):-\\[-0.15ex]
\hspace{2em}pos(P), $\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S),\\[-0.15ex]
\hspace{2em}( generate\_\hspace{0.1em}sons(S,1,I), append(P,[I],Q), pos(Q),\\[-0.15ex]
\hspace{3em}next\_\hspace{0.1em}goal(QQ,G,Rule) ; pos(P), fail ) .  \\[-0.15ex]
next\_\hspace{0.1em}$\vdash$(Q,Rule):-\\[-0.15ex]
\hspace{2em}pos(P),P=Q,$\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em},Rule,\_\hspace{0.1em},\_\hspace{0.1em}).\\[-0.15ex]
next\_\hspace{0.1em}$\vdash$(QQ,Rule):-\\[-0.15ex]
\hspace{2em}pos(P), $\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S),\\[-0.15ex]
\hspace{2em}( generate\_\hspace{0.1em}sons(S,1,I), append(P,[I],Q), pos(Q),\\[-0.15ex]
\hspace{3em}next\_\hspace{0.1em}$\vdash$(QQ,Rule) ; pos(P), fail ) .  \\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{generate\_sons}
\begin{sf}\begin{tabbing}
generate\_\hspace{0.1em}sons([\_\hspace{0.1em}$\mid$\_\hspace{0.1em}],I,I).  \\[-0.15ex]
generate\_\hspace{0.1em}sons([\_\hspace{0.1em}$\mid$T],N,I):-N1 is N+1,generate\_\hspace{0.1em}sons(T,N1,I).
\end{tabbing}\end{sf}

  
 \end{itemize}
  
 \section{Display Routines}
 There are two display predicates $display$ and $snapshot$.
 $display$ is the normal way to show the current problem. 
 $snapshot(filename,depth)$ writes an 
 overview of the proof tree below the current focus on the file
 specified,
 and is mostly used for documentation. The second parameter 
 restricts the depth to which the proof tree is displayed,
 $0$ implies no restriction, i.e. the documentation of the
 complete proof tree.
 There are three global parameters
 which allow some tuning of the layout yielded by $display$
 and $snapshot$.
 The $screensize$ parameter should be equal to the current
 width of the window (standard value is 80),
 the $shift$ parameter describes the
 indentation the system automatically chooses for each new
 level of declaration or operators if they don't fit on
 the rest of the line (standard value is 2), and the
 $fringe$ parameter gives the nesting depth, below which
 the fringed output would yield only '...'.
 the $fringe$ standard value $0$ has no effect and keeps
 all terms unchanged.
 The parameters may be checked and changed at any time using the
 corresponding $screensize(X)$, $shift(X)$ or $fringe(X)$ predicate.
 \small
 \ulinv{screensize} \ulinv{cscreensize}
\begin{sf}\begin{tabbing}
screensize(X):-(integer(X),0$<$X,$\vartheta_{\it screensize}$:=X,!; $\vartheta_{\it screensize}$=:X).
\end{tabbing}\end{sf}

 \ulinv{shift} \ulinv{cshift}
\begin{sf}\begin{tabbing}
shift(X):-(integer(X),0=$<$X,$\vartheta_{\it shift}$:=X,!; $\vartheta_{\it shift}$=:X).
\end{tabbing}\end{sf}

 \ulinv{fringe} \ulinv{cfringe}
\begin{sf}\begin{tabbing}
fringe(X):-(integer(X),0=$<$X,$\vartheta_{\it fringe}$:=X,!; $\vartheta_{\it fringe}$=:X).\\[-0.7ex]
\\[-0.15ex]
?- screensize(80), shift(2), fringe(0).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{display}
\begin{sf}\begin{tabbing}
display:-snapshot(user,2).
\end{tabbing}\end{sf}

 \ulinv{snapshot}
\begin{sf}\begin{tabbing}
snapshot:-snapshot(user,0).\\[-0.15ex]
snapshot(F):-snapshot(F,0).\\[-0.15ex]
snapshot(F,D):-\\[-0.15ex]
\hspace{2em}atom(F),integer(D),tell(F),$\vartheta_{\it thm}$ =: CT,write(CT),write(': '),pos,status,\\[-0.15ex]
\hspace{2em}(universe(1); universe),(autotactic(repeat(intro)); autotactic),nl,\\[-0.15ex]
\hspace{2em}$\vartheta_{\pi}$=:P,snapshot(D,0,1,P),told,!.\\[-0.7ex]
\\[-0.15ex]
snapshot(D,Z,N,$\pi$(H==$>$G,R,\_\hspace{0.1em},S)):-\\[-0.15ex]
\hspace{1em}$\vartheta_{\it shift}$=:C,ZZ is Z+C, write\_\hspace{0.1em}hyp(Z,N,NN,H),\\[-0.15ex]
\hspace{1em}tab(Z),write('==$>$ '),writeterm0(ZZ,G), DD is D-1,\\[-0.15ex]
\hspace{1em}($\backslash$+ DD=0,tab(Z),write('by '),writeterm0(ZZ,R),nl,snapshot(DD,ZZ,1,NN,S); nl).\\[-0.7ex]
\\[-0.15ex]
snapshot(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S):-var(S),!.\\[-0.15ex]
snapshot(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},[]).\\[-0.15ex]
snapshot(D,Z,I,N,[PP$\mid$S]):-\\[-0.15ex]
\hspace{1em}(PP=(P \mbox{\it ext} \_\hspace{0.1em}); PP=P),tab(Z),write([I]),$status_0$(P,Q),tab(1),write(Q),nl,\\[-0.15ex]
\hspace{1em}snapshot(D,Z,N,P),J is I+1,snapshot(D,Z,J,N,S).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{write\_hyp}
\begin{sf}\begin{tabbing}
write\_\hspace{0.1em}hyp(Z,StartHyp, LastHyp, Hyps ) :-\\[-0.15ex]
\hspace{2em}write\_\hspace{0.1em}hyp(Z, 1, StartHyp, LastHyp, Hyps ).\\[-0.7ex]
\\[-0.15ex]
write\_\hspace{0.1em}hyp(\_\hspace{0.1em}, Ctr, \_\hspace{0.1em}, Ctr, [] ).\\[-0.15ex]
write\_\hspace{0.1em}hyp(Z, Ctr, StartHyp, LastHyp, [\_\hspace{0.1em}$\mid$R] ) :-\\[-0.15ex]
\hspace{2em}Ctr $<$ StartHyp,\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}NCtr is Ctr + 1,\\[-0.15ex]
\hspace{2em}write\_\hspace{0.1em}hyp( Z, NCtr, StartHyp, LastHyp, R ).\\[-0.15ex]
write\_\hspace{0.1em}hyp(Z, Ctr, StartHyp, LastHyp, [HH$\mid$R] ) :-\\[-0.15ex]
\hspace{2em}tab(Z),write(Ctr),write('. '),ZZ is Z+3,writeterm0(ZZ,HH),\\[-0.15ex]
\hspace{2em}NCtr is Ctr + 1,\\[-0.15ex]
\hspace{2em}write\_\hspace{0.1em}hyp(Z,NCtr,StartHyp,LastHyp,R).\\[-0.7ex]

\end{tabbing}\end{sf}

 \normalsize
  
 \section{Selector Predicates}
 The selector predicates operate on the current focus without
 modifying the proof tree.
 \begin{itemize}
 \item
 The $status(X)$ predicate is used to check the current status.
 It yields one of the values $complete$, $complete(because)$, $partial$, or
 $incomplete$; a proof marked $complete(because)$ contains some uses
 of the $because$ inference rule, but is otherwise complete.
 \item
 The $goal(G)$ predicate can be used to check the structure
 of the current goal; 
 \item
 The $hypothesis(X)$ predicate generates all hypotheses matching the
 given pattern term X and fails if there are no (further) hypotheses;
 \item
 The $hyp\_list(X)$ predicate yields the list of all hypotheses;
 \item
 The $refinement(X)$ predicate allows to pick up the complete 
 (i.e. not fringed) current refinement,
 which is useful for writing transformational tactics; and
 \item
 $extract(X)$ yields the `polished' extract term. Polishing means
 here that all bound variables appearing in the extract term
 are checked, to see whether they are really used or not. If not their
 defining occurence is replaced by \verb'~';
 \item
 $autotactic(X)$ and $universe(X)$ allow a check of the
 current autotactic and universe level, respectively.
 The current values of autotactic and universe level are
 computed and stored in the process of top-down positioning in the
 proof tree;
 \item
 the short forms \emph{select, pos, status, goal, ...} without any
 parameters may be used for direct display of the current values,
 which is especially useful when working on small or dumb displays.
 \end{itemize}
 The combination of selector predicates with focusing predicates
 gives a powerful control mechanism, which is demonstrated by the
 following examples of user defined control predicates: 
 \begin{verbatim}
      forall(G,X):-
         top,next,copy(G,GG),goal(GG),apply(X),fail.
      upwards:-up,status(partial).
 \end{verbatim}
 $forall(G,X)$ applies the tactic $X$ to all open 
 subgoals of the structure $G$;
 and $upwards$ moves the focus upwards to the 
 first level which is not completely solved.
  
 \ulinv{status}
\begin{sf}\begin{tabbing}
status(Q):-$\vartheta_{\pi}$=:P,$status_0$(P,Q),!.
\end{tabbing}\end{sf}

 \ulinv{goal}
\begin{sf}\begin{tabbing}
goal(G):-$\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em}==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),!.
\end{tabbing}\end{sf}

 \ulinv{hyp\_list}
\begin{sf}\begin{tabbing}
hyp\_\hspace{0.1em}list(H):-$\vartheta_{\pi}$=:$\pi$(H==$>$\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),!.
\end{tabbing}\end{sf}

 \ulinv{hypothesis}
\begin{sf}\begin{tabbing}
hypothesis(H):-hyp\_\hspace{0.1em}list(L),!, member(H,L).
\end{tabbing}\end{sf}

 \ulinv{refinement}
\begin{sf}\begin{tabbing}
refinement(R):-$\vartheta_{\pi}$=:$\pi$(\_\hspace{0.1em},R,\_\hspace{0.1em},\_\hspace{0.1em}),!.
\end{tabbing}\end{sf}

 \ulinv{extract}
\begin{sf}\begin{tabbing}
extract(T):-$\vartheta_{\pi}$=:P,$extract$(P,T0),polish(T0,TT),!,T=TT.
\end{tabbing}\end{sf}

 \ulinv{autotactic}
\begin{sf}\begin{tabbing}
autotactic(X):-$\vartheta_{\it autotactic}$=:X,!.
\end{tabbing}\end{sf}

 \ulinv{universe}
\begin{sf}\begin{tabbing}
universe(X):-$\vartheta_{\it universe}$=:X,!.\\[-0.7ex]
\\[-0.15ex]
status:-status(Q),write(Q),tab(1).\\[-0.15ex]
goal:-goal(G),write('==$>$ '),writeterm(3,G).\\[-0.15ex]
hyp\_\hspace{0.1em}list:-hyp\_\hspace{0.1em}list(H),write\_\hspace{0.1em}hyp(0,1,\_\hspace{0.1em},H).\\[-0.15ex]
refinement:-refinement(R),writeterm(R).\\[-0.15ex]
extract:-extract(T),writeterm(T).\\[-0.15ex]
autotactic:-autotactic(X),write(autotactic(X)),tab(1).\\[-0.15ex]
universe:-universe(X),write(universe(X)),tab(1).\\[-0.7ex]

\end{tabbing}\end{sf}

 \small
 \ulinv{status0}
 % status1 in mode (+,?):
 % as status is calculated as lower bound on inherited
 % statuses, can get wrong answer in (+,+), hence first clause
\begin{sf}\begin{tabbing}
$status_0$(P,S) :- status1(P,SS),!,S=SS.\\[-0.15ex]
status1($\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S),incomplete):-var(S),!.\\[-0.15ex]
status1($\pi$(\_\hspace{0.1em},R,\_\hspace{0.1em},\_\hspace{0.1em}),P):- R==because,!,P=complete(because).\\[-0.15ex]
status1($\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S),P):- $\backslash$+ var(S),status1(S,P).\\[-0.15ex]
status1(P \mbox{\it ext} \_\hspace{0.1em},S):-status1(P,S).\\[-0.15ex]
status1([],complete).\\[-0.15ex]
status1([H$\mid$T],S) :- status1(H,S1),status1(T,S2),\\[-0.15ex]
\hspace{10em}combine\_\hspace{0.1em}status(S1,S2,S),!.\\[-0.15ex]
combine\_\hspace{0.1em}status(X,X,X).\\[-0.15ex]
combine\_\hspace{0.1em}status(incomplete,\_\hspace{0.1em},partial).\\[-0.15ex]
combine\_\hspace{0.1em}status(partial,\_\hspace{0.1em},partial).\\[-0.15ex]
combine\_\hspace{0.1em}status(complete(because),complete,complete(because)).\\[-0.15ex]
combine\_\hspace{0.1em}status(complete(because),\_\hspace{0.1em},partial).\\[-0.15ex]
combine\_\hspace{0.1em}status(complete,complete(because),complete(because)).\\[-0.15ex]
combine\_\hspace{0.1em}status(complete,\_\hspace{0.1em},partial).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{polish}
\begin{sf}\begin{tabbing}
polish(X,Y):-var(X),!,X=Y.\\[-0.15ex]
polish([T],[TT]):-!,polish(T,TT),!.\\[-0.15ex]
polish([U$\mid$T],[U$\mid$T]) :- member(V,[U$\mid$T]),var(V),!.\\[-0.15ex]
polish([U$\mid$T],[{\verb`~`}$\mid$TT]):- $\backslash$+ appears(U,T),!,polish(T,TT).\\[-0.15ex]
polish([U$\mid$T],[U$\mid$TT]):-!,polish(T,TT).\\[-0.15ex]
polish($\sigma$(T,Y,X),TT):-s(T,Y,X,T0),!,polish(T0,TT).\\[-0.15ex]
polish(lambda(U,T),lambda(UU,TT)):-!,polish([U,T],[UU,TT]).\\[-0.15ex]
polish(U:T,UU:TT):-!,polish([U,T],[UU,TT]).\\[-0.15ex]
polish(T,TT):-T=..[F$\mid$A],${\it polish}'$(A,AA),TT=..[F$\mid$AA].\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{polishl}
\begin{sf}\begin{tabbing}
${\it polish}'$([],[]).\\[-0.15ex]
${\it polish}'$([X$\mid$T],[XX$\mid$TT]):-polish(X,XX),${\it polish}'$(T,TT).
\end{tabbing}\end{sf}

 \normalsize
  
 \section{The Inference Engine}
 
 One of the main problems in organising the theorem proving process
 is to ensure the consistency of the data structures representing
 the current state of the proof. In the Oyster implementation, the
 proof tree itself is completely hidden from the user. The user can
 move around the focus and display parts of the proof tree, but 
 for modifying the proof tree there is only one predicate ($apply$),
 which invokes the inference engine of the Oyster system, i.e. the only
 way of modifying the proof tree is the successful application of
 some sequence of inference rules. 
 
 There are two modes of operation of the inference engine:
 the $pure$ and the $nonpure$ (i.e.standard) mode. In the
 $pure$ mode the autotactic as well as all the derived  
 rules are temporarely switched off. This mode is useful in
 debugging proof trees and for the application of
 user defined meta-level strategies.
 The $nonpure$ mode is the standard one and makes the system
 together with the standard autotactic ($repeat \; intro$)
 more suitable for creative interactive use.
 
 \subsection{The $apply$-Predicate}
 
 The $apply$ predicate is parametrised by tactics or pseudo tactics.
 A tactic is either the specification of a inference
 rule, like $intro$ or $elim(x)$, a call of a user defined tactic
 in the form $tactic(U,X)$ (or $U$ for short), 
 or an arbitrary combination of tactics by means of the predefined 
 tacticals $then$, $or$, $repeat$, $complete$, and $try$. 
 The semantics of the \emph{tacticals} is described by the
 $\models$(...) predicate. 
 After the execution of the arguments of $apply$ 
 the current autotactic is $try$-applied to all generated
 subgoals (see below for the definition of the $try$ tactical). 
 The autotactic is considered as a property of the
 proof tree and may differ in several parts of the proof tree.
 The autotactic is assigned as an attribute to the proof tree
 and selected during the process of top down positioning
 in the proof tree.
 Invoking the \emph{autotactic} as well as the
 execution of \emph{pseudo tactics} is described by the
 $\models_{0}$(...) predicate.
  
 The apply predicate modifies the proof tree
 only in the case of successful tactic application. 
 Inference rules and tactics are applied by the backtrackable
 $prove$ predicate. $apply(X)$ may be useful to obtain some
 hints about rules which are applicable in this situation.
 Some shorthand notations allow more convenient use.
 \ulinv{apply}
\begin{sf}\begin{tabbing}
apply(X):-\\[-0.15ex]
\hspace{2em}var(X),!,\\[-0.15ex]
\hspace{2em}toggle(direction,[backwards,forwards]),\\[-0.15ex]
\hspace{2em}$\vartheta_{\pi}$=:$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),($\vdash$(X,G \mbox{\it ext} \_\hspace{0.1em},\_\hspace{0.1em});$\vdash$(X,G,\_\hspace{0.1em})),\\[-0.15ex]
\hspace{2em}toggle(direction,[forwards,backwards]).\\[-0.15ex]
apply(R):-\\[-0.15ex]
\hspace{2em}direction:=forwards, $\vartheta_{\pi}$=:P, !, $\models_{0}$(R,P,Q), $\vartheta_{\pi}$:=Q, \\[-0.15ex]
\hspace{2em}$\vartheta_{\it thm}$=:T, $\vartheta_{\it pos}$(T)=:H, $\vartheta_{\it theorem}$(T)=:M, $\triangle_{:=}$(H,M,Q,N), $\vartheta_{\it theorem}$(T):=N,!.\\[-0.7ex]
\\[-0.15ex]
apply(R,H==$>$G,S):-\\[-0.15ex]
\hspace{2em}$\models$(R,$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},Q)),unfold(Q,S).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{unfold}
\begin{sf}\begin{tabbing}
unfold([],[]).\\[-0.15ex]
unfold([$\pi$(P,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} \_\hspace{0.1em}$\mid$T],[P$\mid$TT]):-unfold(T,TT).\\[-0.15ex]
unfold([$\pi$(P,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em})$\mid$T],[P$\mid$TT]):-unfold(T,TT).\\[-0.15ex]
\hspace{4em}
\end{tabbing}\end{sf}

 
 The $\models_{0}$(R,...) predicate handles pseudo tactics and invokes
 the autotactic by expanding $R$ to $R\; then\; ... $.
 Pseudo tactics are $universe(I)$, $autotactic(T)$, $pure(T)$,
 and $undo$. 
 They may not be combined by means of tacticals,
 {\bf although the system does NOT enforce this restriction}.
  
 \begin{itemize}
 \item
 \ulinv{universe}
 The current universe level is a property of the proof tree.
 It is assigned to a node of the proof tree and defines the
 default value for the universe level in the subtree below that point.
 The default value is computed in 
 a top-down manner during positioning in the proof tree.
 The top level is assumed to be labelled with the universe level $1$.
 The pseudo tactic $universe(I)$ assigns this value to the
 proof tree.
  
 \ulinv{proving}
\begin{sf}\begin{tabbing}
$\models_{0}$(universe(I),$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),\\[-0.15ex]
\hspace{4em}$\pi$(H==$>$G,universe(I),X,[$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} X])).
\end{tabbing}\end{sf}

  
 \item
 \ulinv{autotactic}
 Autotactics are considered as default reasoning strategies and
 assigned to the proof tree in the form of a pseudo tactic
 $autotactic(T)$. The autotactic is valid for the subtree below
 the point, where it is set, except subtrees with another
 explicitly defined autotactic.
 The top level is assumed to be labeled with $repeat \; intro$.
  
\begin{sf}\begin{tabbing}
$\models_{0}$(autotactic(T),$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),\\[-0.15ex]
\hspace{4em}$\pi$(H==$>$G,autotactic(T),X,[$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} X])).
\end{tabbing}\end{sf}

  
 \item
 \ulinv{undo}
 $undo$ is the destructive pseudo tactic, which deletes previous 
 results in proving the current problem, i.e. the \emph{status} of the
 current node becomes \emph{incomplete}. All the subproof below
 the current position is deleted.
  
\begin{sf}\begin{tabbing}
$\models_{0}$(undo,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em})).
\end{tabbing}\end{sf}

 
 \item
 \ulinv{pure}
 In all other cases it is assumed that $\models_0$ is parametrised
 by a tactic and the argument is passed to $\models$, possibly
 extended by the application of the autotactic (in \emph{nonpure mode}
 only). The $\models$ predicate always operates with full
 hypothesis lists, therefore the resulting subproblems have
 to be cleaned up at the end. $increment(P,Q,Q')$ deletes all
 redundant hypotheses from the subgoals of $Q$ and produces $Q'$.
 The pseudo tactic $pure(T)$ switches the system temporarily,
 i.e. for the execution of the tactic $T$ in the,   
 into the \emph{pure mode}.
 \inv{$\vartheta_{\it status}$}
\begin{sf}\begin{tabbing}
$\models_{0}$(pure(R),P,$\pi$(G,pure(R),E,S)):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it status}$=:T,!,\\[-0.15ex]
\hspace{2em}( $\vartheta_{\it status}$:=pure,$\models$(R,P,Q),increment(Q,$\pi$(G,R,E,S)),$\vartheta_{\it status}$:=T; \\[-0.15ex]
\hspace{3em}$\vartheta_{\it status}$:=T,fail ).\\[-0.7ex]
\\[-0.15ex]
$\models_{0}$(R,P,QQ):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it status}$=:pure,!,\\[-0.15ex]
\hspace{2em}$\models$(R,P,Q),increment(Q,QQ).\\[-0.15ex]
$\models_{0}$(R,P,QQ):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it autotactic}$ =: idtac,!,\\[-0.15ex]
\hspace{2em}$\models$(R,P,Q),increment(Q,QQ).\\[-0.15ex]
$\models_{0}$(R,P,$\pi$(G,R,E,S)):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it autotactic}$=:X,\\[-0.15ex]
\hspace{2em}$\vartheta_{\it autotactic}$ := idtac,\\[-0.15ex]
\hspace{2em}($\models$(then(R,try(X)),P,Q), !; $\vartheta_{\it autotactic}$:= X, !, fail),\\[-0.15ex]
\hspace{2em}$\vartheta_{\it autotactic}$ := X,\\[-0.15ex]
\hspace{2em}increment(Q,$\pi$(G,\_\hspace{0.1em},E,S)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{increment}
% increment($\pi$(H==>G,R,E,S),$\pi$(H==>G,R,E,SS)):-
% increment(H,S,SS).
\begin{sf}\begin{tabbing}
increment($\pi$(H==$>$G,R,E,S),$\pi$(H==$>$G,R,E,S)).\\[-0.7ex]
\\[-0.15ex]
increment(\_\hspace{0.1em},[],[]).\\[-0.15ex]
increment(H0,[$\pi$(H==$>$G,R,E,S)$\mid$T],[$\pi$(HH==$>$G,R,E,S)$\mid$TT]):-\\[-0.15ex]
\hspace{1em}diff(H,H0,HH),increment(H0,T,TT).\\[-0.15ex]
increment(H0,[$\pi$(H==$>$G,R,E,S) \mbox{\it ext} V$\mid$T],[$\pi$(HH==$>$G,R,E,S) \mbox{\it ext} V$\mid$TT]):-\\[-0.15ex]
\hspace{1em}diff(H,H0,HH),increment(H0,T,TT).\\[-0.7ex]

\end{tabbing}\end{sf}

  
 \end{itemize}
  
 \subsection{The $\models$-Predicate}
 
 The $\models$(R,...) predicate is the kernel of the inference engine.
 It describes the recursive control of the
 inference process by means of the tacticals 
 \emph{complete, try, repeat, then,} and \emph{ or}, it recognises
 rule specifications and calls the $\vdash$(...) predicate, and
 it handles user defined tactics. $\models$(...) is invoked with 
 full problem descriptions, i.e. full hypothesis lists.
 The reduction process is performed at he end.
 
 \begin{itemize} 
 \item
 The syntax of the tacticals is best
 described by their operator declarations:  
 
 \inv{operator declarations}
 \ulinv{then} \ulinv{or} \ulinv{repeat} \ulinv{complete} \ulinv{try}
\begin{sf}\begin{tabbing}
?- \\[-0.15ex]
\hspace{1em}op(950,xfy,['then']),\\[-0.15ex]
\hspace{1em}op(900,xfy,['or']),\\[-0.15ex]
\hspace{1em}op(850,fx,['repeat','complete','try']).
\end{tabbing}\end{sf}

 
 \item
 \ulinv{idtac}
 $idtac$ is the identical tactic which has no effect at all.
 It is useful in combination with the $then\;[T_1,...]$ tactical,
 giving the possibility of applying other tactics only to certain
 branches of the proof tree.
 It should be used as the auto tactic if you want
 to switch the auto tactic off.
 
 \inv{prove}
\begin{sf}\begin{tabbing}
$\models$(idtac,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,idtac,E,[$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} E])):-!.
\end{tabbing}\end{sf}

   
 \item
 \ulinv{then}
 $T_{1}\; then\; T_{2}$ is a tactic defined by applying first $T_{1}$  
 and then $T_{2}$ on all subgoals. 
 $T_{1}\; then\; [T_{2}^{1},T_{2}^{2},...]$ is a tactic defined 
 by applying $T_{1}$ first
 and then each of tactics $T_{2}^{i}$ to the corresponding subgoals
 which have been generated by $T_{1}$, i.e. $T_{2}^{1}$ to the first 
 subgoal, $T_{2}^{2}$ to the second subgoal etc.
   
\begin{sf}\begin{tabbing}
$\models$(T1 then T2,$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(H==$>$G,T1 then T2,EE,S)):- \\[-0.15ex]
\hspace{2em}$\models$(T1,$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(H==$>$G,\_\hspace{0.1em},E,U)), $\backslash$+ var(U),$\models'$(T2,E,U,EE,S),!.
\end{tabbing}\end{sf}

   
 \item
 \ulinv{or}
 $T_{1}\; or\; T_{2}$ is a tactic which first applies
 $T_{1}$ and in the case of failure, caused 
 by the application of $T_{1}$,  
 makes an attempt to apply $T_{2}$.
   
\begin{sf}\begin{tabbing}
$\models$(T1 or T2,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,T1 or T2,E,S)):- $\models$(T1,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,\_\hspace{0.1em},E,S)).\\[-0.15ex]
$\models$(T1 or T2,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,T1 or T2,E,S)):- $\models$(T2,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,\_\hspace{0.1em},E,S)),!.
\end{tabbing}\end{sf}

   
 \item
 \ulinv{repeat}
 $repeat\;T$ is an unconditional tactical which tries to apply $T$
 on the given problem and recursively $repeat\;T$ 
 on all subproblems generated by $T$.
 You could define $repeat\;T$ as equivalent to
 $(T\;then\;repeat\;T)\;or\;idtac$.
 It generates as a result the list of all subproblems
 which can not be handled further by $T$, i.e. $T$ would
 fail when applied once more to any of these subgoals. 
 $repeat$ combined with $intro$-rule is a very powerful tool,
 thats why the standard autotactic is set to $repeat\;intro$.
 In fact, the shorthand definitions for $intro$ are carefully tuned
 to reach this high level performance. 
 Therefore you should define your own autotactic following the
 pattern $repeat\;(...\;or\;intro\;or\;...)$.
   
\begin{sf}\begin{tabbing}
$\models$(repeat T,$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(H==$>$G,repeat T,EE,S)):- \\[-0.15ex]
\hspace{2em}copy(T,T1),copy(T,T2),\\[-0.15ex]
\hspace{2em}$\models$(T1,$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},E,U)),!,$\models'$(repeat(T2),E,U,EE,S).\\[-0.15ex]
$\models$(repeat T,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,repeat T,E,[$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} E])):-!.
\end{tabbing}\end{sf}

   
 \item
 \ulinv{complete}
 $complete\; T$ is a conditional tactical which is successful with
 the effect of $T$, if the application of $T$ solves the problem
 completely, i.e. if $T$ generates no new subgoals,
 and fails without any effect otherwise.
   
\begin{sf}\begin{tabbing}
$\models$(complete T,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,complete T,E,[])):- \\[-0.15ex]
\hspace{2em}$\models$(T,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,\_\hspace{0.1em},E,Subs)),nonvar(Subs),Subs=[],!.
\end{tabbing}\end{sf}

  
 \item
 \ulinv{try}
 $try$ is a failure catching tactical.
 $try\; T$ is successful every time. It has the effect of $T$ 
 if $T$ is successful, and has no effect otherwise.
\begin{sf}\begin{tabbing}
\hspace{1em}\\[-0.15ex]
$\models$(try T,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,try T,E,S)):- $\models$(T,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,\_\hspace{0.1em},E,S)),!.\\[-0.15ex]
$\models$(try T,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,try T,E,[$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} E])):-!.\\[-0.15ex]
\hspace{1em}
\end{tabbing}\end{sf}

 \item
 The selection of the appropriate inference 
 rule is driven by pattern matching between the
 current goal and the rule specification on one hand and the set of
 inference rules on the other hand. The rule base itself
 is documented in the next chapter. The rules are organised in such a
 way that the rule parameters $new[v,...]$, and $at(i)$
 may be omitted.
 The specification of a rule may be simplified using Prolog
 variables, which become instantiated from the preceding context,
 or by means of anonymous variables, which is especially valuable in 
 the case of the $subst$ and $compute$ rules. This approach allows the
 reusability of rules in a different context. Rules are always called 
 on a copy of the rule specification. Therefore variable bindings
 may only be used inside a single rule specification to formalise
 structural restriction on the parameters, and so you will never get the
 values assigned to the variables outside the $apply(T)$ predicate.
 To connect the $\vdash$-predicate (primarily designed for 
 having a simple and executable specification of the rule base)
 with the $\models$-predicate the list of subgoals generated by
 $\vdash$ has to be extended into a list of subproblems and
 in this process the hypotheses have to be extended. This
 task is performed by the $makesubgoals$ predicate.   
\begin{sf}\begin{tabbing}
$\models$(R,$\pi$(H==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(H==$>$G,R,E,T)):- \\[-0.15ex]
\hspace{2em}functor(R,F,\_\hspace{0.1em}), rulename(F),\\[-0.15ex]
\hspace{2em}( (G=(\_\hspace{0.1em} in \_\hspace{0.1em});G=(\_\hspace{0.1em} $<$ \_\hspace{0.1em});G=(\_\hspace{0.1em}$<$*\_\hspace{0.1em})),$\vdash$(R,H==$>$G,S),E=axiom;\\[-0.15ex]
\hspace{3em}$\vdash$(R,H==$>$G \mbox{\it ext} E,S)\\[-0.15ex]
\hspace{2em}),!,${\it subgoals}$(H,S,T).\\[-0.7ex]

\end{tabbing}\end{sf}

  
 \item
 \inv{user tactic} \ulinv{tactic}
 A user defined tactic is an arbitrary piece of Prolog code,
 designed to prove a given theorem in an unknown environment,
 or to generate parameters which may be passed to other tactics.
 The effect of the application of a user defined tactic 
 on a certain subproblem $H==>G$ is defined to
 be the effect of applying this tactic on the top level
 of a new theorem $H==>G$, folding the resulting proof tree
 into a one level structure, and copying this into the
 original proof tree. 
 \footnote{This implies that a tactic cannot move above the
 starting point it was called from}
 
 \ulinv{tactic}
 If the application of a user defined tactic of the form
 $tactic(U,X)$ is successful, $X$ is bound to the resulting refinement
 which would have the same effect as the application of the tactic.
 You can call a tactic simply by giving the corresponding
 (possibly parametrised) Prolog call $U$.
 If you call a user defined tactic in the short version,
 the resulting refinement is neither stored nor in any
 way documented. Reproving the proof tree would require in
 this case fully executing the tactic, i.e. running through
 the whole search space again. This may cause serious troubles
 if the tactic has changed in the meantime. Thus you should
 use the short form only for calling fixed tactics or tactics
 which have no effect at all.
 Tactics which do not have any effect at all
 can be used in connection with the $tacticals$ and to build
 conditional tactics: 
 \begin{verbatim}
       repeat (\+ goal(_ => void) then intro)
 \end{verbatim}
 Is an example for a tactic which works like $repeat\; intro$
 except that it does not apply \emph{intro} on negations.
       
 If you call a tactic in the
 long form $tactic(U,X)$ with an unbound variable as second
 parameter, the tactic is executed and the resulting refinement
 is stored in the proof tree. But if you use a tactic of the
 form $tactic(U,X)$ in the $then$ or $repeat$ branch of a
 tactical construct, the result of the tactic application can't
 be stored, because it would be different in different branches. 
 If you use the long form tactic specification on the ground
 level, it is expanded and stored in the expanded form.
 In this case reproving would
 not require a reexecution of the tactic, it would simply
 apply the resulting refinement directly - so you can save
 time if the search space is very large.
 The long form of a tactic application is furthermore
 an appropriate tool for debugging tactics.
  
\begin{sf}\begin{tabbing}
$\models$(tactic(U,R),$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,tactic(U,R),E,S)):- \\[-0.15ex]
\hspace{2em}var(R),tactic(U,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,R,E,S)),!.\\[-0.15ex]
$\models$(tactic(U,R),$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,tactic(U,R),E,S)):-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(R),$\models$(R,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,\_\hspace{0.1em},E,S)),!.\\[-0.15ex]
\hspace{0em}\\[-0.15ex]
$\models$(U,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,U,E,S)):-\\[-0.15ex]
\hspace{2em}functor(U,F,\_\hspace{0.1em}), $\backslash$+ rulename(F), \\[-0.15ex]
\hspace{2em}$\backslash$+ member(F, [then,or,repeat,complete,try,idtac,undo,tactic]),\\[-0.15ex]
\hspace{2em}tactic(U,$\pi$(G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(G,\_\hspace{0.1em},E,S)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \small
 \ulinv{tactic}
\begin{sf}\begin{tabbing}
tactic(U,Q,QQ):-\\[-0.15ex]
\hspace{1em}$\vartheta_{\it thm}$=:N,N=..N1,genint(I),append(N1,[I],N2),NN=..N2, $\backslash$+ $\vartheta_{\it theorem}$(NN)=:\_\hspace{0.1em}, \\[-0.15ex]
\hspace{1em}$\vartheta_{\it pos}$(NN):=[], $\vartheta_{\it theorem}$(NN):=Q, \\[-0.15ex]
\hspace{1em}$\vartheta_{\it universe}$=:CU, $\vartheta_{\it autotactic}$=:CA, $\vartheta_{\it status}$=:CS,\\[-0.15ex]
\hspace{1em}defaultautotactic =: DA,\\[-0.15ex]
\hspace{1em}select(NN),\\[-0.15ex]
\hspace{1em}$\vartheta_{\it universe}$:=CU, $\vartheta_{\it autotactic}$:=CA, $\vartheta_{\it status}$:=CS,\\[-0.15ex]
\hspace{1em}defaultautotactic:=CA,\\[-0.15ex]
\hspace{1em}(call(U),!,T=succeeds; T=fails),\\[-0.15ex]
\hspace{1em}defaultautotactic:=DA,\\[-0.15ex]
\hspace{1em}$\vartheta_{\it theorem}$(NN)=:Q0, $\vartheta_{\it theorem}$(NN):=\_\hspace{0.1em},\\[-0.15ex]
\hspace{1em}$\vartheta_{\it universe}$=:CU2, $\vartheta_{\it autotactic}$=:CA2, $\vartheta_{\it status}$=:CS2,\\[-0.15ex]
\hspace{1em}select(N),!,\\[-0.15ex]
\hspace{1em}$\vartheta_{\it universe}$:=CU2, $\vartheta_{\it autotactic}$:=CA2, $\vartheta_{\it status}$:=CS2,\\[-0.15ex]
\hspace{1em}T=succeeds,fold(Q0,QQ).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{fold}
\begin{sf}\begin{tabbing}
fold($\pi$(P,R,\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(P,idtac,X, [$\pi$(P,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} X])):-var(R),!.\\[-0.15ex]
fold($\pi$(P,R,E,[]),$\pi$(P,R,E,[])):-!.\\[-0.15ex]
fold($\pi$(H==$>$G,R,E,S),$\pi$(H==$>$G,R0,EE,SS)):-\\[-0.15ex]
\hspace{1em}fold(E,S,EE,SS,RR),(idtaclist(RR),R0=R;R0=(R then RR)),!.\\[-0.15ex]
\hspace{1em}\\[-0.15ex]
fold(E,[],E,[],[]).\\[-0.15ex]
fold(E,[$\pi$(HH==$>$G,R,E1,S1) \mbox{\it ext} E0$\mid$T],EE,S,[R0$\mid$RR]):-\\[-0.15ex]
\hspace{1em}fold($\pi$(HH==$>$G,R,E1,S1),$\pi$(\_\hspace{0.1em},R0,E0,S2)), \\[-0.15ex]
\hspace{1em}fold(E,T,EE,SS,RR),append(S2,SS,S).\\[-0.15ex]
fold(E,[$\pi$(HH==$>$G,R,E1,S1)$\mid$T],EE,S,[R0$\mid$RR]):-\\[-0.15ex]
\hspace{1em}fold($\pi$(HH==$>$G,R,E1,S1),$\pi$(\_\hspace{0.1em},R0,\_\hspace{0.1em},S2)), \\[-0.15ex]
\hspace{1em}fold(E,T,EE,SS,RR),append(S2,SS,S).\\[-0.7ex]
\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{idtaclist}
\begin{sf}\begin{tabbing}
idtaclist([]).\\[-0.15ex]
idtaclist([idtac$\mid$X]):-idtaclist(X).
\end{tabbing}\end{sf}

 \normalsize
  
 \item
 Utility predicates needed:
 \small
 \ulinv{provelist}
\begin{sf}\begin{tabbing}
$\models'$(\_\hspace{0.1em},E,S,E,S):-var(S).\\[-0.15ex]
$\models'$(\_\hspace{0.1em},E,[],E,[]).\\[-0.15ex]
$\models'$([T$\mid$TT],E,[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} E0$\mid$R],EE,Q):- !,\\[-0.15ex]
\hspace{2em}$\models$(T,$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},E0,S1)), \\[-0.15ex]
\hspace{2em}$\models'$(TT,E,R,EE,S2), append(S1,S2,Q).\\[-0.15ex]
$\models'$([T$\mid$TT],E,[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em})$\mid$R],EE,Q):- !,\\[-0.15ex]
\hspace{2em}$\models$(T,$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S1)), \\[-0.15ex]
\hspace{2em}$\models'$(TT,E,R,EE,S2),append(S1,S2,Q).\\[-0.15ex]
$\models'$(T,E,[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} E0$\mid$R],EE,Q):- \\[-0.15ex]
\hspace{2em}copy(T,TT),$\models$(T,$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},E0,S1)), \\[-0.15ex]
\hspace{2em}$\models'$(TT,E,R,EE,S2), append(S1,S2,Q).\\[-0.15ex]
$\models'$(T,E,[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em})$\mid$R],EE,Q):- \\[-0.15ex]
\hspace{2em}copy(T,TT),$\models$(T,$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),$\pi$(\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S1)),\\[-0.15ex]
\hspace{2em}$\models'$(TT,E,R,EE,S2),append(S1,S2,Q).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{makesubgoals}
\begin{sf}\begin{tabbing}
${\it subgoals}$(\_\hspace{0.1em},[],[]).\\[-0.15ex]
${\it subgoals}$(H0,[==$>$G \mbox{\it ext} T$\mid$L],[$\pi$(H0==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} T$\mid$LL]):-\\[-0.15ex]
\hspace{2em}!,${\it subgoals}$(H0,L,LL).\\[-0.15ex]
${\it subgoals}$(H0,[==$>$G$\mid$L],[$\pi$(H0==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em})$\mid$LL]):-\\[-0.15ex]
\hspace{2em}!,${\it subgoals}$(H0,L,LL).\\[-0.15ex]
${\it subgoals}$(H0,[-(TL)==$>$G \mbox{\it ext} T$\mid$L],[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} T$\mid$LL]):-\\[-0.15ex]
\hspace{2em}!,thin\_\hspace{0.1em}hyps(TL,H0,HH),${\it subgoals}$(HH,L,LL).\\[-0.15ex]
${\it subgoals}$(H0,[+(TL)==$>$G \mbox{\it ext} T$\mid$L],[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} T$\mid$LL]):-\\[-0.15ex]
\hspace{2em}!,replace\_\hspace{0.1em}hyps(TL,H0,HH),${\it subgoals}$(HH,L,LL).   \\[-0.15ex]
${\it subgoals}$(H0,[H==$>$G \mbox{\it ext} T$\mid$L],[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}) \mbox{\it ext} T$\mid$LL]):-\\[-0.15ex]
\hspace{2em}!,append(H0,H,HH),${\it subgoals}$(H0,L,LL).\\[-0.15ex]
${\it subgoals}$(H0,[H==$>$G$\mid$L],[$\pi$(HH==$>$G,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em})$\mid$LL]):-\\[-0.15ex]
\hspace{2em}!,append(H0,H,HH),${\it subgoals}$(H0,L,LL).
\end{tabbing}\end{sf}

 Note the special forms of hypothesis list modifications returnable
 by a rule: $-(Tlist)$ is a list of hypotheses to be thinned out for
 the subproblems, $+(Hyps)$ is a list of hypotheses to \emph{replace}
 those of the same name in the subproblems.
 
 \normalsize
 \end{itemize}
  
 \subsection{Shorthand Notations}
 There are several shorthand notations for rules and tacticals,
 which simply allow you to avoid unnecessary writing of $apply$.
 There are no shorthand notations for pseudotactics.
 \small
 \ulinv{intro}
\begin{sf}\begin{tabbing}
intro:-apply(intro).\\[-0.15ex]
intro(X):-apply(intro(X)).\\[-0.15ex]
intro(X,Y):-apply(intro(X,Y)).\\[-0.15ex]
intro(X,Y,Z):-apply(intro(X,Y,Z)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{elim}
\begin{sf}\begin{tabbing}
elim(X):-apply(elim(X)).\\[-0.15ex]
elim(X,Y):-apply(elim(X,Y)).\\[-0.15ex]
elim(X,Y,Z):-apply(elim(X,Y,Z)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{equality}
\begin{sf}\begin{tabbing}
equality:-apply(equality).\\[-0.15ex]
equality(X):-apply(equality(X)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{decide}
\begin{sf}\begin{tabbing}
decide(X):-apply(decide(X)).\\[-0.15ex]
decide(X,Y):-apply(decide(X,Y)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{simplify}
\begin{sf}\begin{tabbing}
simplify:-apply(simplify).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{compute}
\begin{sf}\begin{tabbing}
compute(X):-apply(compute(X)).\\[-0.15ex]
compute(hyp(X),Y):-apply(compute(hyp(X),Y)).\\[-0.15ex]
compute(hyp(X),Y,Z):-apply(compute(hyp(X),Y,Z)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{reduce}
 \ulinv{reduce}
\begin{sf}\begin{tabbing}
reduce(X):-apply(reduce(X)).\\[-0.15ex]
reduce(X,Y):-apply(reduce(X,Y)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{subst}
\begin{sf}\begin{tabbing}
subst(over(V,X),Y):-apply(subst(over(V,X),Y)).\\[-0.15ex]
subst(over(V,X),Y,Z):-apply(subst(over(V,X),Y,Z)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{seq}
\begin{sf}\begin{tabbing}
seq(X):-apply(seq(X)).\\[-0.15ex]
seq(X,Y):-apply(seq(X,Y)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{thin}
\begin{sf}\begin{tabbing}
thin(L) :- apply(thin(L)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{hyp}
\begin{sf}\begin{tabbing}
hyp(X):-apply(hyp(X)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{arith}
\begin{sf}\begin{tabbing}
arith:-apply(arith).\\[-0.15ex]
\hspace{2em}
\end{tabbing}\end{sf}

 \ulinv{unroll}
\begin{sf}\begin{tabbing}
unroll(X):-apply(unroll(X)).\\[-0.15ex]
unroll(X,Y):-apply(unroll(X,Y)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{repeat}
\begin{sf}\begin{tabbing}
T1 then T2:-apply(T1 then T2).
\end{tabbing}\end{sf}

 \ulinv{or}
\begin{sf}\begin{tabbing}
T1 or T2:-apply(T1 or T2).
\end{tabbing}\end{sf}

 \ulinv{repeat}
\begin{sf}\begin{tabbing}
repeat T:-apply(repeat T).
\end{tabbing}\end{sf}

 \ulinv{complete}
\begin{sf}\begin{tabbing}
complete T:-apply(complete(T)).
\end{tabbing}\end{sf}

 \ulinv{try}
\begin{sf}\begin{tabbing}
try T:-apply(try T).
\end{tabbing}\end{sf}

 \ulinv{pure}
\begin{sf}\begin{tabbing}
pure(X):-apply(pure(X)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \normalsize 
  
  
 \chapter{The Rule Base}
 
 This chapter defines the rule base of the type theoretic
 logic under consideration. The rules are presented 
 exactly in their internal representation. 
 This has the important advantage that there is
 absolutely no difference between the logic documented and
 the logic implemented. In fact this document is not
 only a reference manual, but the precise and executable
 formal specification of a logical system: at least
 one step to increase the reliability of theorem proving
 and more general reasoning systems. Hopefully the 
 use and (proof) reading of this documentation
 will increase the reliability of the 
 implementation much more than only closed shop debugging
 and will increase your confidence in the implementation as well.
  
 \section{Overview}
 This chapter contains the definition of the $\vdash$-predicate.
 The $\vdash$-predicate is called with three parameters:
 \begin{enumerate}
 \item
 The \emph{rule specification} (intro, elim(x), ...),
 used directly for calling the inference rule. 
 If there are several different inference rules applicable in one
 situation then these inference rules have different specifications.
 On the other hand, the rule specification is chosen in such
 a way that semantically similar rules have the same
 specification. The rule parameters $at(I)$ and $new[x,...]$
 are in all cases optional. 
 Please pay attention, that new variables
 have to be supplied always as a list. $new$ is defined as key word
 for reasons of simplicity. 
 \inv{operator declarations} \ulinv{new}
\begin{sf}\begin{tabbing}
?- op(100,fx,['new']).
\end{tabbing}\end{sf}

 New variables are always generated
 from the sequence $v0, v1, v2, ...$ avoiding identifier clashes.
 The default universe level is taken from the proof tree in
 a similar way as the autotactic.
 The specification of a rule may be simplified using Prolog
 variables, which is especially valuable in the case of the
 $subst$ and $compute$ rules. This approach allows the reusability 
 of rules in a different context. However rules are always called on 
 a copy of the rule specification. As a result variable bindings
 may only be used inside a single rule specification to formalise
 structural restriction on the parameters, you will never get the
 values assigned to the variables outside the $\vdash$-predicate.
 \item
 A pattern of the form $H==>G\; \mbox{\it ext} \; E$, where $H$ denotes the
 current \emph{hypothesis list}, $G$ is a pattern for the current
 \emph{goal} and $E$ describes the \emph{extract term} generated by this
 inference rule. 
 In the case of membership or equality goals, as well as in
 goals of the form $A$$<$$B$ or $A$$<=B$ , the specification 
 of the extract term is omitted, because in these cases the
 extract term is always equal to \emph{axiom}.
 The application of an inference rule is
 possible only if the current goal matches $G$.
 The selection of an inference 
 rule is driven by the rule specification and the structure
 of the current goal.
 $H$ refers to a Prolog list of hypotheses, i.e. either
 definitions, references to other theorems or assumptions 
 of the form $x:h_x$,
 which you should read as \emph{"let x be an arbitrary element
 of the type $h_x$"}, where $h_x$ either is a type in the
 traditional sense or any proposition. In the last case you may 
 think of $x$ as the name of the proposition, but in fact 
 $x$ is an arbitrary element, i.e. a proof of that proposition.
 The current goal $G$ always is a type, which will be
 refined during the process of proof. If you think of $G$ as a
 proposition this refinement yields a proof. If you think of $G$
 as a traditional type, this refinement results in an element of
 that type (program).
 The extract term $E$ is either a ground term (like $axiom$)
 or contains variables which are connected to the extract
 terms provided by the proofs of the subgoals. The extract term
 is always of the type of the current goal. For each form of terms
 of the type theoretic language there is at least one rule which
 produces an extract term of this form.
 \item
 A list of \emph{subgoals}, the elements of which are
 either of the form $H_i==>G_i$, if their proof does not 
 contribute to
 the extract term of the current inference rule, or of the form
 $H_i==>G_i\; \mbox{\it ext} E_i$
 consisting of the subgoal and a variable representing
 the extract term provided by that subgoal. The inference rules
 describe only the increment to the hypotheses, i.e. additional
 properties which are available for the proof of the corresponding
 subgoals. If there are no additional hypotheses $H_i$
 is omitted completely. 
 \end{enumerate}
  
 The rule base is divided into sections each describing a 
 basic type or a (family of) type constructors
 (\emph{lists, products, unions,...}).
 Each section starts with a short motivation
 and an overview of the intended meaning of that type.
 The sections are divided into subsections 
 \emph{Type Formation}, \emph{Constructors}, and \emph{ Selectors}
 which consist of the inference rules. 
 Strictly speaking the subsections \emph{Type Formation} should
 be considered as part of the \emph{Constructors} for universes.
 They are distributed only for reasons of better readability.
 The inference rules itself are classified 
 (as \emph{refinement/realisation rules,}
 \emph{ membership rules}, or \emph{ equality rules}) and 
 informally commented. These comments have
 no further formal role and can be ignored. The idea behind these
 comments was to clarify the meaning and possible ways of
 application of the inference rule to the inexperienced
 user. If there is a number in front of a rule, this number
 gives a reference to the corresponding rule in [2]
 We distinguish the following sorts of rules:
 \begin {itemize}
 \item
 {\bf {\large Constructor Rules}} 
 \inv{constructor rules}
 \begin{enumerate}
 \item
 {\bf refinement/realisation rules:}
 \inv{refinement rules} \inv{realisation rules}
 They describe the ways for straight forward refinement of
 the proof. The main result in applying such a rule is the
 \emph{refinement} of the extract term of the top level goal, 
 corresponding to the refinement step connected with the rule.
 The extract terms generated by proving the subgoals have a direct 
 influence on the extract term of the refinement rule. 
 Realisation rules describe a the expllicite generation of a 
 realisation of the goal, i.e. they produce a complete extract term.
 \item
 {\bf membership rules:}
 \inv{membership rules}
 They are applicable to goals of the form $A\; in \; T$ only.
 Their aim is to prove that the fully refined term $A$ is
 in fact a member of $T$. The extract term of such a proof is
 always $axiom$ (and therefore generally omitted in the 
 description of the rules). 
 The membership rules for $universes$, i.e.
 the rules which apply to goals of the form $A\; in\; u(i)$,
 are sometimes also called \emph{well-formedness} rules.
 To avoid the application of membership rules on equalities
 the membership rules are (if necessary)
 guarded by the $noequal$ predicate:
 \ulinv{noequal}
\begin{sf}\begin{tabbing}
noequal(\_\hspace{0.1em}=\_\hspace{0.1em}):-!,fail.\\[-0.15ex]
noequal(\_\hspace{0.1em}).
\end{tabbing}\end{sf}

 \item
 {\bf equality rules:}
 \inv{equality rules}
 They are applicable only to goals of the form $A=B \; in \; T$.
 There is one general equality rule at the end of the rule
 base which catches all equalities of the form $A=A' \; in \; T$
 where $A$ and $A'$ are syntactically equivalent (more formally
 speaking $A$ and $A'$ are $\alpha$-convertible).
 That is why only non trivial equality rules are given explicitly.
 There are two types of equality rules: equality rules for
 types of the form $A=B\; in\; u(i)$
 (in the section \emph{Type Formation}) and equality rules for 
 members of a type $T$ (in the section \emph{Constructors}).
 Both sections logically should contain the corresponding 
 equality rules. If there is no explicit equality rule, the
 catch all rule applies.
 \end{enumerate}
 \item
 {\bf {\large Selector Rules}}
 \inv{selector rules}
 \begin{enumerate}
 \item
 {\bf refinement rules:}
 \inv{refinement rules}
 The refinement rules for selectors are \emph{elim} rules
 or \emph{decide} rules. The \emph{elim} rules exploit the
 structural properties of the type of a variable in the
 hypothesis list for generating a \emph{selector} construct 
 which is able to handle the general case. 
 The \emph{decide} rules
 correspond to decidable basic predicates and yield the appropriate
 decision operator as extract term.
 These rules correspond only two partial refinements of the
 extract terms, therefore there are no realisation rules for 
 selectors.
    
 \item
 {\bf membership rules:}
 \inv{membership rules}
 The membership rules for selectors are the most difficult 
 ones because of the rich type structure. 
 Suppose you have a goal of the form $H==>sel(E,...)\;in\;T$,
 with $E$ being a possibly deeply structured term the type of
 which, say $T'$ is not obvious, and with $T$ being an instantiation
 of a type scheme, depending on the current value of $E$.
 To deal with this situation, you have to use a 
 \emph{membership rule} of the form $intro(using(T'),over(z,T_z))$,
 where $using(T')$ reflects your assumptions  about the intended 
 semantics of $E$, and a $over(z,T_z)$ describes a type scheme,
 which (instantiated with $E$) would yield $T$.
 In most cases there is no direct
 depency between the type $T$ of the induction term and the current
 value of the base term $E$. To simplify
 the automatic proof of these wellformedness goals there is
 usually 
 \inv{derived rule}
 a \emph{derived rule}, which assumes the result type to be constant.
 If you have really nontrivial wellformedness goals to prove,
 you should switch the system into the \emph{pure} mode, and
 supply the type pattern explicitly. But this could be done
 by a user defined tactic. Still there is the problem of
 supplying the type information for the base term. For the
 simplest case, that the base term is a single variable, which
 is declared in the hypothesis list, there is again a \emph{derived 
 rule} which simply accesses the declaration from the hypothesis
 list for generating the type of the base term.
 
 \item
 {\bf equality rules:}
 \inv{equality rules}
 The equality rules for selector terms do not describe the
 equality between to selctor terms, but the possible ways
 of \emph{reducing} the selector terms to simpler ones.
 These equality rules are usually specified in the form
 \emph{reduce(...)} with a goal of the structure 
 $H==>sel(E,...)=E'\;in\;T$. From theire nature they should be
 considered as \emph{conditional rewriting rules}. They are not
 automatically aplicable because one need a guess, which of
 the possible preconditions are valid, and therefore in which
 way the rewriting should work. \emph{Unconditional rewrite rules}
 are not explicitly given in this chapter, they are available
 as shorthand notations for \emph{term rewriting rules} (see
 chapter 5).
 \end{enumerate}
 \end{itemize}
 
 There are some
 rules in the system, which are from their nature efficiency
 rules. These rules may be deactivated by running the \emph{inference
 engine} in the $pure$ mode. They are marked
 with a special $\circ$. The $derived$ predicate deactivates
 these rules in the $pure$ mode.
 The $rulename$ predicate is used to shorten the search process
 in the case of errors. Ensure that the list of rule names
 is really complete all the time.
  
 \ulinv{rulename}
\begin{sf}\begin{tabbing}
rulename(X):-\\[-0.15ex]
\hspace{2em}member(X, [intro, elim, reduce, decide, equality, unroll, hyp, seq,\\[-0.15ex]
\hspace{7em}lemma, def, subst, compute, normalise, simplify, arith, thin, because]).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{derived}
\begin{sf}\begin{tabbing}
derived:-$\vartheta_{\it status}$=:nonpure.\\[-0.7ex]

\end{tabbing}\end{sf}

 \begin{itemize}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,H==$>$G \mbox{\it ext} X,[]):-\\[-0.15ex]
\hspace{2em}{\bf derived},decl(X:GG,H),$\alpha$(G,GG).
\end{tabbing}\end{sf}

 \end{itemize} 
  
  
 \section{Atom}
 \inv{atom type}
  
 The type $atom$ is provided to model character strings. The elements
 of the type $atom$ are arbitrary, possibly empty  strings $'...'$,
 which are (for reasons of syntactical uniqueness) represented in the
 form $atom('...')$. 
 The equality of the canonical elements of the type $atom$
 is effectively decidable, i.e. it forms a basic computational
 operation. Therefore there is a decision operator $atom\_eq(a,b,s,t)$,
 which is defined to be $s$ if $a=b\;in\;atom$ and $t$ otherwise .
  
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1] 
\begin{sf}\begin{tabbing}
$\vdash$(intro(atom),\_\hspace{0.1em}==$>$u(\_\hspace{0.1em}) \mbox{\it ext} atom,[]).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
 $atom$ is a realisation for any universe
  
 \item[2] 
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$atom in u(\_\hspace{0.1em}),[]).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $atom$ is a type, i.e. member of any universe.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[3] 
\begin{sf}\begin{tabbing}
$\vdash$(intro(atom(A)),\_\hspace{0.1em}==$>$atom \mbox{\it ext} atom(A),[]):-atom(A).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
 atoms $atom(A)$ are possible realisations for the type $atom$.
  
 \item[4] 
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$atom(A) in atom,[]):-atom(A).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 Terms of the form $atom(A)$ are elements of the type $atom$.
 \end{enumerate}
  
 \subsection{Selectors}
  
 \begin{enumerate}
 \item[$\bullet$] 
\begin{sf}\begin{tabbing}
$\vdash$(decide(X=Y in atom,new[U]),\\[-0.15ex]
\hspace{2em}H==$>$T \mbox{\it ext} atom\_\hspace{0.1em}eq(X,Y,$\sigma$(E1,[axiom],[U]),$\sigma$(E2,[lambda({\verb`~`},axiom)],[U])),\\[-0.15ex]
\hspace{2em}[ [U:X=Y in atom]==$>$T \mbox{\it ext} E1, \\[-0.15ex]
\hspace{2em}[U:X=Y in atom=$>$void]==$>$T \mbox{\it ext} E2,\\[-0.15ex]
\hspace{3em}==$>$X in atom,\\[-0.15ex]
\hspace{3em}==$>$Y in atom]):-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(X), $\backslash$+ var(Y),syntax(H,X),syntax(H,Y),free([U],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The decision operator may be used as a refinement for any
 $T$, provided both the $then$ and the $else$ part are refinements
 of $T$. This rule gives you the possibility of introducing 
 case analysis in the current proof.
  
 \item[5] 
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Z]),H==$>$atom\_\hspace{0.1em}eq(A,B,X,Y) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$A in atom, ==$>$B in atom,\\[-0.15ex]
\hspace{2em}[Z:A=B in atom]==$>$X in T, \\[-0.15ex]
\hspace{2em}[Z:A=B in atom=$>$void]==$>$Y in T ]):-\\[-0.15ex]
\hspace{2em}free([Z],H).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The decision operator is an element of any type $T$,
 provided both the $then$ and the $else$ part of the decision
 operator are elements of $T$.
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(true),\_\hspace{0.1em}==$>$atom\_\hspace{0.1em}eq(A,B,X,Y)=X in T, \\[-0.15ex]
\hspace{2em}[ ==$>$X in T, ==$>$Y in T, ==$>$A=B in atom ]).\\[-0.15ex]
$\vdash$(reduce(false),\_\hspace{0.1em}==$>$atom\_\hspace{0.1em}eq(A,B,X,Y)=Y in T, \\[-0.15ex]
\hspace{2em}[ ==$>$X in T, ==$>$Y in T, ==$>$A=B in atom =$>$ void ]).
\end{tabbing}\end{sf}

 {\bf equality rules:}
 These rules allow the reduction of the current goal, if you
 can prove the preconditions necessary for this simplifications.
 \end{enumerate}
  
 \inv{Unary type}
  
 The type $unary$ is provided in order to satisfy a requirement
 for a type inhabited by only a single term that arises when
 recursive types are constructed.   It is also a convenient way of
 representing a trivially inhabitted type (and hence true judgement).
 The only term inhabiting $unary$ is $unit$.
 
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1] 
\begin{sf}\begin{tabbing}
$\vdash$(intro(unary),\_\hspace{0.1em}==$>$u(\_\hspace{0.1em}) \mbox{\it ext} unary,[]).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
 $unary$ is a realisation for any universe
  
 \item[2] 
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$unary in u(\_\hspace{0.1em}),[]).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $unary$ is a type, i.e. member of any universe.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[3] 
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$unary \mbox{\it ext} unit,[]).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
 $axiom$ is a realisation of the type $unary$.
  
 \item[4] 
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$unit in unary,[]).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 Terms of the form $unit$ are elements of the type $unary$.
 \end{enumerate}
  
 \subsection{Selectors}
  
 \begin{enumerate}
 \item[5] 
\begin{sf}\begin{tabbing}
$\vdash$(elim(X), H==$>$T \mbox{\it ext} E, [==$>$TT \mbox{\it ext} E] ) :-\\[-0.15ex]
\hspace{2em}decl(X:unary,H),\\[-0.15ex]
\hspace{2em}s( T, [unit], [X], TT ).\\[-0.7ex]

\end{tabbing}\end{sf}

 \end{enumerate}
 \section{Void}
 \inv{void type}
  
 The type $void$ is empty, i.e. there are no members of $void$. 
 Assuming the underlying proposition as type paradigm $void$
 may be regarded as any unprovable proposition. A hypothesis
 of the form $x:void$ stating that $void$ is inhabited by $x$
 is the typical form of stating a contradiction.
 From such a contradiction you can derive any goal. The
 symbolic extract term $any(x)$ is member of any type, if
 $x$ is a member of $void$.
 
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(void),\_\hspace{0.1em}==$>$u(\_\hspace{0.1em}) \mbox{\it ext} void,[]).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
 $void$ is a realisation for any universe.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$void in u(\_\hspace{0.1em}),[]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $void$ is a type, i.e. a member 
 of any universe.
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(elim(X),H==$>$\_\hspace{0.1em} \mbox{\it ext} any(X),[]):- decl(X:void,H).
\end{tabbing}\end{sf}

 {\bf refinement rule:} 
 a hypothesis stating that $void$
 is inhabited by some $X$ is the incarnation of a contradiction.
 From such a contradiction you can prove anything. This is
 reflected in the extract term. 
  
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$any(X) in \_\hspace{0.1em}, [ ==$>$X in void]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $any(X)$ is a fictive  
 member of each type indicating which contradiction $X$
 was exploited by the proof.
 \end{enumerate}
  
  
 \section{Pnat}
 \inv{pnat type} \inv{natural numbers}
  
 The type $pnat$ supplies the natural numbers with Peano arithmetic.
 The canonical elements of $pnat$ are $0$ and terms of the form
 $s(...)$, where $s$ is the successor function on natural numbers.
 Inductive definition terms have the form $p\_ind(x,a,[u,v,t])$.
 They define the result of a mapping from $pnat$ into some other
 type $T$. The terms $a$ and $t$ have to be of the type $T$, $u$ and
 $v$ are free variables in $t$, and it is assumed that $u$ ranges
 over $pnat$ and that $v$ ranges over $T$. If $x=0\; in\; pnat$ the
 inductive definition term is defined to be equal to $a$. If $x$
 has the form $s(x')$, then the inductive definition term is
 defined to be equal to the value of $s$, if $u$ is set to $x'$ and 
 $v$ is set to the value of the inductive definition term for $x'$.
 Let us consider two examples. 
 \begin{itemize}
 \item
 The predecessor of $y$ could be defined as 
 $p\_ind(y,0,[u,\verb'~',u])$,
 \footnote{the defining occurrences of bound variables which do not 
 appear in their scope may be omitted, i.e. you can write instead of
 a senseless variable name a tilde. You should use 
 this convention as far as possible, to avoid unnecessary confusion 
 to other persons,
 and to improve the systems behaviour, because it is obvious that
 no substitution has to be carried out in this case.}
 i.e. it is set to $u$ if $y$
 has the form $s(u)$ and is defined to be $0$ for $0$. 
 Please note, that such an inductive definition term defines only
 a single value. If you want to describe the predecessor \emph{function}
 you have to use a $\lambda$-construction 
 $lambda(y,p\_ind(y,0,[u,\verb'~',u]))$ (see below). Note furthermore,
 that inductive definition terms, like all other terms, are always 
 \emph{totally defined}. There
 is no way of specifying partial constructs, you always have to 
 define the value for all cases.
 \item
 The embedding of a natural number $n$ in their peano interpretation
 into the integers is defined by $p\_ind(n,0,[\verb'~',u,u+1])$, i.e.
 the element $0$ of $pnat$ is mapped into $0$ in $int$ and a
 term of the form $s(i)$ is mapped into $u+1$, if $i$ is mapped into
 $u$. 
 \end{itemize}
  
  
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(pnat),\_\hspace{0.1em}==$>$u(\_\hspace{0.1em}) \mbox{\it ext} pnat,[]).
\end{tabbing}\end{sf}

 {\bf realisation rule:} $pnat$ is a realisation for any universe.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$pnat in u(\_\hspace{0.1em}),[]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $pnat$ is a type, i.e. a member 
 of any universe.
 \end{enumerate}
  
 \subsection{Constructors}
 \begin{enumerate}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(0),\_\hspace{0.1em}==$>$pnat \mbox{\it ext} 0,[]).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
 $0$ is a realisation for the type $pnat$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$0 in pnat,[]).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $0$ is an element of $pnat$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(s),\_\hspace{0.1em}==$>$pnat \mbox{\it ext} s(X), [ ==$>$pnat \mbox{\it ext} X ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} 
 $s(...)$ is a partial refinement for the type $pnat$,
 leaving the refinement of the predecessor open. 
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$s(X) in pnat, [ ==$>$X in pnat ]).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $s(X)$ is an element of $pnat$, if $X$ is an element of $pnat$.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(s),\_\hspace{0.1em}==$>$X=Y in pnat, [ ==$>$s(X)=s(Y) in pnat ]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 To prove that $X$ and $Y$ are equal in $pnat$,
 it is sufficient to prove that the successors of $X$ and $Y$ are equal in 
 $pnat$. 
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(elim(X,new[U,V]),H==$>$T \mbox{\it ext} p\_\hspace{0.1em}ind(X,T0,[U,V,Ts]),\\[-0.15ex]
\hspace{2em}[ ==$>$TT0 \mbox{\it ext} T0, \\[-0.15ex]
\hspace{3em}[U:pnat,V:TTu]==$>$Tsu \mbox{\it ext} Ts ]):-\\[-0.15ex]
\hspace{2em}decl(X:pnat,H),free([U,V],H,HH),s(T,[s(U)],[X],Tsu), \\[-0.15ex]
\hspace{2em}shyp(HH,HH==$>$T,[0],[X],\_\hspace{0.1em}==$>$TT0), shyp(HH,HH==$>$T,[U],[X],\_\hspace{0.1em}==$>$TTu).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of the type $pnat$ in
 the hypothesis list, generates an \emph{induction} term, the 
 further refinement of which is determined by the subgoals
 of the \emph{elim} step.
\begin{sf}\begin{tabbing}
$\vdash$(elim(X,cv,new[U,V,W]),H==$>$ T \mbox{\it ext} cv\_\hspace{0.1em}ind(X,[W,U,Ts]),\\[-0.15ex]
\hspace{2em}[ [W:pnat,U:(V:\{V:pnat $\backslash$ V $<$* W\}=$>$Tsv)] ==$>$ Tsw \mbox{\it ext} Ts] ) :-\\[-0.15ex]
\hspace{2em}decl(X:pnat,H),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(T, [V], [X], Tsv ),\\[-0.15ex]
\hspace{2em}s(T, [W], [X], Tsw ).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 This rule implements course-of-values induction.  Instead of a simple
 induction hypothesis, an induction hypothesis scheme for the goal
 with the elim-ed variable replaced by any smaller peano natural number.
 
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(over(Z,T),new[U,V]),H==$>$p\_\hspace{0.1em}ind(E,T0,[X,Y,Ts]) in Te,\\[-0.15ex]
\hspace{2em}[ ==$>$E in pnat, ==$>$T0 in To, [U:pnat,V:Tu]==$>$TTs in Tsu ]):-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),free([U,V],H),\\[-0.15ex]
\hspace{2em}s(T,[E],[Z],Te),s(T,[s(U)],[Z],Tsu),\\[-0.15ex]
\hspace{2em}s(T,[0],[Z],To),s(T,[U],[Z],Tu),s(Ts,[U,V],[X,Y],TTs). 
\end{tabbing}\end{sf}

 {\bf membership rule:}
 An \emph{induction term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_e$ is an
 instantiation of that type scheme for $E$ and the subterms of
 the induction term can be proven to be in the corresponding
 instantiations $T_o$ and $T_s$. To simplify
 the automatic proof of these wellformedness goals there is
 a derived rule, which assumes the result type to be constant.
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U,V]),H==$>$p\_\hspace{0.1em}ind(E,T0,[X,Y,Ts]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in pnat, ==$>$T0 in T, [U:pnat,V:T]==$>$TTs in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},free([U,V],H),\\[-0.15ex]
\hspace{2em}s(Ts,[U,V],[X,Y],TTs).
\end{tabbing}\end{sf}

 \end{description}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(over(Z,T),new[U,V,W]),H==$>$cv\_\hspace{0.1em}ind(E,[X,Y,Ts]) in Te,\\[-0.15ex]
\hspace{2em}[ ==$>$E in pnat, \\[-0.15ex]
\hspace{3em}[V:(W:\{U:pnat $\backslash$ U $<$* E\}=$>$ Tsw)]==$>$Tsev in Te ]):-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(T,[E],[Z],Te),\\[-0.15ex]
\hspace{2em}s(Ts,[E,V], [X,Y], Tsev ),\\[-0.15ex]
\hspace{2em}s(T, [W], [Z], Tsw ).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 An \emph{induction term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_e$ is an
 instantiation of that type scheme for $E$ and the subterm of
 the induction term can be proven to be in the corresponding
 $T_s$. To simplify
 the automatic proof of these wellformedness goals there is
 a derived rule, which assumes the result type to be constant.
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U,V,W]),H==$>$cv\_\hspace{0.1em}ind(E,[X,Y,Ts]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in pnat,\\[-0.15ex]
\hspace{3em}[V:(W:\{U:pnat $\backslash$ U $<$* E\}=$>$ T)]==$>$Tsev in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(Ts,[E,V], [X,Y], Tsev ).
\end{tabbing}\end{sf}

 \end{description}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(decide(X=Y in pnat,new[U]),\\[-0.15ex]
\hspace{2em}H==$>$T \mbox{\it ext} pnat\_\hspace{0.1em}eq(X,Y,$\sigma$(E1,[axiom],[U]),$\sigma$(E2,[lambda({\verb`~`},axiom)],[U])),\\[-0.15ex]
\hspace{2em}[ [U:X=Y in pnat]==$>$T \mbox{\it ext} E1, \\[-0.15ex]
\hspace{2em}[U:X=Y in pnat=$>$void]==$>$T \mbox{\it ext} E2 ,\\[-0.15ex]
\hspace{4em}==$>$X in pnat,\\[-0.15ex]
\hspace{4em}==$>$Y in pnat]):-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(X), $\backslash$+ var(Y), syntax(H,X),syntax(H,Y),free([U],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The decision operator for natural number equality may be used as
 a refinement for any type T, provided both, the \emph{then} and 
 the \emph{else} part are refinements of $T$. This rule gives
 you the possibility of introducing a case analysis in the
 current proof.   
 
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new [V]),H==$>$pnat\_\hspace{0.1em}eq(A,B,S,T) in TT,\\[-0.15ex]
\hspace{2em}[ ==$>$A in pnat, ==$>$B in pnat,\\[-0.15ex]
\hspace{3em}[V:A=B in pnat]==$>$S in TT, \\[-0.15ex]
\hspace{3em}[V:A=B in pnat=$>$void]==$>$T in TT ]):-\\[-0.15ex]
\hspace{2em}free([V],H).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The decision operator yields a value of the type $T$, provided
 both the \emph{then} and the \emph{else} part of the decision
 operator are elements of $T$.
 
 \item[11]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(true),\_\hspace{0.1em}==$>$pnat\_\hspace{0.1em}eq(A,B,X,Y)=X in T, \\[-0.15ex]
\hspace{2em}[  ==$>$X in T, ==$>$Y in T,  ==$>$A=B in pnat ]).\\[-0.15ex]
$\vdash$(reduce(false),\_\hspace{0.1em}==$>$pnat\_\hspace{0.1em}eq(A,B,X,Y)=Y in T, \\[-0.15ex]
\hspace{2em}[  ==$>$X in T, ==$>$Y in T, ==$>$A=B in pnat =$>$ void ]).
\end{tabbing}\end{sf}

 {\bf equality rules:}      
 These rules describe value of the decision term under certain
 assumptions. 
 \item[12]
\begin{sf}\begin{tabbing}
$\vdash$(reduce,H==$>$cv\_\hspace{0.1em}ind(E,[X,Y,T] = Tsev in \_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}[ ==$>$ E in pnat ] ) :-\\[-0.15ex]
\hspace{2em}free( [R], H ),\\[-0.15ex]
\hspace{2em}s( T, [E,lambda(R,cv\_\hspace{0.1em}ind(R,[X,Y,T]))], [X,Y], Tsev ).
\end{tabbing}\end{sf}

 {\bf equality rules:}      
 This rule describes the value of the course of values induction
 term under certain assumptions. 
  
 \end{enumerate}
 \section{Pless}
 \inv{pless type scheme}
 $pless$ is a type scheme which is introduced for keeping the
 theoretical system closed. For each $A$ and $B$ of type
 $pnat$ there exists a type $A$$<*$$B$ which is inhabited 
 by $axiom$,if $A$ and $B$ are naturals and $A$ is less then $B$,
 or is empty otherwise. In this sense
 we may assume $axiom$ as the only canonical element of $A$$<*$$B$.
  
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro($<$*),\_\hspace{0.1em}==$>$u(\_\hspace{0.1em}) \mbox{\it ext} A$<$*B, [ ==$>$pnat \mbox{\it ext} A, ==$>$pnat \mbox{\it ext} B ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} $A<*B$ is a refinement for any universe,
 if $A$ and $B$ are refinements of the type $pnat$.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$A$<$*B in u(\_\hspace{0.1em}), [ ==$>$A in pnat, ==$>$B in pnat ]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $A<*B$ is a type of any universe level
 if $A$ and $B$ are elements of the type $pnat$.
  
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$I$<$*J,[]):-pnat(I),pnat(J),pless(I,J).
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 If $I$ and $J$ are canonical members of $pnat$, i.e. natural
 numbers, then $I$$<*J$ is inhabited by $axiom$, if $I$ is less $J$.
  
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$axiom in (A$<$*B), [ ==$>$A$<$*B]).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 Axiom is a canonical member of $A$$<*$$B$, if the type $A$$<*$$B$
 is inhabited at all.
  
 \end{enumerate}
  
 \subsection{Selectors}
  
 \begin{enumerate}
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(decide(X$<$*Y,new[U]),\\[-0.15ex]
\hspace{2em}H==$>$T \mbox{\it ext} pless(X,Y,$\sigma$(E1,[axiom],[U]),$\sigma$(E2,[lambda({\verb`~`},axiom)],[U])),\\[-0.15ex]
\hspace{2em}[ [U:X$<$*Y]==$>$T \mbox{\it ext} E1, \\[-0.15ex]
\hspace{2em}[U:X$<$*Y=$>$void]==$>$T \mbox{\it ext} E2 ,\\[-0.15ex]
\hspace{3em}==$>$ X in pnat,\\[-0.15ex]
\hspace{3em}==$>$ Y in pnat]):-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(X), $\backslash$+ var(Y),syntax(H,X),syntax(H,Y),free([U],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The decision operator for the strict ordering of naturals may be 
 used as a refinement for any type T, provided both, the \emph{then} 
 and the \emph{else} part are refinements of $T$. This rule gives
 you the possibility of introducing a case analysis in the
 current proof.   
  
 \item[11]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new [V]),H==$>$pless(A,B,S,T) in TT,\\[-0.15ex]
\hspace{2em}[ ==$>$A in pnat, ==$>$B in pnat,\\[-0.15ex]
\hspace{3em}[V:A$<$*B]==$>$S in TT, \\[-0.15ex]
\hspace{3em}[V:(A$<$*B=$>$void)]==$>$T in TT ]):-\\[-0.15ex]
\hspace{2em}free([V],H). 
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The decision operator yields a value of the type $T$, provided
 both the \emph{then} and the \emph{else} part of the decision
 operator are elements of $T$.
  
 \item[14]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(true),\_\hspace{0.1em}==$>$pless(A,B,X,Y)=X in T, \\[-0.15ex]
\hspace{2em}[ ==$>$X in T, ==$>$Y in T, ==$>$A$<$*B ]).\\[-0.15ex]
$\vdash$(reduce(false),\_\hspace{0.1em}==$>$pless(A,B,X,Y)=Y in T, \\[-0.15ex]
\hspace{2em}[ ==$>$X in T, ==$>$Y in T, ==$>$A$<$*B=$>$void ]).
\end{tabbing}\end{sf}

 {\bf equality rules:}      
 These rules describe value of the decision term under certain
 assumptions. 
  
 \end{enumerate}
  
 \subsection{Arithmetic}
 The aim of this section is to provide the rule base
 for common arithmetical reasoning. Normally these rules
 will not be used directly, because the built-in tactic
 \emph{arith} solves many of the standard arithmetic problems.
 Nevertheless these explicit \emph{arith}-rules are necessary
 to enable the handling of more difficult arithmetic problems,
 and these rules provide a proper semantic base for the 
 \emph{arith} tactic.  
 \begin{enumerate}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(arith(Y,left),H==$>$X$<$*Z, [ ==$>$Y$<$*X=$>$void, ==$>$Y$<$*Z ]):-\\[-0.15ex]
\hspace{2em}syntax(H,Y).\\[-0.15ex]
$\vdash$(arith(Y,right),H==$>$X$<$*Z, [ ==$>$X$<$*Y, ==$>$Z$<$*Y=$>$void ]):-\\[-0.15ex]
\hspace{2em}syntax(H,Y).\\[-0.15ex]
$\vdash$(arith($<$*), \_\hspace{0.1em}==$>$X$<$*Y, [==$>$A in pnat, ==$>$ B in pnat] ) :-\\[-0.15ex]
\hspace{2em}pdecide( X,Y,less ),\\[-0.15ex]
\hspace{2em}s\_\hspace{0.1em}subterm(X,A), s\_\hspace{0.1em}subterm(Y,B).\\[-0.15ex]
$\vdash$(arith($<$*), H==$>$X$<$*Y=$>$void \mbox{\it ext} lambda(V,V),\\[-0.15ex]
\hspace{8em}[==$>$A in pnat, ==$>$ B in pnat] ) :-\\[-0.15ex]
\hspace{2em}pdecide( X,Y,R ), $\backslash$+ R = less,\\[-0.15ex]
\hspace{2em}free([V],H),\\[-0.15ex]
\hspace{2em}s\_\hspace{0.1em}subterm(X,A), s\_\hspace{0.1em}subterm(Y,B).\\[-0.15ex]
$\vdash$(arith($<$*), \_\hspace{0.1em}==$>$X$<$*Y, [ ==$>$ A$<$*B ] ) :-\\[-0.15ex]
\hspace{2em}s\_\hspace{0.1em}strip( X$<$*Y, A$<$*B ).
\end{tabbing}\end{sf}

  
 \end{enumerate}
 \pagebreak
  
 \section{Int}
 \inv{int type}
 The type $int$ supplies the common integer arithmetic with
 ordering $<$. Terms of the form $A$$<$$B$ 
 define a new class of propositions. They form a
 special class of types (see next section).
 The canonical elements of the type $int$ are the integers
 in the common sense. 
 There are noncanonical constructors for integers: the usual
 arithmetic operations.
 The equality of the canonical elements of the type $int$
 is effective decidable, i.e. it forms a basic computational
 operation. Therefore there is a decision operator $int\_eq(a,b,s,t)$,
 which is defined to be $s$ if $a=b\;in\;int$ and $t$ otherwise .
 The inductive definition terms have the form 
 $ind(x,[a^-,b^-,t^-],t^0,[a^+,b^+,t^+])$. They define the 
 result of a mapping from $int$ into some other type $T$. 
 The terms $t^-$, $t^0$, and $t^+$ have to be of that type $T$,
 $a^-$ and $b^-$ are free variables in $t^-$,
 $a^+$ and $b^+$ are free variables in $t^+$, 
 and $a^\mp$ is assumed to vary over $int$, 
 whereas $b^\mp$ vary over the type $T$.
 If $x$ is less than $0$, $a^-$ is $x$,
 and $b^-$ is the value of that inductive term for $x+1$, then the
 value of this induction definition term for $x$ is defined to be $t^-$.
 If $x=0 \; in\; int$ then the value of the inductive definition term
 is defined to be $t^0$, and if $x$ if greater than $0$, it works
 the other way round: i.e. if $a^+$ is $x$, and $b^+$ is the
 value of the inductive definition term for $x-1$, 
 then the value of the inductive definition term for $x$ is defined
 to be $t^+$. Let us consider some examples:
 \begin{itemize}
 \item
 The \emph{signum} of an integer $p$ could be defined by 
 $ind(p,[\verb'~',\verb'~',-1],0,[\verb'~',\verb'~',1])$;
 \item
 $2^i$ could be described as
 $ind(i,[\verb'~',\verb'~',0],1,[\verb'~',p,2*p])$;
 \item
 and the \emph{factorial} $n!$ could be defined by
 $ind(n,[\verb'~',\verb'~',0],1,[u,f,u*f])$. 
 \end{itemize}
 Again, these inductive definition terms define only single values,
 if you want to describe a function, you have to use $\lambda$-terms.
  
 \subsection{Type Formation}
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(int),\_\hspace{0.1em}==$>$u(\_\hspace{0.1em}) \mbox{\it ext} int,[]).
\end{tabbing}\end{sf}

 {\bf realisation rule:} $int$ is a realisation for any universe.
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$int in u(\_\hspace{0.1em}),[]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $int$ is a type, i.e. a member of any
 universe.
 \end{enumerate}
  
 \subsection{Constructors}
 Constructors for integers are the integer numbers and the usual
 arithmetic operators. The rules are so obvious, they don't
 need any further explanation.
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro(C),\_\hspace{0.1em}==$>$int \mbox{\it ext} C,[]):-var(C),C='$<$integer$>$';integer(C).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
  
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$C in int,[]):-integer(C).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(- {\verb`~`}),\_\hspace{0.1em}==$>$int \mbox{\it ext} -T, [ ==$>$int \mbox{\it ext} T]).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
  
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$ -T in int, [ ==$>$T in int ]).
\end{tabbing}\end{sf}

 {\bf membership rule:}
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(- {\verb`~`}),\_\hspace{0.1em}==$>$ T=TT in int, [ ==$>$ -T = -TT in int]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} + {\verb`~`}),\_\hspace{0.1em}==$>$int \mbox{\it ext} M+N, [ ==$>$int \mbox{\it ext} M, ==$>$int \mbox{\it ext} N ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`} - {\verb`~`}),\_\hspace{0.1em}==$>$int \mbox{\it ext} M-N, [ ==$>$int \mbox{\it ext} M, ==$>$int \mbox{\it ext} N ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`} * {\verb`~`}),\_\hspace{0.1em}==$>$int \mbox{\it ext} M*N, [ ==$>$int \mbox{\it ext} M, ==$>$int \mbox{\it ext} N ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`} / {\verb`~`}),\_\hspace{0.1em}==$>$int \mbox{\it ext} M/N, [ ==$>$int \mbox{\it ext} M, ==$>$int \mbox{\it ext} N ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`} mod {\verb`~`}),\_\hspace{0.1em}==$>$int \mbox{\it ext} M mod N, [ ==$>$int \mbox{\it ext} M, ==$>$int \mbox{\it ext} N ]).
\end{tabbing}\end{sf}

 {\bf refinement rules:}
  
 \item[7]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$M+N in int, [ ==$>$M in int, ==$>$N in int]).\\[-0.15ex]
$\vdash$(intro,\_\hspace{0.1em}==$>$M-N in int, [ ==$>$M in int, ==$>$N in int]).\\[-0.15ex]
$\vdash$(intro,\_\hspace{0.1em}==$>$M*N in int, [ ==$>$M in int, ==$>$N in int]).\\[-0.15ex]
$\vdash$(intro,\_\hspace{0.1em}==$>$M/N in int, [ ==$>$M in int, ==$>$N in int]).\\[-0.15ex]
$\vdash$(intro,\_\hspace{0.1em}==$>$M mod N in int, [ ==$>$M in int, ==$>$N in int]).
\end{tabbing}\end{sf}

 {\bf membership rules:}
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} + {\verb`~`}),\_\hspace{0.1em}==$>$M+N=MM+NN in int,[ ==$>$M=MM in int, ==$>$N=NN in int ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`} - {\verb`~`}),\_\hspace{0.1em}==$>$M-N=MM-NN in int,[ ==$>$M=MM in int, ==$>$N=NN in int ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`} * {\verb`~`}),\_\hspace{0.1em}==$>$M*N=MM*NN in int,[ ==$>$M=MM in int, ==$>$N=NN in int ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`} / {\verb`~`}),\_\hspace{0.1em}==$>$M/N=MM/NN in int,[ ==$>$M=MM in int, ==$>$N=NN in int ]).\\[-0.15ex]
$\vdash$(intro({\verb`~`}mod{\verb`~`}),\_\hspace{0.1em}==$>$M mod N=MM mod NN in int,[ ==$>$M=MM in int, ==$>$N=NN in int ]).
\end{tabbing}\end{sf}

 {\bf equality rules:}
 \end{enumerate}
  
 \subsection{Selectors}
  
 \begin{enumerate}
 \item[8]
\begin{sf}\begin{tabbing}
$\vdash$(elim(X,new[U,V,W]),H==$>$T \mbox{\it ext} ind(X,[U,W,T1],T0,[U,W,T2]),\\[-0.15ex]
\hspace{2em}[ [U:int,V:U$<$0,W:Tsucc]==$>$Tu \mbox{\it ext} T1, \\[-0.15ex]
\hspace{3em}==$>$TT \mbox{\it ext} T0, \\[-0.15ex]
\hspace{3em}[U:int,V:0$<$U,W:Tpred]==$>$Tu \mbox{\it ext} T2 ]):-\\[-0.15ex]
\hspace{2em}decl(X:int,H),free([U,V,W],H,HH),s(T,[U],[X],Tu),\\[-0.15ex]
\hspace{2em}shyp(HH,H==$>$T,[U+1],[X],\_\hspace{0.1em}==$>$Tsucc),\\[-0.15ex]
\hspace{2em}shyp(HH,H==$>$T,[0],[X],\_\hspace{0.1em}==$>$TT),\\[-0.15ex]
\hspace{2em}shyp(HH,H==$>$T,[U-1],[X],\_\hspace{0.1em}==$>$Tpred).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of the type $int$ in
 the hypothesis list, generates an \emph{induction} term, the 
 further refinement of which is determined by the subgoals
 of the \emph{elim} step.
  
 \item[9]
\begin{sf}\begin{tabbing}
$\vdash$(intro(over(Z,T),new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$ind(E,[X1,Y1,T1],T0,[X2,Y2,T2]) in Te,\\[-0.15ex]
\hspace{2em}[ ==$>$E in int,\\[-0.15ex]
\hspace{3em}[U:int,W:U$<$0,V:Tsucc]==$>$TT1 in Tu, \\[-0.15ex]
\hspace{3em}==$>$T0 in To, \\[-0.15ex]
\hspace{3em}[U:int,W:0$<$U,V:Tpred]==$>$TT2 in Tu ]):-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(T,[E],[Z],Te),s(T,[U],[Z],Tu),s(T,[U+1],[Z],Tsucc),\\[-0.15ex]
\hspace{2em}s(T,[0],[Z],To),s(T,[U-1],[Z],Tpred),\\[-0.15ex]
\hspace{2em}s(T1,[U,V],[X1,Y1],TT1),s(T2,[U,V],[X2,Y2],TT2).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 An \emph{integer induction term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_e$ is an
 instantiation of that type scheme for $E$ and the subterms of
 the induction term can be proven to be in the corresponding
 instantiations $T_o$ and $T_s$. In most cases there is no direct
 depency between the type of the induction term and the current
 value of the base term of that induction term. To simplify
 the automatic proof of these wellformedness goals there is
 a derived rule, which assumes the result type to be constant.
  
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U,V,W]),H==$>$ind(E,[X1,Y1,T1],T0,[X2,Y2,T2]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in int,\\[-0.15ex]
\hspace{3em}[U:int,W:U$<$0,V:T]==$>$TT1 in T, \\[-0.15ex]
\hspace{3em}==$>$T0 in T, \\[-0.15ex]
\hspace{3em}[U:int,W:0$<$U,V:T]==$>$TT2 in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(T1,[U,V],[X1,Y1],TT1),s(T2,[U,V],[X2,Y2],TT2).
\end{tabbing}\end{sf}

 \end{description}
  
 \item[12]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(down),\_\hspace{0.1em}==$>$ind(E,[X1,Y1,T1],T0,TT)=TT1 in T, \\[-0.15ex]
\hspace{2em}[ ==$>$ind(E,[X1,Y1,T1],T0,TT) in T, ==$>$E$<$0 ]):-\\[-0.15ex]
\hspace{2em}s(T1,[E,ind(E+1,[X1,Y1,T1],T0,TT)],[X1,Y1],TT1).\\[-0.15ex]
$\vdash$(reduce(base),\_\hspace{0.1em}==$>$ind(E,T1,T0,T2)=T0 in T, \\[-0.15ex]
\hspace{2em}[ ==$>$ind(E,T1,T0,T2) in T, ==$>$E=0 in int ]).\\[-0.15ex]
$\vdash$(reduce(up),\_\hspace{0.1em}==$>$ind(E,TT,T0,[X2,Y2,T2])=TT2 in T, \\[-0.15ex]
\hspace{2em}[ ==$>$ind(E,TT,T0,[X2,Y2,T2]) in T, ==$>$0$<$E ]):-\\[-0.15ex]
\hspace{2em}s(T2,[E,ind(E-1,TT,T0,[X2,Y2,T2])],[X2,Y2],TT2).
\end{tabbing}\end{sf}

 {\bf equality rules:} 
 These rules describe the reduction of the induction terms
 depending on an assumption about the value of the base term,
 i.e. whether thisa term is less than, greater than, or equal
 to zero.     
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(decide(X=Y in int,new[U]),\\[-0.15ex]
\hspace{2em}H==$>$T \mbox{\it ext} int\_\hspace{0.1em}eq(X,Y,$\sigma$(E1,[axiom],[U]),$\sigma$(E2,[lambda({\verb`~`},axiom)],[U])),\\[-0.15ex]
\hspace{2em}[ [U:X=Y in int]==$>$T \mbox{\it ext} E1, \\[-0.15ex]
\hspace{2em}[U:X=Y in int=$>$void]==$>$T \mbox{\it ext} E2,\\[-0.15ex]
\hspace{4em}==$>$X in int,\\[-0.15ex]
\hspace{4em}==$>$ Y in int ]):-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(X), $\backslash$+ var(Y), syntax(H,X),syntax(H,Y),free([U],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The decision operator for integer equality may be used as
 a refinement for any type T, provided both, the \emph{then} and 
 the \emph{else} part are refinements of $T$. This rule gives
 you the possibility of introducing a case analysis in the
 current proof.   
 
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new [V]),H==$>$int\_\hspace{0.1em}eq(A,B,S,T) in TT,\\[-0.15ex]
\hspace{2em}[ ==$>$A in int, ==$>$B in int,\\[-0.15ex]
\hspace{3em}[V:A=B in int]==$>$S in TT, \\[-0.15ex]
\hspace{3em}[V:A=B in int=$>$void]==$>$T in TT ]):-\\[-0.15ex]
\hspace{2em}free([V],H).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The decision operator yields a value of the type $T$, provided
 both the \emph{then} and the \emph{else} part of the decision
 operator are elements of $T$.
 
 \item[13]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(true),\_\hspace{0.1em}==$>$int\_\hspace{0.1em}eq(A,B,X,Y)=X in T, \\[-0.15ex]
\hspace{2em}[  ==$>$X in T, ==$>$Y in T,  ==$>$A=B in int ]).\\[-0.15ex]
$\vdash$(reduce(false),\_\hspace{0.1em}==$>$int\_\hspace{0.1em}eq(A,B,X,Y)=Y in T, \\[-0.15ex]
\hspace{2em}[  ==$>$X in T, ==$>$Y in T, ==$>$A=B in int =$>$ void ]).
\end{tabbing}\end{sf}

 {\bf equality rules:}      
 These rules describe value of the decision term under certain
 assumptions. 
  
 \end{enumerate}
 \section{Less}
 \inv{less type scheme}
 $less$ is a type scheme which is introduced for keeping the
 theoretical system closed. For each $A$ and $B$ of type
 $int$ there exists a type $A$$<$$B$ which is inhabited 
 by $axiom$,if $A$ and $B$ are integers and $A$ is less then $B$,
 or is empty otherwise. In this sense
 we may assume $axiom$ as the only canonical element of $A$$<$$B$.
  
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro($<$),\_\hspace{0.1em}==$>$u(\_\hspace{0.1em}) \mbox{\it ext} A$<$B, [ ==$>$int \mbox{\it ext} A, ==$>$int \mbox{\it ext} B ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} $A<B$ is a refinement for any universe,
 if $A$ and $B$ are refinements of the type $int$.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$A$<$B in u(\_\hspace{0.1em}), [ ==$>$A in int, ==$>$B in int ]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $A<B$ is a type of any universe level
 if $A$ and $B$ are elements of the type $int$.
  
 \end{enumerate}
 
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$I$<$J,[]):-integer(I),integer(J),I$<$J.
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 If $I$ and $J$ are canonical members of $int$, i.e. integer
 numbers, then $I$$<J$ is inhabited by $axiom$, if $I$ is less $J$.
  
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$axiom in (A$<$B), [ ==$>$A$<$B]).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 Axiom is a canonical member of $A$$<$$B$, if the type $A$$<$$B$
 is inhabited at all.
  
 \end{enumerate}
  
 \subsection{Selectors}
  
 \begin{enumerate}
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(decide(X$<$Y,new[U]),\\[-0.15ex]
\hspace{2em}H==$>$T \mbox{\it ext} less(X,Y,$\sigma$(E1,[axiom],[U]),$\sigma$(E2,[lambda({\verb`~`},axiom)],[U])),\\[-0.15ex]
\hspace{2em}[ [U:X$<$Y]==$>$T \mbox{\it ext} E1, \\[-0.15ex]
\hspace{2em}[U:X$<$Y=$>$void]==$>$T \mbox{\it ext} E2,\\[-0.15ex]
\hspace{4em}==$>$X in int,\\[-0.15ex]
\hspace{4em}==$>$Y in int ]):-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(X), $\backslash$+ var(Y),syntax(H,X),syntax(H,Y),free([U],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The decision operator for the strict ordering of integers may be 
 used as a refinement for any type T, provided both, the \emph{then} 
 and the \emph{else} part are refinements of $T$. This rule gives
 you the possibility of introducing a case analysis in the
 current proof.   
  
 \item[11]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new [V]),H==$>$less(A,B,S,T) in TT,\\[-0.15ex]
\hspace{2em}[ ==$>$A in int, ==$>$B in int,\\[-0.15ex]
\hspace{3em}[V:A$<$B]==$>$S in TT, \\[-0.15ex]
\hspace{3em}[V:(A$<$B=$>$void)]==$>$T in TT ]):-\\[-0.15ex]
\hspace{2em}free([V],H). 
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The decision operator yields a value of the type $T$, provided
 both the \emph{then} and the \emph{else} part of the decision
 operator are elements of $T$.
  
 \item[14]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(true),\_\hspace{0.1em}==$>$less(A,B,X,Y)=X in T, \\[-0.15ex]
\hspace{2em}[ ==$>$X in T, ==$>$Y in T, ==$>$A$<$B ]).\\[-0.15ex]
$\vdash$(reduce(false),\_\hspace{0.1em}==$>$less(A,B,X,Y)=Y in T, \\[-0.15ex]
\hspace{2em}[ ==$>$X in T, ==$>$Y in T, ==$>$A$<$B=$>$void ]).
\end{tabbing}\end{sf}

 {\bf equality rules:}      
 These rules describe value of the decision term under certain
 assumptions. 
 \end{enumerate}
 \pagebreak
 \subsection{Arithmetic}
 The aim of this section is to provide the rule base
 for common arithmetical reasoning. Normally these rules
 will not be used directly, because the built-in tactic
 \emph{arith} solves many of the standard arithmetic problems.
 Nevertheless these explicit \emph{arith}-rules are necessary
 to enable the handling of more difficult arithmetic problems,
 and these rules provide a proper semantic base for the 
 \emph{arith} tactic. 
 \begin{enumerate}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(arith(Y,left),H==$>$X$<$Z, [ ==$>$Y$<$X=$>$void, ==$>$Y$<$Z ]):-\\[-0.15ex]
\hspace{2em}syntax(H,Y).\\[-0.15ex]
$\vdash$(arith(Y,right),H==$>$X$<$Z, [ ==$>$X$<$Y, ==$>$Z$<$Y=$>$void ]):-\\[-0.15ex]
\hspace{2em}syntax(H,Y).
\end{tabbing}\end{sf}

  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(arith(+,Z),\_\hspace{0.1em}==$>$X$<$Y, [ ==$>$X+Z$<$Y+Z ]).\\[-0.15ex]
$\vdash$(arith(-,Z),\_\hspace{0.1em}==$>$X$<$Y, [ ==$>$X-Z$<$Y-Z ]).\\[-0.15ex]
$\vdash$(arith(*,0$<$Z),\_\hspace{0.1em}==$>$X$<$Y, [ ==$>$X*Z$<$Y*Z, ==$>$0$<$Z ]).\\[-0.15ex]
$\vdash$(arith(*,Z$<$0),\_\hspace{0.1em}==$>$X$<$Y, [ ==$>$Y*Z$<$X*Z, ==$>$Z$<$0 ]).
\end{tabbing}\end{sf}

  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(arith(+),\_\hspace{0.1em}==$>$0$<$X*Y, [ ==$>$0$<$X, ==$>$0$<$Y ]).\\[-0.15ex]
$\vdash$(arith(-),\_\hspace{0.1em}==$>$0$<$X*Y, [ ==$>$X$<$0, ==$>$Y$<$0 ]).
\end{tabbing}\end{sf}

  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(arith,\_\hspace{0.1em}==$>$X mod Y$<$0=$>$void, [ ==$>$X in int, ==$>$Y in int ]).\\[-0.15ex]
$\vdash$(arith(+),\_\hspace{0.1em}==$>$X mod Y$<$Y, [ ==$>$X in int, ==$>$0$<$Y ]).\\[-0.15ex]
$\vdash$(arith(-),\_\hspace{0.1em}==$>$X mod Y$<$(-Y), [ ==$>$X in int, ==$>$Y$<$0 ]).
\end{tabbing}\end{sf}

  
 \end{enumerate}
 \pagebreak
  
 \section{List Types}
 \inv{list type}
 The type of all finite lists over a given type $A$ is written in
 the form $A\;list$. The elements of the list type $A\;list$ are the 
 empty list $nil$ and nonempty lists $x$$::$$y$ constructed from an
 element $x$ of the base type $A$ and a list $y$ of the type $A\;list$.
 Examples for members of the type $int\; list$ would be
 $nil$, $1$$::$$nil$, $2$$::$$3$$::$$nil$, etc.
 There is one universal list destructor, the list induction term
 $list\_ind(x,y,[u,v,w,z])$, it maps the list $x$ of type $A\; list$
 into some other type $T$, provided that $y$, and $z$ are from the 
 type $T$. $u$, $v$ and $w$ are free variables in $z$ which 
 become bound in the list induction term. If $x$ is the empty list,
 the list induction term ist defined to be $y$. If $x$ is a nonempty
 list and therefore has the form $u::v$, and if furthermore $w$
 is assumed to be the value of the list induction term for $v$,
 then the value of the list induction term for $x$ is defined to
 be $z$. Let us consider the following examples:
 \begin{itemize}
 \item
 The length of a list $l$ is described by
 $list\_ind(l,0,[\verb'~',\verb'~',n,n+1])$.
 \item
 Suppose $x$ is of the type $A\; list$ and there is a special
 element $err$ \footnote{Remember, that there is no way of describing
 partial constructs, you always need an \emph{error element} or
 some equivalent.}
 in $A$, then head and the tail of the list $x$ can
 be described as $list\_ind(x,err,[h,\verb'~',\verb'~',h])$, and
 $list\_ind(x,nil,[\verb'~',t,\verb'~',t])$, respectively.
 \item
 The \emph{sum} of the elements of a list $k$ of integers could be
 described in the form $list\_ind(k,0,[h,\verb'~',s,h+s])$.
 \end{itemize}
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} list),\_\hspace{0.1em}==$>$u(I) \mbox{\it ext} A list, [ ==$>$u(I) \mbox{\it ext} A ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} $A\;list$ is a refinement
 for any universe, if $A$ is a refinement for the same universe. 
 This is a typical stepwise refinement rule. 
 You make a partial decision (to use a list structure),
 but let the base type of the list still open. So there is a subgoal
 still stating that your initial universe is inhabited, which would
 result (during further refinement) in some type $A$.
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$A list in u(I), [ ==$>$A in u(I) ]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $A\;list$ is a type of universe level $i$,
 i.e. a member of $u(i)$ if $A$ is a type of universe level $i$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$A list=B list in u(I), [ ==$>$A=B in u(I) ]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two list types are equal if the corresponding base types are
 equal.
 \end{enumerate}
  
 \subsection{Constructors}
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),nil),\_\hspace{0.1em}==$>$A list \mbox{\it ext} nil,[ ==$>$A list in u(I)]):- level(I).
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 $nil$ is a realisation for any well-formed list type.
  
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$nil in A list,[ ==$>$A list in u(I)]):- level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 $nil$ is an element of any well-formed list type.
  
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(::),\_\hspace{0.1em}==$>$A list \mbox{\it ext} B::C, [ ==$>$A \mbox{\it ext} B, ==$>$A list \mbox{\it ext} C ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} 
 List construction is a partial refinement over any list type.
 The head and the tail of the list are derived as refinement of
 the basic type or of the list type again.
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$B::C in A list, [ ==$>$B in A, ==$>$C in A list ]).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 A list construction term $B::C$ is an element of the type $A list$,
 if the head $B$ is an element of the basic type $A$ and the
 tail $C$ is an element of the list type $A list$ again.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$A::B=AA::BB in T list, [ ==$>$A=AA in T, ==$>$B=BB in T list ]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two nonempty lists are equal if the heads and tails are equal
 in the corresponding types.
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate}
 \item[7]
\begin{sf}\begin{tabbing}
$\vdash$(elim(X,new[U,V,W]),H==$>$T \mbox{\it ext} list\_\hspace{0.1em}ind(X,Tb,[U,V,W,Tu]),\\[-0.15ex]
\hspace{2em}[ ==$>$Tnil \mbox{\it ext} Tb, \\[-0.15ex]
\hspace{3em}[U:A,V:A list,W:Tv]==$>$Tuv \mbox{\it ext} Tu ]):-\\[-0.15ex]
\hspace{2em}decl(X:A list,H), free([U,V,W],H,HH), s(T,[V],[X],Tv),\\[-0.15ex]
\hspace{2em}shyp(HH,H==$>$T,[nil],[X],\_\hspace{0.1em}==$>$Tnil),\\[-0.15ex]
\hspace{2em}shyp(HH,H==$>$T,[U::V],[X],\_\hspace{0.1em}==$>$Tuv).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of a list type $A\; list$ in
 the hypothesis list, generates an \emph{list induction} term, the 
 further refinement of which is determined by the subgoals
 of the \emph{elim} step.
  
 \item[8]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(A list),over(Z,T),new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$list\_\hspace{0.1em}ind(E,Tbase,[X,Y,K,Tind]) in Te,\\[-0.15ex]
\hspace{2em}[ ==$>$E in A list, \\[-0.15ex]
\hspace{3em}==$>$Tbase in Tnil, \\[-0.15ex]
\hspace{3em}[U:A,V:A list,W:Tv]==$>$Tstep in Tuv ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(T,[E],[Z],Te),s(T,[U::V],[Z],Tuv),\\[-0.15ex]
\hspace{2em}s(T,[nil],[Z],Tnil),s(T,[V],[Z],Tv),\\[-0.15ex]
\hspace{2em}s(Tind,[U,V,W],[X,Y,K],Tstep).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A \emph{list induction term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_e$ is an
 instantiation of that type scheme for $E$ and the subterms of
 the induction term can be proven to be in the corresponding
 instantiations $T_o$ and $T_s$, and if you can predict the
 type of the base term $using(A\; list)$. 
 In most cases there is no direct
 depency between the type of the induction term and the current
 value of the base term of that induction term. To simplify
 the automatic proof of these wellformedness goals there is
 a \emph{derived rule}, which assumes the result type to be constant.
 Still there is the problem of
 supplying the type information for the base term. For the
 simplest case, that the base term is a single variable, which
 is declared in the hypothesis list, there is again a \emph{derived 
 rule} which simply accesses the declaration from the hypothesis
 list for generating the type of the base term.
 
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(A list),new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$list\_\hspace{0.1em}ind(E,Tbase,[X,Y,Z,Tind]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in A list, \\[-0.15ex]
\hspace{3em}==$>$Tbase in T, \\[-0.15ex]
\hspace{3em}[U:A,V:A list,W:T]==$>$Tstep in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},syntax(H,A),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(Tind,[U,V,W],[X,Y,Z],Tstep).
\end{tabbing}\end{sf}

 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$list\_\hspace{0.1em}ind(E,Tbase,[X,Y,Z,Tind]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in A list,\\[-0.15ex]
\hspace{3em}==$>$Tbase in T, \\[-0.15ex]
\hspace{3em}[U:A,V:A list,W:T]==$>$Tstep in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},type(E,H,A list), free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(Tind,[U,V,W],[X,Y,Z],Tstep).
\end{tabbing}\end{sf}

 \end{description}
 \end{enumerate}
  
 \section{Disjoint Union Types}
 \inv{disjoint union type}
 If $A$ and $B$ are types, then the disjoint union of $A$ and $B$,
 denoted by $A\backslash B$, is also a type. 
 The elements of the disjoint
 union $A\backslash B$ have the form $inl(x)$, 
 where $x$ is an element of $A$,
 or $inr(y)$, where $y$ is an element of $B$. Whether an element of
 a disjoint union type is a projection from the left or the right
 member type of the union is a decidable property, which 
 forms a basic computational operation. The
 decision operator has the form $decide(z,[u,f],[v,g])$
 and yields the value $f_{[x/u]}$ if $z$ has the form $inl(x)$ or
 $g_{[y/v]}$ if $z$ is of the form $inr(y)$.
  
 \subsection{Type Formation}
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} $\backslash$ {\verb`~`}),\_\hspace{0.1em}==$>$u(I) \mbox{\it ext} A$\backslash$B, [ ==$>$u(I) \mbox{\it ext} A, ==$>$u(I) \mbox{\it ext} B ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} 
 $A\backslash B$ is a refinement
 for any universe, if $A$ and $B$ are refinements for the
 same universe. This is a stepwise
 refinement rule. You make a partial decision (to use a disjoint union),
 but let the base types of the union still open. So there are two 
 subgoals still stating that your initial universe is inhabited,
 which would result (during further refinement) in some types $A$ and
 $B$.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(A$\backslash$B) in u(I), [ ==$>$A in u(I), ==$>$B in u(I) ]).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $A\backslash B$ is a type of universe level $i$,
 i.e. a member of $u(i)$ if $A$ and $B$ are types of universe level $i$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(A$\backslash$B)=(AA$\backslash$BB) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A=AA in u(I), ==$>$B=BB in u(I) ]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Union types are equal if the corresponding base types are equal.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),left),\_\hspace{0.1em}==$>$A$\backslash$B \mbox{\it ext} inl(X), \\[-0.15ex]
\hspace{2em}[ ==$>$A \mbox{\it ext} X, ==$>$B in u(I)]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 A left injection term $inl(X)$ is a refinement for the union type
 $A\backslash B$ at any universe level
 if $X$ is a refinement of the type $A$ and the
 other half of the union type is well-formed at the universe level given. 
  
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$inl(X) in (A$\backslash$B), \\[-0.15ex]
\hspace{2em}[ ==$>$X in A, ==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A left injection term $inl(X)$ is a member of the union type
 $A\backslash B$ at any universe level
 if $X$ is a member of $A$ and the
 other half of the union type is well-formed at the universe level given. 
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$inl(X)=inl(XX) in (A$\backslash$B),\\[-0.15ex]
\hspace{2em}[ ==$>$X=XX in A, ==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Left injection terms are equal if the injecting terms are equal,
 and the other half of the union type is well-formed at the universe
 level given.
  
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),right),\_\hspace{0.1em}==$>$A$\backslash$B \mbox{\it ext} inr(X), \\[-0.15ex]
\hspace{2em}[ ==$>$B \mbox{\it ext} X, ==$>$A in u(I)]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 A right injection term $inr(X)$ is a refinement for the union type
 $A\backslash B$ at any universe level
 if $X$ is a refinement of the type $B$ and the other half of the 
 union type is well-formed at the universe level given. 
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$inr(X) in (A$\backslash$B), \\[-0.15ex]
\hspace{2em}[ ==$>$X in B, ==$>$A in u(I) ]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A right injection term $inr(X)$ is a member of the union type
 $A\backslash B$ at any universe level
 if $X$ is a member of $B$ and the other half of the 
 union type is well-formed at the universe level given. 
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$inr(X)=inr(XX) in (A$\backslash$B),\\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), ==$>$X=XX in B ]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Right injection terms are equal if the injecting terms are equal
 and the other half of the union type is well-formed at the universe
 level given.
 \end{enumerate}
  
 \subsection{Selectors}
  
 \begin{enumerate}
 \item[7]
\begin{sf}\begin{tabbing}
$\vdash$(elim(V,new[X,Y,N1,N2]),H==$>$T \mbox{\it ext} decide(V,[X,Tx],[Y,Ty]),\\[-0.15ex]
\hspace{2em}[ [X:A,N1:V=inl(X) in (A$\backslash$B)]==$>$Tinl \mbox{\it ext} Tx, \\[-0.15ex]
\hspace{3em}[Y:B,N2:V=inr(Y) in (A$\backslash$B)]==$>$Tinr \mbox{\it ext} Ty ]):-\\[-0.15ex]
\hspace{2em}decl(V:A$\backslash$B,H), free([X,Y,N1,N2],H,HH), \\[-0.15ex]
\hspace{2em}shyp(HH,H==$>$T,[inl(X)],[V],\_\hspace{0.1em}==$>$Tinl),\\[-0.15ex]
\hspace{2em}shyp(HH,H==$>$T,[inr(Y)],[V],\_\hspace{0.1em}==$>$Tinr).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of a disjoint
 union type generates to subgoals, one for the case the
 value of the variables comes from the left base type, and
 one for the other case. The extract term combines the
 resulting terms from both cases into a \emph{decision term}.
  
 \item[8]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(A$\backslash$B),over(Z,T),new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$decide(E,[X,Tx],[Y,Ty]) in Te,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (A$\backslash$B),\\[-0.15ex]
\hspace{3em}[U:A,W:E=inl(U) in A$\backslash$B]==$>$Tu in Tleft, \\[-0.15ex]
\hspace{3em}[V:B,W:E=inr(V) in A$\backslash$B]==$>$Tv in Tright ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),syntax(H,B),$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(Tx,[U],[X],Tu),s(Ty,[V],[Y],Tv),\\[-0.15ex]
\hspace{2em}s(T,[E],[Z],Te),s(T,[inl(U)],[Z],Tleft),s(T,[inr(V)],[Z],Tright).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A \emph{decision term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_e$ is an
 instantiation of that type scheme for $E$ and the subterms of
 the decision term can be proven to be in the corresponding
 instantiations $T_{left}$ and $T_{right}$, and if you can predict the
 type of the base term $using(A\backslash B)$. 
 In most cases there is no direct
 depency between the type of the decision term and the current
 value of the base term of that decision term. To simplify
 the automatic proof of these wellformedness goals there is
 a \emph{derived rule}, which assumes the result type to be constant.
 Still there is the problem of
 supplying the type information for the base term. For the
 simplest case, that the base term is a single variable, which
 is declared in the hypothesis list, there is again a \emph{derived 
 rule} which simply accesses the declaration from the hypothesis
 list for generating the type of the base term.
  
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(A$\backslash$B),new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$decide(E,[X,Tx],[Y,Ty]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (A$\backslash$B), \\[-0.15ex]
\hspace{3em}[U:A,W:E=inl(U) in A$\backslash$B]==$>$Tu in T, \\[-0.15ex]
\hspace{3em}[V:B,W:E=inr(V) in A$\backslash$B]==$>$Tv in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},syntax(H,A),syntax(H,B),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(Tx,[U],[X],Tu),s(Ty,[V],[Y],Tv).
\end{tabbing}\end{sf}

 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new [U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$decide(E,[X,Tx],[Y,Ty]) in T, \\[-0.15ex]
\hspace{2em}[ ==$>$E in (A$\backslash$B),\\[-0.15ex]
\hspace{3em}[U:A,W:E=inl(U) in A$\backslash$B]==$>$Tu in T, \\[-0.15ex]
\hspace{3em}[V:B,W:E=inr(V) in A$\backslash$B]==$>$Tv in T ]):-\\[-0.15ex]
\hspace{2em}type(E,H,A$\backslash$B), \\[-0.15ex]
\hspace{2em}{\bf derived},free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(Tx,[U],[X],Tu),s(Ty,[V],[Y],Tv).
\end{tabbing}\end{sf}

 \end{description}
 \end{enumerate}
  
 \section{Function Types}
 \inv{function type}
 Function types $A$$\rightarrow$$B$ describe mappings from the type 
 $A$ into the type $B$. The elements of a function type are 
 $\lambda$-terms of the form $lambda(x,t_x)$.
 We may consider function type as logical implications,
 i.e. a special form of propositions. Propositions are inhabited by
 their proofs. A proof of a implication $A$$\rightarrow$$B$ consists 
 in the
 intuitionistic framework of a mapping, which maps any proof of $A$
 into a proof of $B$, i.e. any member of $A$ into $B$.
 There is one selector defined on function types: the \emph{function
 application} $f\;of\;a$ where $f$ is any element of 
 $A$$\rightarrow$$B$ and $a$ is an element of $A$.
  
 \subsection{Type Formation}
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} =$>$ {\verb`~`}),\_\hspace{0.1em}==$>$u(I) \mbox{\it ext} A=$>$B, [ ==$>$u(I) \mbox{\it ext} A, ==$>$u(I) \mbox{\it ext} B ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} 
 $A\rightarrow B$ is a refinement
 for any universe, if $A$ and $B$ are refinements for the
 same universe. This is a stepwise
 refinement rule. You make a partial decision (to use a function type),
 but let the base types of the mapping still open. So there are two 
 subgoals still stating that your initial universe is inhabited,
 which would result (during further refinement) in some types $A$ and
 $B$.
  
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),H==$>$(A=$>$B) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [Y:A]==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $A\rightarrow B$ is a type of universe level $i$,
 i.e. a member of $u(i)$ if $A$ is a type of universe level $i$,
 and $B$ can be proven to be a type under the assumption of $A$
 being inhabited by an arbitrary element $Y$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(A=$>$B)=(AA=$>$BB) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A=AA in u(I), ==$>$B=BB in u(I) ]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Function Types are equal if the corresponding domain and range types 
 are equal.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Y]),H==$>$A=$>$B \mbox{\it ext} lambda(Y,F), \\[-0.15ex]
\hspace{2em}[ [Y:A]==$>$B \mbox{\it ext} F, ==$>$A in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 A $\lambda$-term $lambda(Y,F)$ is a refinement for the type 
 $A\rightarrow B$ at any universe level 
 if $F$ is a refinement of $B$ under the 
 assumption of $Y$ being an arbitrary element of $A$,
 and if the domain type $A$ is a member of that given 
 universe level.
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Z]),H==$>$lambda(X,F) in (A=$>$B), \\[-0.15ex]
\hspace{2em}[ [Z:A]==$>$Fz in B, ==$>$A in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Z],H),s(F,[Z],[X],Fz),level(I).\\[-0.15ex]
$\vdash$(intro(\mbox{\it at}(I)),H==$>$lambda(X,F) in (A=$>$B),\\[-0.15ex]
\hspace{2em}[ [X:A]==$>$F in B, ==$>$A in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([X],H),level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A $\lambda$-term $lambda(X,F)$ is an element of the type 
 $A$$\rightarrow$$B$ at any universe level 
 if $F_{[z/x]}$ is a member of $B$ under the 
 assumption of $z$ being an arbitrary element of $A$,
 and if the domain type $A$ is a member of that given 
 universe level.

% \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),using(AA=$>$BB),new[X,Y,W]),H==$>$F in (A=$>$B),\\[-0.15ex]
\hspace{2em}[ [X:A,Y:A,W:X=Y in A]==$>$F of X =F of Y in B, \\[-0.15ex]
\hspace{3em}==$>$A in u(I), \\[-0.15ex]
\hspace{3em}==$>$F in (AA=$>$BB) ]):-\\[-0.15ex]
\hspace{2em}free([X,Y,W],H),level(I).
\end{tabbing}\end{sf}

  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Y]),H==$>$lambda(Xf,F)=lambda(Xg,G) in (A=$>$B),\\[-0.15ex]
\hspace{2em}[ [Y:A]==$>$ FF=GG in B,==$>$A in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(F,[Y],[Xf],FF),s(G,[Y],[Xg],GG),level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two $\lambda$-terms are equal if you can prove the equality
 of the base terms under the assumption of the same free variable.
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate}
 \item[8]
\begin{sf}\begin{tabbing}
$\vdash$(elim(F,new[Y]),H==$>$T \mbox{\it ext} $\sigma$(E,[F of X],[Y]), \\[-0.15ex]
\hspace{2em}[ ==$>$A \mbox{\it ext} X, [Y:B]==$>$T \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}( decl(F:A=$>$B,H);\\[-0.15ex]
\hspace{3em}(decl(F:(V:A=$>$B),H),$\backslash$+freevarinterm(B,V))\\[-0.15ex]
\hspace{2em}),\\[-0.15ex]
\hspace{2em}free([Y],H).\\[-0.15ex]
$\vdash$(elim(F,on(X),new[Y,Z]),H==$>$T \mbox{\it ext} $\sigma$(E,[F of X],[Y]),\\[-0.15ex]
\hspace{2em}[ ==$>$X in A, \\[-0.15ex]
\hspace{3em}[Y:B,Z:Y=F of X in B]==$>$T \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}( decl(F:(A=$>$B),H);\\[-0.15ex]
\hspace{3em}(decl(F:(V:A=$>$B),H),$\backslash$+freevarinterm(B,V))\\[-0.15ex]
\hspace{2em}),\\[-0.15ex]
\hspace{2em}free([Y,Z],H),\\[-0.15ex]
\hspace{2em}syntax(H,X).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of a function type 
 generates a function application term, which is automatically
 substituted for all occurences of references $Y$ to the 
 instantiation of the range type (proposition) of that function
 type in the extract term of the proof of the subgoal.
 The second \emph{elim} rule describes the situation, where you
 wish to refer to the value of the function application term
 in further proof. 
  
 \item[9]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(A=$>$B),new[U]),H==$>$F of Y in T, \\[-0.15ex]
\hspace{2em}[ ==$>$F in (A=$>$B), \\[-0.15ex]
\hspace{3em}==$>$Y in A, \\[-0.15ex]
\hspace{3em}[U:B]==$>$U in T]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),syntax(H,B),free([U],H).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A \emph{function application term} is of a given type $T$ if you can
 supply function type for the \emph{base term}, such that $F$ is
 of that function type, that the argument is in the domain
 of that function type, and that the memberhood in the range of
 the function type implies memberhood in $T$.
 Still there is the problem of
 supplying the type information for the function itself. For the
 simplest case, that the function term is a single variable, which
 is declared in the hypothesis list, there is again a \emph{derived 
 rule} which simply accesses the declaration from the hypothesis
 list for generating the type of the base term.
  
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U]),H==$>$F of Y in T, \\[-0.15ex]
\hspace{2em}[ ==$>$F in (A=$>$B), \\[-0.15ex]
\hspace{3em}==$>$Y in A,\\[-0.15ex]
\hspace{3em}[U:B]==$>$U in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},free([U],H),type(F,H,A=$>$B).
\end{tabbing}\end{sf}

 \end{description}
  
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(equality(new[Y]),H==$>$F=G in (A=$>$B),\\[-0.15ex]
\hspace{2em}[ [Y:A]==$>$ F of Y=G of Y in B, \\[-0.15ex]
\hspace{3em}==$>$F in (A=$>$B), \\[-0.15ex]
\hspace{3em}==$>$G in (A=$>$B) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 The equality rule for function terms differs a little from 
 the other rules, because there are not only syntactic
 properties which could be used for proving the equality of
 two functions. This rule describes the \emph{extensionality}
 of the equality of functions.
  
 \end{enumerate}
  
 \section{Dependent Function Types}
 \inv{dependent function type}
 Dependent function types $X:A\rightarrow B$, where $A$ is a type and
 $B$ denotes a family $B_{X\in A}$ of types,
 are a generalisation of function types. 
 They describe mappings from the type $A$ into a family
 of types $B_{a\in A}$, such that an element $X\in A$ is mapped
 into an element of the type $B_{[X/a]}$.
 The elements of a dependent function type are also $\lambda$-terms
 of the form $lambda(x,t_x)$, but the result type of $t_x$ may depend
 on the value of $x$.
 One can consider dependent function type from the logical point
 of view as universally quantified propositions, stating that $B$ is
 valid for all $X$ of type $A$.
 A proof of that universally quantified proposition consists in the
 intuitionistic framework of a mapping which maps any element $X$
 of $A$ into a proof of $B$, i.e. any member $X$ of $A$ into a member
 of $B_{[X/a]}$.
 There is one selector defined on dependent function types: 
 the \emph{function application} $f\;of\;a$ where 
 $f$ is any element of $x:A\rightarrow B$
 and $a$ is an element of $A$.
  
 \subsection{Type Formation}
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(X:A=$>$ {\verb`~`}),H==$>$u(I) \mbox{\it ext} X:A=$>$B, \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [X:A]==$>$u(I) \mbox{\it ext} B ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),free([X],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:} 
 $X:A\rightarrow B$ is a refinement for any universe, 
 if $A$ is a type, and $B$ is a refinement of the same universe 
 under the assumption of the existence of some $X$ of type $A$. 
 This is a stepwise refinement rule. 
 You make a partial decision (to use a function type),
 but let the base types of the mapping still open. So there are two 
 subgoals still stating that your initial universe is inhabited,
 which would result (during further refinement) in some types $A$ and
 $B$.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),H==$>$(X:A=$>$B) in u(I), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(B,[Y],[X],By).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $X:A\rightarrow B$ is a type of universe level $i$,
 i.e. a member of $u(i)$ if $A$ is a type of universe level $i$,
 and $B[Y/X]$ can be proven to be a type under the assumption of $A$
 being inhabited by an arbitrary element $Y$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),H==$>$(X:A=$>$B)=(XX:AA=$>$BB) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A=AA in u(I), [Y:A]==$>$By=BBy in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(B,[Y],[X],By), s(BB,[Y],[XX],BBy).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Dependent function types are equal if the corresponding domain
 types are equal and if the range types can be proven equal
 under the assumption of a common free variable $Y$. 
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Y]),H==$>$X:A=$>$B \mbox{\it ext} lambda(Y,F), \\[-0.15ex]
\hspace{2em}[ [Y:A]==$>$By \mbox{\it ext} F, ==$>$A in u(I) ]):-\\[-0.15ex]
\hspace{2em}( (free([X],H),By=B,Y=X);\\[-0.15ex]
\hspace{3em}(free([Y],H),s(B,[Y],[X],By))\\[-0.15ex]
\hspace{2em}),\\[-0.15ex]
\hspace{2em}!,level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 A $\lambda$-term $lambda(Y,F)$ 
 is a refinement for the type $X:A$$\rightarrow$$B$ at any universe level 
 if $F$ is a refinement of $B_{[Y/X]}$ 
 under the assumption of $Y$ being an arbitrary element of $A$,
 and if the domain type $A$ is a member of that given 
 universe level. 
 The first disjunct describes the special case
 where $X$ is a free variable in $H$, and may be used as a
 preferred variable identifier instead of $Y$. This has no 
 influence on the logical interpretation, but allows you to
 exploit the intensional meaning of the variable identifier
 in further proof. There is a derived rule which handles the 
 special case of having propositions
 universally quantified (i.e. parametrised) over some type 
 and automatically supplies a suitable universe level. 
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),H==$>$X:u(I)=$>$B \mbox{\it ext} lambda(Y,F), \\[-0.15ex]
\hspace{2em}[ [Y:u(I)]==$>$By \mbox{\it ext} F, ==$>$u(I) in u(J) ]):-\\[-0.15ex]
\hspace{2em}{\bf derived}, free([Y],H),\\[-0.15ex]
\hspace{2em}s(B,[Y],[X],By),level(I),J is I+1.\\[-0.15ex]
$\vdash$(intro,H==$>$X:u(I)=$>$B \mbox{\it ext} lambda(X,F), \\[-0.15ex]
\hspace{2em}[ [X:u(I)]==$>$B \mbox{\it ext} F, ==$>$u(I) in u(J) ]):-\\[-0.15ex]
\hspace{2em}{\bf derived}, free([X],H),level(I),J is I+1.
\end{tabbing}\end{sf}

 \end{description}
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Z]),H==$>$lambda(X,F) in (Y:A=$>$B),\\[-0.15ex]
\hspace{2em}[ [Z:A]==$>$Fz in Bz, ==$>$A in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Z],H),s(B,[Z],[Y],Bz),s(F,[Z],[X],Fz), level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A $\lambda$-term $lambda(X,F)$ is an element of the type 
 $Y$$:$$A$$\rightarrow$$B$ at any universe level 
 if $F_{[Z/X]}$ is a member of $B_{[Z/Y]}$ under the 
 assumption of $Z$ being an arbitrary element of $A$,
 and if the domain type $A$ is a member of that given 
 universe level.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new [Y]),H==$>$lambda(Xf,F)=lambda(Xg,G) in (X:A=$>$B),\\[-0.15ex]
\hspace{2em}[ [Y:A]==$>$ FF=GG in By,==$>$ A in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(F,[Y],[Xf],FF),s(G,[Y],[Xg],GG),s(B,[Y],[X],By),level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two $\lambda$-terms are equal if you can prove the equality
 of the base terms under the assumption of the same free variable
 in the common range type.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),using(U:AA=$>$BB),new[X,Y,W]),\\[-0.15ex]
\hspace{2em}H==$>$F in (A=$>$B), \\[-0.15ex]
\hspace{2em}[ [X:A,Y:A,W:X=Y in A]==$>$F of X =F of Y in B,\\[-0.15ex]
\hspace{3em}==$>$A in u(I),\\[-0.15ex]
\hspace{3em}==$>$F in (U:AA=$>$BB) ]):-\\[-0.15ex]
\hspace{2em}free([X,Y,W],H),level(I).\\[-0.7ex]
\\[-0.7ex]

\end{tabbing}\end{sf}

 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate}
 \item[7]
\begin{sf}\begin{tabbing}
$\vdash$(elim(F,on(X),new[Y]),H==$>$T \mbox{\it ext} $\sigma$(E,[F of X],[Y]),\\[-0.15ex]
\hspace{2em}[ ==$>$X in A, \\[-0.15ex]
\hspace{3em}[Y:Bx]==$>$T \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}decl(F:(V:A=$>$B),H),free([Y],H),syntax(H,X),s(B,[X],[V],Bx).\\[-0.15ex]
$\vdash$(elim(F,on(X),new[Y,Z]),H==$>$T \mbox{\it ext} $\sigma$(E,[F of X],[Y]),\\[-0.15ex]
\hspace{2em}[ ==$>$X in A, \\[-0.15ex]
\hspace{3em}[Y:Bx,Z:Y=F of X in Bx]==$>$T \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}decl(F:(V:A=$>$B),H),free([Y,Z],H),syntax(H,X),s(B,[X],[V],Bx).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of a function type 
 generates a function application term, which is automatically
 substituted for all occurences of references $Y$ to the 
 instantiation of the range type (proposition) of that function
 type in the extract term of the proof of the subgoal.
 The second \emph{elim} rule describes the situation, where you
 wish to refer to the value of the function application term
 in further proof. 
 \item[9]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(X:A=$>$B),over(Z,T),new[U,V]),H==$>$F of Y in Ty, \\[-0.15ex]
\hspace{2em}[ ==$>$F in (X:A=$>$B), ==$>$Y in A, [U:A,V:Bu]==$>$V in Tu ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),$\tau_{var}$(X),syntax([X:\_\hspace{0.1em}$\mid$H],B),$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),\\[-0.15ex]
\hspace{2em}free([U,V],H),\\[-0.15ex]
\hspace{2em}s(T,[Y],[Z],Ty),s(B,[U],[X],Bu),s(T,[U],[Z],Tu).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A \emph{function application term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_y$ is an
 instantiation of that type scheme for the argument $Y$ 
 and that in general, that for any $U$ in the domain
 type $A$ and any value $V$ of the range type $B_u$ is in the
 instantiation of $T$ for $U$. In most cases there is no direct
 depency between the type of the function application term and the 
 current value of the argument term. To simplify
 the automatic proof of these wellformedness goals there is
 a \emph{derived rule}, which assumes the result type to be constant.
 Still there is the problem of
 supplying the type information for the function itself. For the
 simplest case, that the function term is a single variable, which
 is declared in the hypothesis list, there is again a \emph{derived 
 rule} which simply accesses the declaration from the hypothesis
 list for generating the type of the base term.
  
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(X:A=$>$B),new[U,V]),H==$>$F of Y in T,\\[-0.15ex]
\hspace{2em}[ ==$>$F in (X:A=$>$B), ==$>$Y in A, [U:A,V:Bu]==$>$V in T ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),syntax([X:\_\hspace{0.1em}$\mid$H],B),$\tau_{var}$(X),\\[-0.15ex]
\hspace{2em}free([U,V],H),s(B,[U],[X],Bu).
\end{tabbing}\end{sf}

 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U,V]),H==$>$F of Y in T, \\[-0.15ex]
\hspace{2em}[ ==$>$F in (X:A=$>$B), ==$>$Y in A, [U:A,V:Bu]==$>$V in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},free([U,V],H),type(F,H,X:A=$>$B),\\[-0.15ex]
\hspace{2em}s(B,[U],[X],Bu). 
\end{tabbing}\end{sf}

 \end{description}
  
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(equality(new[Y]),H==$>$F=G in (X:A=$>$B),\\[-0.15ex]
\hspace{2em}[ [Y:A]==$>$ F of Y=G of Y in By, \\[-0.15ex]
\hspace{3em}==$>$F in (X:A=$>$B), \\[-0.15ex]
\hspace{3em}==$>$G in (X:A=$>$B) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(B,[Y],[X],By).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 The equality rule for function terms differs a little from 
 the other rules, because there are not only syntactic
 properties which could be used for proving the equality of
 two functions. This rule describes the \emph{extensionality}
 of the equality of functions.
  
 \end{enumerate}
  
  
 \section{Product Types}
 \inv{product type}
  
 Cartesian product types $A\#B$ consist of ordered pairs $x\&y$ of
 elements $x$ of $A$ and $y$ of $B$.
 We can interpret product types as logical conjunctions,
 i.e. a special form of propositions. Elements of such a product
 type would be the proofs of the conjunction. A proof of a conjunction
 $A\#B$ consists of a proof of $A$ and a proof of $B$.
 So we might consider the set of all proofs of $A\#B$ as the set
 of ordered pairs of proofs of $A$ and $B$. There is one selector 
 construct $spread$, a generalisation of the usual
 projection operators: supposed $s=x\&y\;in\;A\#B$, then 
 $spread(s,[u,v,t])$ is defined to be
 $t_{[x,y/u,v]}$, i.e. $t$ with $u$ and $v$ substituted by the left 
 and right component of $s$ respectively.
 The left projection and the right projection operators could be
 described as $spread(s,[u,\verb'~',u])$ and 
 $spread(s,[\verb'~'~,v,v])$, respectively.
  
 \subsection{Type Formation}
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} \# {\verb`~`}),\_\hspace{0.1em}==$>$u(I) \mbox{\it ext} A\#B, [ ==$>$u(I) \mbox{\it ext} A, ==$>$u(I) \mbox{\it ext} B ]).
\end{tabbing}\end{sf}

 {\bf refinement rule:} $A\#B$ is a refinement
 for any universe, if $A$ and $B$ are refinements for the
 same universe.  This is a stepwise
 refinement rule. You make a partial decision (to use a Cartesian 
 product), but let the base types of the product still open. 
 So there are two subgoals still stating that your initial universe 
 is inhabited, which would result (during further refinement) in some
 types $A$ and $B$.
  
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(A\#B) in u(I), [ ==$>$A in u(I), ==$>$B in u(I) ]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $A\#B$ is a type of universe level $i$,
 i.e. a member of $u(i)$ if $A$ and $B$ are types of universe level $i$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(A\#B)=(AA\#BB) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A=AA in u(I), ==$>$B=BB in u(I) ]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Product types are equal if the corresponding base types are equal.
 \end{enumerate}
  
 \subsection{Constructors}
 \begin{enumerate}
 \item[7]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$A\#B \mbox{\it ext} F\&G, [ ==$>$A \mbox{\it ext} F, ==$>$B \mbox{\it ext} G ]). 
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 Ordered pairs $F\&G$ are refinements for Cartesian product types
 $A\#B$ if $F$ is a refinement of $A$ and $G$ is a refinement of $B$.
  
 \item[8]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(F\&G)in (A\#B), [ ==$>$F in A, ==$>$G in B]).
\end{tabbing}\end{sf}

 {\bf membership rule:}  
 An ordered pair $F\&G$ is a members of the Cartesian product type
 $A\#B$ if $F$ is a member of $A$ and $G$ is a member of $B$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$U\&V=UU\&VV in (A\#B), [ ==$>$U=UU in A, ==$>$V=VV in B ]).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Pairs are equal in the product type, if the components are equal
 in the corresponding base types.
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate} 
 \item[9]
\begin{sf}\begin{tabbing}
$\vdash$(elim(Z,new[U,V,W]),H==$>$T \mbox{\it ext} spread(Z,[U,V,S]),\\[-0.15ex]
\hspace{2em}[ [U:A,V:B,W:Z=U\&V in (A\#B)]==$>$Tuv \mbox{\it ext} S ]):-\\[-0.15ex]
\hspace{2em}decl(Z:A\#B,H),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(T,[U\&V],[Z],Tuv).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of a Cartesian product
 type in the hypothesis list, generates an \emph{spread} term, the 
 further refinement of which is determined by the subgoal
 of the \emph{elim} step.
  
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(A\#B),over(Z,T),new[U,V,W]),H==$>$spread(E,[X,Y,S]) in Te,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (A\#B), [U:A,V:B,W:E=U\&V in (A\#B)]==$>$Suv in Tuv ]):-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),syntax(H,A),syntax(H,B),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(S,[U,V],[X,Y],Suv),s(T,[U\&V],[Z],Tuv),s(T,[E],[Z],Te).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A \emph{spread term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_e$ is an
 instantiation of that type scheme for the base term $E$ and 
 the subterm of the spread term can be proven to be in the 
 corresponding instantiation $T_{u,v}$, and if you can predict the
 type of the base term $using(A\#B)$. 
 In most cases there is no direct
 depency between the type of the decision term and the current
 value of the base term of that decision term. To simplify
 the automatic proof of these wellformedness goals there is
 a \emph{derived rule}, which assumes the result type to be constant.
 Still there is the problem of
 supplying the type information for the base term. For the
 simplest case, that the base term is a single variable, which
 is declared in the hypothesis list, there is again a \emph{derived 
 rule} which simply accesses the declaration from the hypothesis
 list for generating the type of the base term.
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(A\#B),new[U,V,W]),H==$>$spread(E,[X,Y,S]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (A\#B), [U:A,V:B,W:E=U\&V in (A\#B)]==$>$Suv in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},syntax(H,A),syntax(H,B),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(S,[U,V],[X,Y],Suv).
\end{tabbing}\end{sf}

 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U,V,W]),H==$>$spread(E,[X,Y,S]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (A\#B), [U:A,V:B,W:E=U\&V in (A\#B)]==$>$Suv in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},type(E,H,A\#B), free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(S,[U,V],[X,Y],Suv).
\end{tabbing}\end{sf}

 \end{description}
  
 \end{enumerate}
  
  
 \section{Dependent Product Types}
 \inv{dependent product type}
 Dependent product types $x:A\#B$, where $A$ is a type and $B$ denotes
 a family of types $B_{x\in A}$, are a generalisation of 
 Cartesian product types. They consist of ordered pairs $a\&b$, 
 such that $a$ is an element of $A$ and that the second component $b$
 is an element of the type $B_a$, indicated by the first element
 of the pair.
 We can interpret dependent product types $X:A\#B$ as existentially
 quantified propositions: there is an $X$ of type $A$ with property
 $B$. The proof of such an existential proposition consists in
 the intuitionistic framework of an element of the type $A$ and
 a proof of the property $B$ for this $X$, which we might consider
 as ordered pair. There is one selector 
 construct $spread$, a generalisation of the usual
 projection operators: supposed $s=a\&b\;in\;(x:A\#B)$, then 
 $spread(s,[u,v,t])$ is defined to be
 $t_{[a,b/u,v]}$, i.e. $t$ with $u$ and $v$ substituted by the left 
 and right component of $s$ respectively.
 The left projection and the right projection operators could be
 described as $spread(s,[u,\verb'~',u])$ and 
 $spread(s,[\verb'~',v,v])$, respectively.
  
 \subsection{Type Formation}
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(X:A\# {\verb`~`}),H==$>$u(I) \mbox{\it ext} X:A\#B, \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [X:A]==$>$u(I) \mbox{\it ext} B ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),free([X],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:} $X:A\#B$ is a possible refinement
 for any universe, if $A$ is a type, and $B$ is a refinement of
 the same universe under the
 assumption of the existence of some $X$ of type $A$. This is a stepwise
 refinement rule. You make a partial decision (to use a dependent
 product type over $A$),
 but let the type of the second components be open. So there is a
 subgoal stating that your initial universe is inhabited,
 which would result (during further refinement) in some type $B$.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),H==$>$(X:A\#B) in u(I), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(B,[Y],[X],By).
\end{tabbing}\end{sf}

 {\bf membership rule:} $X:A\#B$ is a type of universe level $i$,
 i.e. a member of $u(i)$ if $A$ is a type of universe level $i$,
 and $B_{[Y/X]}$ can be proven to be a type under the assumption of $A$
 being inhabited by an arbitrary element $Y$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),\_\hspace{0.1em}==$>$(X:A\#B)=(XX:AA\#BB) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A=AA in u(I), [Y:A]==$>$By=BBy in u(I) ]):-\\[-0.15ex]
\hspace{2em}s(B,[Y],[X],By),s(BB,[Y],[XX],BBy).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Dependent product types are equal if the left base types are equal
 and the right base types can be proven equal under the assumption
 of the same free variable.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),F,new[Y]),H==$>$X:A\#B \mbox{\it ext} F\&G, \\[-0.15ex]
\hspace{2em}[ ==$>$F in A, ==$>$Bf \mbox{\it ext} G, [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}syntax(H,F),free([Y],H),s(B,[F],[X],Bf),s(B,[Y],[X],By),level(I).\\[-0.15ex]
$\vdash$(intro(\mbox{\it at}(I),F),H==$>$X:A\#B \mbox{\it ext} F\&G, \\[-0.15ex]
\hspace{2em}[ ==$>$F in A, ==$>$Bf \mbox{\it ext} G, [X:A]==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}syntax(H,F),free([X],H),s(B,[F],[X],Bf),level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 If you supply a term $F$, the ordered pairs $F\&G$ may be regarded
 as a refinement of the dependent product type $X:A\#B$ at any
 universe level
 if $F$ is a member of $A$, and $G$ is a refinement of $B_{[F/X]}$,
 and if $B_{[Y/X]}$ can be proven to be a member of that universe
 under the assumption of $Y$ being an arbitrary element of $A$.
 Proving the existence of some $X$ of type $A$ with the property $B$
 requires in the constructive framework always to supply 
 such an element.
 The second rule describes the special case
 where $X$ is a free variable in $H$, and may be used as a
 preferred variable identifier instead of $Y$. This has no 
 influence on the logical interpretation, but allows you to
 exploit the intensional meaning of the variable identifier
 in further proof.
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Y]),H==$>$(F\&G) in (X:A\#B), \\[-0.15ex]
\hspace{2em}[ ==$>$F in A, ==$>$G in Bf, [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(B,[F],[X],Bf),s(B,[Y],[X],By), level(I).\\[-0.15ex]
$\vdash$(intro(\mbox{\it at}(I)),H==$>$(F\&G) in (X:A\#B),\\[-0.15ex]
\hspace{2em}[ ==$>$F in A, ==$>$G in Bf, [X:A]==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([X],H),s(B,[F],[X],Bf),level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}  
 An ordered pair $F\&G$ is a member of the dependent product type
 $X:A\#B$ if $F$ is a member of $A$ and $G$ is a member of $B_{[F/X]}$.
 and if $B_{[Y/X]}$ can be proven to be a member of that universe
 under the assumption of $Y$ being an arbitrary element of $A$.
 The second rule describes the special case
 where $X$ is a free variable in $H$, and may be used as a
 preferred variable identifier instead of $Y$. This has no
 influence on the logical interpretation, but allows you to
 exploit the intensional meaning of the variable identifier
 in further proof.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$U\&V=UU\&VV in (X:A\#B),\\[-0.15ex]
\hspace{2em}[ ==$>$U=UU in A, ==$>$V=VV in Bu ]):-\\[-0.15ex]
\hspace{2em}s(B,[U],[X],Bu).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Pairs are equal in the dependent product type, 
 if the left components are equal in the base type,
 and the right components
 can be proven equal in the corresponding derived type.
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate} 
 \item[9]
\begin{sf}\begin{tabbing}
$\vdash$(elim(Z,new[U,V,N1]),H==$>$T \mbox{\it ext} spread(Z,[U,V,S]),\\[-0.15ex]
\hspace{2em}[ [U:A, V:Bu, N1:Z=U\&V in (X:A\#B)]==$>$Tuv \mbox{\it ext} S ]):-\\[-0.15ex]
\hspace{2em}decl(Z:X:A\#B,H),\\[-0.15ex]
\hspace{2em}( (free( [X,V,N1], H),U=X,Bu=B);\\[-0.15ex]
\hspace{3em}(free([U,V,N1],H),s(B,[U],[X],Bu))\\[-0.15ex]
\hspace{2em}),\\[-0.15ex]
\hspace{2em}!,s(T,[U\&V],[Z],Tuv).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 The elimination of an arbitrary variable of a dependent product
 type in the hypothesis list, generates an \emph{spread} term, the 
 further refinement of which is determined by the subgoal
 of the \emph{elim} step.
  
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(P:A\#B),over(Z,T),new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$spread(E,[X,Y,S]) in Te,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (P:A\#B), \\[-0.15ex]
\hspace{3em}[U:A,V:Bu,W:E=U\&V in (P:A\#B)]==$>$Suv in Tuv ]):-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),\\[-0.15ex]
\hspace{2em}$\tau_{var}$(P),syntax(H,A),syntax([P:\_\hspace{0.1em}$\mid$H],B),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(B,[U],[P],Bu),s(S,[U,V],[X,Y],Suv),\\[-0.15ex]
\hspace{2em}s(T,[U\&V],[Z],Tuv),s(T,[E],[Z],Te).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A \emph{spread term} is of a given type $T_e$ if you can
 supply a type scheme $over(z,T_z)$, such that $T_e$ is an
 instantiation of that type scheme for the base term $E$ and 
 the subterm of the spread term can be proven to be in the 
 corresponding instantiation $T_{u,v}$, and if you can predict the
 type of the base term $using(p:A\#B)$. 
 In most cases there is no direct
 depency between the type of the decision term and the current
 value of the base term of that decision term. To simplify
 the automatic proof of these wellformedness goals there is
 a \emph{derived rule}, which assumes the result type to be constant.
 Still there is the problem of
 supplying the type information for the base term. For the
 simplest case, that the base term is a single variable, which
 is declared in the hypothesis list, there is again a \emph{derived 
 rule} which simply accesses the declaration from the hypothesis
 list for generating the type of the base term.
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(P:A\#B),new[U,V,W]), H==$>$spread(E,[X,Y,S]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (P:A\#B), \\[-0.15ex]
\hspace{3em}[U:A,V:Bu,W:E=U\&V in (P:A\#B)]==$>$Suv in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},syntax(H,A),syntax([P:\_\hspace{0.1em}$\mid$H],B),$\tau_{var}$(P),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(B,[U],[P],Bu),s(S,[U,V],[X,Y],Suv).
\end{tabbing}\end{sf}

 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[U,V,W]), H==$>$spread(E,[X,Y,S]) in T,\\[-0.15ex]
\hspace{2em}[ ==$>$E in (P:A\#B),\\[-0.15ex]
\hspace{3em}[U:A,V:Bu,W:E=U\&V in (P:A\#B)]==$>$Suv in T ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},type(E,H,P:A\#B), free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(B,[U],[P],Bu),s(S,[U,V],[X,Y],Suv).
\end{tabbing}\end{sf}

 \end{description}
 \end{enumerate}
  
  
 \section{Quotient Types}
 \inv{quotient type}
 Quotient types $A///[x,y,E]$ consist of 
 elements $T$ of the basic type $A$ with equality given by the 
 equivalence relation $E_{x,y}$.
  
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(A///[U,V,E],new[X,Y,Z,Wxy,Wyz]),H==$>$u(I) \mbox{\it ext} A///[U,V,E],\\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), \\[-0.15ex]
\hspace{3em}[X:A,Y:A]==$>$Exy in u(I),\\[-0.15ex]
\hspace{3em}[X:A]==$>$Exx, \\[-0.15ex]
\hspace{3em}[X:A,y:A,Wxy:Exy]==$>$Eyx, \\[-0.15ex]
\hspace{3em}[X:A,Y:A,Z:A,Wxy:Exy,Wyz:Eyz]==$>$Exz ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),syntax(H,A///[U,V,E]),free([X,Y,Z,Wxy,Wyz],H),\\[-0.15ex]
\hspace{2em}s(E,[X,Y],[U,V],Exy),s(E,[Y,X],[U,V],Eyx),\\[-0.15ex]
\hspace{2em}s(E,[X,X],[U,V],Exx),s(E,[Y,Z],[U,V],Eyz),s(E,[X,Z],[U,V],Exz).
\end{tabbing}\end{sf}

 {\bf realisation rule:} 
 $A///[x,y,E]$ is a realisation for any universe, 
 if $A$ is a type over the same universe,
 $E$ can be proven to be a type(proposition) under the assumption
 of $x$ and $y$ being elements of the type $A$, and if
 $E$ is a equivalence relation, i.e. $E$ fulfils the usual criteria
 for an equivalence relation.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[X,Y,Z,Wxy,Wyz]),H==$>$(A///[U,V,E]) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), \\[-0.15ex]
\hspace{3em}[X:A,Y:A]==$>$Exy in u(I),\\[-0.15ex]
\hspace{3em}[X:A]==$>$Exx, \\[-0.15ex]
\hspace{3em}[X:A,Y:A,Wxy:Exy]==$>$Eyx, \\[-0.15ex]
\hspace{3em}[X:A,Y:A,Z:A,Wxy:Exy,Wyz:Eyz]==$>$Exz ]):-\\[-0.15ex]
\hspace{2em}free([X,Y,Z,Wxy,Wyz],H),\\[-0.15ex]
\hspace{2em}s(E,[X,Y],[U,V],Exy),s(E,[Y,X],[U,V],Eyx),\\[-0.15ex]
\hspace{2em}s(E,[X,X],[U,V],Exx),s(E,[Y,Z],[U,V],Eyz),s(E,[X,Z],[U,V],Exz).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 $A///[x,y,E]$ is a type of universe level $i$,
 i.e. a member of $u(i)$, under the same conditions as above.
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[R,S,T]),H==$>$(A///[X,Y,E])=(B///[U,V,F]) in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$ (A///[X,Y,E]) in u(I), \\[-0.15ex]
\hspace{3em}==$>$ (B///[U,V,F]) in u(I), \\[-0.15ex]
\hspace{3em}==$>$A=B in u(I),\\[-0.15ex]
\hspace{3em}[T:A=B in u(I),R:A,S:A]==$>$Ers=$>$Frs,\\[-0.15ex]
\hspace{3em}[T:A=B in u(I),R:A,S:A]==$>$Frs=$>$Ers ]):-\\[-0.15ex]
\hspace{2em}free([R,S,T],H),s(E,[R,S],[X,Y],Ers),s(F,[R,S],[U,V],Frs).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two quotient types are equal if the corresponding base types
 are equal and the defining relations can be proved to be equivalent.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$A///[X,Y,E] \mbox{\it ext} T, \\[-0.15ex]
\hspace{2em}[ ==$>$A \mbox{\it ext} T, ==$>$ (A///[X,Y,E]) in u(I) ]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 Any refinement $T$ of the base type of a quotient type 
 may be
 used as a refinement of the quotient type at any universe level,
 if the quotient type is a member of that universe. 
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$T in (A///[X,Y,E]), \\[-0.15ex]
\hspace{2em}[ ==$>$T in A, ==$>$ (A///[X,Y,E]) in u(I) ]):-\\[-0.15ex]
\hspace{2em}noequal(T),level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}  
 ${T}$ is an element of the quotient type at a given universe level
 if $T$ is an element of the base type of that quotient type,
 and if the quotient type is a member of the given universe.
  
 \item[7]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$T=TT in (A///[X,Y,E]),\\[-0.15ex]
\hspace{2em}[ ==$>$ (A///[X,Y,E]) in u(I), ==$>$T in A, ==$>$TT in A, ==$>$Ett ]):-\\[-0.15ex]
\hspace{2em}s(E,[T,TT],[X,Y],Ett),level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two equivalence classes are equal, if their representatives are
 both members of the base type, and the equivalence relation
 can be proven between them.
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate}
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(elim(\mbox{\it at}(I),U,new[V,W,WE]),H==$>$S=SS in Tu,\\[-0.15ex]
\hspace{2em}[ [V:A,W:A]==$>$Evw in u(I),\\[-0.15ex]
\hspace{3em}==$>$Tu in u(I),\\[-0.15ex]
\hspace{3em}[V:A,W:A,WE:Evw]==$>$Sv=SSw in Tv ]):-\\[-0.15ex]
\hspace{2em}decl(U:(A///[X,Y,E]),H), free([V,W,WE],H),\\[-0.15ex]
\hspace{2em}s(E,[V,W],[X,Y],Evw),s(Tu,[V],[U],Tv),\\[-0.15ex]
\hspace{2em}s(S,[V],[U],Sv),s(SS,[W],[U],SSw),\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 \end{enumerate}
 {\bf equality rule:}
 If you want to prove an equality which depends on  an element $U$
 of a quotient type, or more exactly, which depends on the
 fact that a quotient type is inhabited, than it is enough to
 prove the equality for $U$ on both sides of the equality substituted
 by two arbitrary members of the equivalence class described by $U$.
 \begin{enumerate}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(elim(\mbox{\it at}(I),U,new[V,W,WE]),H==$>$S in Tu,\\[-0.15ex]
\hspace{2em}[ [V:A,W:A]==$>$Evw in u(I),\\[-0.15ex]
\hspace{3em}==$>$Tu in u(I),\\[-0.15ex]
\hspace{3em}[V:A,W:A,WE:Evw]==$>$SSv=SSw in Tv ]):-\\[-0.15ex]
\hspace{2em}decl(U:(A///[X,Y,E]),H), free([V,W,WE],H),\\[-0.15ex]
\hspace{2em}s(E,[V,W],[X,Y],Evw),s(Tu,[V],[U],Tv),\\[-0.15ex]
\hspace{2em}s(S,[V],[U],SSv), s(S,[W],[U],SSw), \\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 If you want to prove a membership goal which depends on  an element $U$
 of a quotient type, or more exactly, which depends on the
 fact that a quotient type is inhabited, then it is enough to
 prove equality of two new terms, corresponding to terms related by the 
 equivalence relation $U$.
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(elim(\mbox{\it at}(I),D,new[WE]),H==$>$G,\\[-0.15ex]
\hspace{2em}[ ==$>$ (A///[X,Y,E]) in u(I),\\[-0.15ex]
\hspace{3em}[WE:Evw]==$>$ G]):-\\[-0.15ex]
\hspace{2em}decl(D:(V=W in (A///[X,Y,E])),H), free([WE],H),\\[-0.15ex]
\hspace{2em}s(E,[V,W],[X,Y],Evw),\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 If you want to prove a goal which depends on  an equality between
 elements of a quotient type, then the extra hypothesis that the
 elements are related by the equivalence relation can be added
 (provided that the quotient type is well-formed).
 
 \end{enumerate}
  
 \section{Subset Types}
 \inv{subset type}
  
 Set types project the mathematical idea of \emph{sets} into the
 the type theoretic framework: A subset $\{X:A\backslash B\}$ 
 should consist of exactly the elements $X$ of $A$ which
 fulfil the property $B$, the equality relation is the same as in
 the basic type of the set, all operations over the basic type are
 directly applicable over the set type.
 But this approach contradicts basic assumptions of the 
 intuitionism. 
 Strictly speaking the elements of a subset 
 $\{X:A\backslash B\}$ should be pairs $x\&b$, where $x$ is an
 element of $A$ and $b$ is an element of $B_x$, i.e. a proof
 that $x$ fulfils the defining property of the set.
 This concept of sets could easily be simulated using the
 dependent product types.
 But using this strict interpretation leads to a lot of problems
 in practical work. It would be impossible to use the
 operations which are defined on the basic type directly on the
 subset type. You can imagine the effort that would be necessary,
 to work in natural numbers, defined as a subset of the type \emph{int},
 if there were no access to the operations and rules 
 available for integers. 
 To overcome this dilemma, we opted for a compromise:
 The elements of the set type are really the elements the
 basic type, but they are connected with a hidden information,
 the extract term of the proof that these elements belong to  
 the subset. If you refer to a hypothesis stating that a
 certain element belongs to a subset, you can use the fact that
 the defining property of the subset is fulfilled by that
 element. But as soon as you use this property in a constructive
 way, the extract term of your proof becomes tagged with an
 $assert(...)$ term, describing the characteristic property
 of the set type. Such an $assert(...)$ term is in general
 not executable, because it requires the proof of the property
 at run time. For certain simple properties this can be done.
 But this is not the point: the main idea is that 
 these $assert(...)$ terms are hidden in the
 extract term of the top level goal in most applications, because
 they appear in subgoals of a proof step which yields a constant
 extract term (for example \emph{axiom}).
 That means you can use the subset types in the ordinary mathematical
 sense: all operations and functions defined on the basic type
 are directly available on the subset, but you should not use the
 defining property of a set type in constructive parts of the
 proof. If you are not sure about the effects, test the
 extract term of the top level goal. 
  
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\{X:A$\backslash$ {\verb`~`}\}),H==$>$u(I) \mbox{\it ext} \{X:A$\backslash$B\}, \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [X:A]==$>$u(I) \mbox{\it ext} B ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A),free([X],H).
\end{tabbing}\end{sf}

 {\bf refinement rule:} 
 $\{X:A\backslash B\}$ is a possible refinement
 for any universe, if $A$ is a type in that universe,
 and $B$ is a refinement of the same universe under the assumption of 
 $X$ being an arbitrary element of $A$.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),H==$>$\{X:A$\backslash$B\} in u(I), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(B,[Y],[X],By).\\[-0.15ex]
$\vdash$(intro,H==$>$\{X:A$\backslash$B\} in u(I), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), [X:A]==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([X],H).
\end{tabbing}\end{sf}

 {\bf membership rule:} 
 $\{X:A\backslash B\}$ is a type of universe level $i$,
 i.e. a member of $u(i)$, if $A$ is a type in $u(i)$ and $B[Y/X]$ can 
 be proven to be a type in the same universe under the assumption of $Y$
 being an arbitrary element of $A$.
  
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Z]),H==$>$\{X:A$\backslash$B\}=\{Y:AA$\backslash$BB\} in u(I),\\[-0.15ex]
\hspace{2em}[ ==$>$A=AA in u(I), \\[-0.15ex]
\hspace{3em}[Z:A]==$>$Bz=$>$BBz, \\[-0.15ex]
\hspace{3em}[Z:A]==$>$BBz=$>$Bz ]):-\\[-0.15ex]
\hspace{2em}free([Z],H),s(B,[Z],[X],Bz),s(BB,[Z],[Y],BBz).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two set types are equal if the base types are equal and the
 defining relations can be proven to be equivalent over the
 base type.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),T,new[Y]),H==$>$\{X:A$\backslash$B\} \mbox{\it ext} T, \\[-0.15ex]
\hspace{2em}[ ==$>$T in A, ==$>$BB, [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}syntax(H,T),free([Y],H), s(B,[T],[X],BB),s(B,[Y],[X],By),level(I).\\[-0.15ex]
$\vdash$(intro(\mbox{\it at}(I),T),H==$>$\{X:A$\backslash$B\} \mbox{\it ext} T,\\[-0.15ex]
\hspace{2em}[ ==$>$T in A, ==$>$BB, [X:A]==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}syntax(H,T),free([X],H), s(B,[T],[X],BB),level(I).
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 If you supply a term $T$, this term may be regarded
 as a realisation of the set type $\{X:A\backslash B\}$ at any
 universe level
 if $T$ is a member of $A$ and fulfils $B$,
 i.e. $B_{[T/X]}$ can be proven,
 and if $B_{[Y/X]}$ can be proven to be a member of that universe
 under the assumption of $Y$ being an arbitrary element of $A$.
 Proving the existence of some $X$ of type $A$ with the property $B$
 requires in the constructive framework always the exhibition
 of a term
 yielding such an element, and the proof of the defining
 property of the subset.
 The second rule describes the special case
 where $X$ is a free variable in $H$, and may be used as a
 preferred variable identifier instead of $Y$. This has no 
 influence on the logical interpretation, but allows you to
 exploit the intensional meaning of the variable identifier
 in further proof.
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Y]),H==$>$T in \{X:A$\backslash$B\},\\[-0.15ex]
\hspace{2em}[ ==$>$T in A, ==$>$BB, [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}noequal(T),free([Y],H),s(B,[T],[X],BB),s(B,[Y],[X],By), level(I).\\[-0.15ex]
$\vdash$(intro(\mbox{\it at}(I)),H==$>$T in \{X:A$\backslash$B\},\\[-0.15ex]
\hspace{2em}[ ==$>$T in A, ==$>$BB, [X:A]==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}noequal(T),free([X],H),s(B,[T],[X],BB),level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 $T$ is a member of a set type, if $T$ is a member of the
 base type and the defining property of the set type can be
 proven for $T$.
  
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[Y]),H==$>$T=TT in \{X:A$\backslash$B\},\\[-0.15ex]
\hspace{2em}[ ==$>$T=TT in A, ==$>$BB, [Y:A]==$>$By in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(B,[T],[X],BB),s(B,[Y],[X],By), level(I).\\[-0.15ex]
$\vdash$(intro(\mbox{\it at}(I)),H==$>$T=TT in \{X:A$\backslash$B\},\\[-0.15ex]
\hspace{2em}[ ==$>$T=TT in A, ==$>$BB, [X:A]==$>$B in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([X],H),s(B,[T],[X],BB),level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 Two elements of a set type are equal if they are equal in the
 base type.
  
 \end{enumerate}
  
 \subsection{Selectors}
 \begin{enumerate}
 \item[9]
\begin{sf}\begin{tabbing}
$\vdash$(elim(\mbox{\it at}(I),U,new[X,Y,Z]),H==$>$T \mbox{\it ext} $\sigma$(F,[U,assert(Bu)],[X,Y]),\\[-0.15ex]
\hspace{2em}[ [X:A]==$>$Bx in u(I), \\[-0.15ex]
\hspace{3em}[X:A,Y:Bu,Z:X=U in A]==$>$Tu \mbox{\it ext} F ]):-\\[-0.15ex]
\hspace{2em}decl(U:\{V:A$\backslash$B\},H), free([X,Y,Z],H), \\[-0.15ex]
\hspace{2em}s(B,[X],[V],Bx),s(B,[U],[V],Bu),s(T,[X],[U],Tu),level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 This rule describes exactly the effect of exploiting the 
 characteristic property of a set appearing in the hypothesis list.
 There is a derived rule, which handles the special case, that
 you can infer that an element $X$ is an element of the base
 type of a set, if you know that $X$ is an element of an subtype. 
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,H==$>$X in T, []):-\\[-0.15ex]
\hspace{2em}{\bf derived},member(X:\{\_\hspace{0.1em}:TT$\backslash$\_\hspace{0.1em}\},H), $\alpha$(T,TT).
\end{tabbing}\end{sf}

 \end{description}
 \end{enumerate}
  
  
 \section{Recursive Types}
 \inv{recursive type}
 
 Recursive types have the general form $rec(z,B_z)$, where $z$
 is a free variable in $B_z$.
 Invariably the form used is $rec(z,A\backslash B_z)$,  where $z$ 
 does not appear in A.
 $A$ is called the \emph{base type} and $B_z$ the \emph{iterator}
 of the recursive type. 
 The elements of such an recursive type are left injection terms
 built from the elements of $A$, and right injection terms built
 up from elements of the order $n$$>$$0$ of $B_z$ according to the
 iterator. Elements of the order $1$ of $B_z$ are those elements which
 are built up assuming as basis elements of $z$ only left injection
 terms from $A$. Elements of the order $n$$>$$1$ of $B_z$ are those  
 which are built up assuming as basis elements of $z$ only left
 injection terms from $A$ or right injection terms from elements
 of the order $n-1$ of $B_z$. Occurrences of the free variable
 are not allowed in the left hand side of function type, of
 in a functiom application, or in the first argument of an induction term.
 
 Let us consider as an example the type $rec(z,int\backslash z\#z)$, 
 which defines exactly the type of binary trees over the type $int$.
 Elements of  $rec(z,int\backslash z\#z)$ are for example:
 \begin{verbatim}
     inl(i1),
     inr(inl(i1) & inl(i2)),
     inr(inr(inl(i1) & inl(i2)) & inl(i3)),
     inr(inr(inl(i1) & inr(inl(i2) & inl(i3))) & inl(i4)), \end{verbatim}
 where the $i_j$ are elements of the base type $int$.
 
 The construction of elements of a recursive type is described
 using the constructors for the base type $A\backslash B_z$.
 For recursive types there is a selector term $rec\_ind(x,[v,w,t])$ 
 defined which describes a term of a type $T$ as if there were 
 a (recursive) mapping from the type $rec(z,A\backslash B_z)$ into $T$,
 defined by $t$, which decides whether the argument $w$ is a left
 injection term coming from $A$ or is constructed in some other way
 from elements of the recursive type again. In the latter case
 it is assumed that $v$ already describes a mapping for the
 terms of lower order into $T$, which might be applied
 on the appropriate subterms extracted from $w$. 
 
 Let us consider again the type of binary trees over integers
 $rec(z,int\backslash z\#z)$. The \emph{weight} of a tree, i.e. the
 sum of the integers in the tips of that tree could be defined 
 by the induction term:
 \begin{verbatim}
  rec_ind(x,[v,w,decide(w,[i,i], 
                     [p,spread(p,[l,r,v of l+v of r])])]) \end{verbatim}
 for $x=inl(i_1)$ this term would obviously yield $i_1$, for
 $x=inr(inl(i_1)\&inl(i_2))$ the variable $p$ would become bound
 to $inl(i_1)\&inl(i_2)$ which results in $l$ and $r$ becoming
 $inl(i_1)$ and $inl(i_2)$ respectively. The recursive application
 of $v$ yields then $i_1$ and $i_2$ which gives together the value
 $inl(i_1)+inl(i_2)$ for the induction term.
 
 Let $rec(z,A\backslash B_z)$ be an arbitrary recursive type, then the type
 $B'$ obtained from $B_z$ by substituting the recursive type itself 
 for $z$ has exactly the same members as the recursive type. 
 Therefore $B'$ could be considered as another (unrolled) 
 representation for the same (recursive) type. 
 
 \subsection{Type Formation}
 
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[Y]),H==$>$rec(Z,T) in u(I), \\[-0.15ex]
\hspace{2em}[  [Y:u(I)]==$>$Ty in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Y],H),s(T,[Y],[Z],Ty),\\[-0.15ex]
\hspace{2em}$\backslash$+ illegal\_\hspace{0.1em}rec\_\hspace{0.1em}type(rec(Z,T)). 
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A recursive type is a member of a given universe, if its base
 type is a member of that universe, and if under the assumption
 of $y$ being an arbitrary member of that universe 
 the iterator applied on $y$ can be proven to be a member of
 that universe too.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$rec(Z,T) \mbox{\it ext} X, \\[-0.15ex]
\hspace{2em}[ ==$>$TT \mbox{\it ext} X, ==$>$rec(Z,T) in u(I) ]):-\\[-0.15ex]
\hspace{2em}s(T,[rec(Z,T)],[Z],TT), level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 A refinement for any recursive type can be constructed
 as a refinement of the unrolled recursive type. 
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$X in rec(Z,T), \\[-0.15ex]
\hspace{2em}[ ==$>$X in TT, ==$>$rec(Z,T) in u(I) ]):-\\[-0.15ex]
\hspace{2em}s(T,[rec(Z,T)],[Z],TT), level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A term $X$ is a member of a recursive type, if $X$ can be
 proven to be a member of the unrolled recursive type. 
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(unroll(X,new[Y,Z]),H==$>$G \mbox{\it ext} $\sigma$(F,[axiom,X],[Z,Y]), \\[-0.15ex]
\hspace{2em}[ [Y:TT,Z:Y=X in TT]==$>$GG \mbox{\it ext} F ]):-\\[-0.15ex]
\hspace{2em}decl(X:rec(V,T),H), free([Y,Z],H),\\[-0.15ex]
\hspace{2em}s(T,[rec(V,T)],[V],TT),s(G,[Y],[X],GG).
\end{tabbing}\end{sf}

 {\bf equality rule:}
 For each variable of a recursive type one can derive an element
 of the unrolled type, which is equal to the original one.
 There is a derived rule, which allows the efficient handling of
 wellformedness goals generated in proofs concerning recursive
 types.
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,H==$>$X in T0,[]):-\\[-0.15ex]
\hspace{2em}{\bf derived},decl(X:rec(V,T),H),s(T,[rec(V,T)],[V],TT),$\alpha$(TT,T0).
\end{tabbing}\end{sf}

 \end{description}
 \end{enumerate}
  
 \subsection{Selectors}
  
 \begin{enumerate}
  
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(elim(\mbox{\it at}(I),X,new[U,U0,V,W]),H==$>$G \mbox{\it ext} rec\_\hspace{0.1em}ind(X,[V,W,F]),\\[-0.15ex]
\hspace{2em}[ [U:u(I), U0:X:U=$>$(X in rec(Z,T)), \\[-0.15ex]
\hspace{3em}V:X:U=$>$G, \\[-0.15ex]
\hspace{3em}W:TT]==$>$Gw \mbox{\it ext} F ]):-\\[-0.15ex]
\hspace{2em}decl(X:rec(Z,T),H), free([U,U0,V,W],H), \\[-0.15ex]
\hspace{2em}s(G,[W],[X],Gw),s(T,[U],[Z],TT), level(I).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 Supposed $U$ is an arbitrary subtype of the recursive type,
 (this property is described by $U_0$)
 and $V$ is already declared as a mapping from that subtype
 into $G$, and is $W$ an element of the next higher
 level of unrolling, i.e. an element of $A\backslash B_u$,
 and $G$ can be refined to $F$ then we can extend this 
 structural induction step into a fully defined induction term.   
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),using(rec(Z,T)),over(X,S),new[U,U0,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$rec\_\hspace{0.1em}ind(R,[G,J,K]) in Sr,\\[-0.15ex]
\hspace{2em}[ [U:u(I), U0:W:U=$>$(W in rec(Z,T)), V:(W:U=$>$Su),W:Tu]==$>$KK in Su, \\[-0.15ex]
\hspace{3em}==$>$R in rec(Z,T) ]):-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(X),syntax([X:\_\hspace{0.1em}$\mid$H],S),$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),\\[-0.15ex]
\hspace{2em}free([U,U0,V,W],H), level(I), s(S,[R],[X],Sr),\\[-0.15ex]
\hspace{2em}s(S,[U],[X],Su), s(T,[U],[Z],Tu),s(K, [V,W], [G,J], KK). 
\end{tabbing}\end{sf}

 {\bf membership rule:}
 Suppose that $U$ is an arbitrary subtype of the recursive type
 provided (property $U_0$), and $V$ is a mapping into the
 corresponding type, supplied by the type scheme $over(x,S)$,
 and $W$ is an element of the next higher level of unrolling.
 If one can prove under these assumptions that the base term
 really belongs to the recursive type supplied, then 
 the value of the structural induction term belongs to the appropriate
 instantiation of $S$.
 Again there are derived rules handling the most usual cases of
 a constant type scheme and a directly accessible declaration 
 for the base term.
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),using(rec(Z,T)),new[U,U0,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$rec\_\hspace{0.1em}ind(R,[G,J,K]) in S,\\[-0.15ex]
\hspace{2em}[ [U:u(I), U0:W:U=$>$(W in rec(Z,T)), V:(W:U=$>$S),W:Tu]==$>$KK in S, \\[-0.15ex]
\hspace{3em}==$>$R in rec(Z,T) ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},syntax([Z:\_\hspace{0.1em}$\mid$H],T),$\tau_{var}$(Z),free([U,U0,V,W],H), level(I),\\[-0.15ex]
\hspace{2em}s(T,[U],[Z],Tu),s(K, [V,W], [G,J], KK).
\end{tabbing}\end{sf}

 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),new[U,U0,V,W]),H==$>$rec\_\hspace{0.1em}ind(R,[G,J,K]) in S,\\[-0.15ex]
\hspace{2em}[ [U:u(I), U0:W:U=$>$(W in rec(Z,T)), V:(W:U=$>$S),W:Tu]==$>$KK in S,\\[-0.15ex]
\hspace{3em}==$>$R in rec(Z,T) ]):-\\[-0.15ex]
\hspace{2em}{\bf derived},type(R,H,rec(Z,T)), free([U,U0,V,W],H), level(I),\\[-0.15ex]
\hspace{2em}s(T,[U],[Z],Tu),s(K,[V,W],[G,J], KK).
\end{tabbing}\end{sf}

 \end{description}%  
 \end{enumerate}
  
 \section{Acc Types}
 \inv{acc type}
  
 $Acc$ types have the general form $acc(A,R)$. $A$, the base type, is a set
 well-ordered by the relation $R$. For $acc$ types there is a selector term
 $wo\_ind(X,[W,U,Ts])$. Here $X$ is the recursion argument. Let us suppose
 that (a) $W:A$ and (b) that if $U$ is a member of the dependent function
 type mapping members $V$ of the subset $\{V:A \backslash R\ of\ V\ of\ W\}$
 onto members of a type $T(V)$ depending on $V$, then $T$ is a member of
 $T(W)$. Then $wo\_ind(X,[W,U,Ts]$) is a member of $T(X)$.
 
 \subsection{Type Formation}
  
 \begin{description}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(acc(A,{\verb`~`})),H==$>$u(I) \mbox{\it ext} acc(A,R),\\[-0.15ex]
\hspace{2em}[==$>$A in u(I), ==$>$(A=$>$A=$>$u(I)) \mbox{\it ext} R]):-\\[-0.15ex]
\hspace{2em}syntax(H,A).
\end{tabbing}\end{sf}

 {\bf refinement rule:} $acc(A,R)$ is a possible refinement for any universe,
 if $A$ is a type in that universe, and $R$ is a refinement of $A=>A=>u(I)$.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$acc(A,R) in u(I),\\[-0.15ex]
\hspace{2em}[==$>$A in u(I),==$>$R in (A=$>$A=$>$u(I))]).
\end{tabbing}\end{sf}

 {\bf membership rule:} $acc(A,R)$ is a type of universe level,i.e. a member
 of $u(I)$, if $A$ is a type in that universe, and $R$ is a member of
 $A=>A=>u(I)$.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(new[X,Y]),H==$>$acc(A,R)=acc(Ax,Rx) in u(I),\\[-0.15ex]
\hspace{2em}[==$>$A=Ax in u(I),\\[-0.15ex]
\hspace{2em}[X:A,Y:A]==$>$R of X of Y =$>$ Rx of X of Y,\\[-0.15ex]
\hspace{2em}[X:A,Y:A]==$>$Rx of X of Y =$>$ R of X of Y]):-\\[-0.15ex]
\hspace{2em}free([X,Y],H).
\end{tabbing}\end{sf}

 {\bf equality rule:} Two $acc$ types are equal if the
 base types are equal and the defining relations can be proved to be
 equivalent over the base type.
 \end{description} %  
 \subsection{Constructors}
  
 \begin{description}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),X,new[U,V]),H==$>$acc(A,R) \mbox{\it ext} X,\\[-0.15ex]
\hspace{2em}[==$>$X in A,[V:A,U:R of V of X]==$>$V in acc(A,R),\\[-0.15ex]
\hspace{2em}==$>$acc(A,R) in u(I)]):-\\[-0.15ex]
\hspace{2em}syntax(H,X),free([U,V],H),level(I).
\end{tabbing}\end{sf}

 {\bf realisation rule:} If you supply a term $X$, this term may be regarded
 as a realisation of the acc type $acc(A,R)$ at any universe level if $X$
 is a member of $A$, and if $V$ can be proved to be a member of $acc(A,R)$
 on the assumption that $V$ is a member of $A$ and $R\ of\ V\ of X$, and that
 $acc(A,R)$ is a member of universe $u(I)$.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I),acc,new[U,V]),H==$>$X in acc(A,R), \\[-0.15ex]
\hspace{2em}[==$>$X in A,[V:A,U:R of V of X]==$>$V in acc(A,R),\\[-0.15ex]
\hspace{2em}==$>$acc(A,R) in u(I)]):-\\[-0.15ex]
\hspace{2em}free([U,V],H),level(I).
\end{tabbing}\end{sf}

 {\bf membership rule:} $X$ is a member of the the $acc$ type $acc(A,R)$
 if $X$ is a member of $A$, and if $V$ can be proved to be a member of
 $acc(A,R)$ on the assumption that $V$ is a member of $A$ and
 $R\ of\ V\ of\ X$, and that $acc(A,R)$ is a member of universe $u(I)$.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$T=Tx in acc(A,R),\\[-0.15ex]
\hspace{2em}[==$>$T=Tx in A,==$>$R in (A=$>$A=$>$u(I))]):-\\[-0.15ex]
\hspace{2em}level(I).
\end{tabbing}\end{sf}

 {\bf equality rule:} Two elements of an $acc$ type are
 equal if they are equal on the base type.
 \end{description}
  
 \subsection{Selectors}
  
 \begin{description}
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(elim(X,wo,new[U,V,W]),H==$>$T \mbox{\it ext} wo\_\hspace{0.1em}ind(X,[W,U,Ts]),\\[-0.15ex]
\hspace{2em}[[W:A,U:(V:\{V:A$\backslash$R of V of W\}=$>$Tsv)] ==$>$ Tsw \mbox{\it ext} Ts]):-\\[-0.15ex]
\hspace{2em}decl(X:acc(A,R),H),free([U,V,W],H), \\[-0.15ex]
\hspace{2em}s(T, [V], [X], Tsv),\\[-0.15ex]
\hspace{2em}s(T, [W], [X], Tsw).
\end{tabbing}\end{sf}

 {\bf refinement rule:} The elimination of an arbitrary variable of type
 $acc(A,R)$ in the hypothesis list, generates an induction term, the
 further refinement of which is determined by the subgoals of the elim step.
 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(acc(A,R)),over(Z,T),new[U,V,W]),\\[-0.15ex]
\hspace{2em}H==$>$wo\_\hspace{0.1em}ind(E,[X,Y,Ts]) in Te,\\[-0.15ex]
\hspace{2em}[==$>$E in acc(A,R),\\[-0.15ex]
\hspace{2em}[V:(W:\{U:A$\backslash$R of U of E\}=$>$Tsw)]==$>$Tsev in Te]):-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T),free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(T,[E],[Z],Te),\\[-0.15ex]
\hspace{2em}s(Ts,[E,V],[X,Y],Tsev),\\[-0.15ex]
\hspace{2em}s(T,[W],[Z], Tsw).
\end{tabbing}\end{sf}

 {\bf membership rule:} An induction term is of a given type $Te$ if you can
 supply a type schema $over(Z,T)$, such that $Te$ is an instantiation of
 that type schema for $E$ and the subterm of the induction term can be
 proved to be in the corresponding $Ts$. To simplify the automatic proof of
 these well-formedness goals there is a derived rule, which asssumes
 the result type to be constant.
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(intro(using(acc(A,R)),new[U,V,W]),H==$>$wo\_\hspace{0.1em}ind(E,[X,Y,Ts]) in T,\\[-0.15ex]
\hspace{2em}[==$>$E in acc(A,R),\\[-0.15ex]
\hspace{2em}[V:(W:\{U:A$\backslash$R of U of E\}=$>$T)]==$>$Tsev in T]):-\\[-0.15ex]
\hspace{2em}{\bf derived},free([U,V,W],H),\\[-0.15ex]
\hspace{2em}s(Ts,[E,V],[X,Y],Tsev).
\end{tabbing}\end{sf}

 \item[$\bullet$]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(using(acc(A,R))),H==$>$wo\_\hspace{0.1em}ind(E,[X,Y,T])=Tsev in \_\hspace{0.1em},\\[-0.15ex]
\hspace{2em}[==$>$E in acc(A,R)]):-\\[-0.15ex]
\hspace{2em}free([R],H),\\[-0.15ex]
\hspace{2em}s(T,[E,lambda(R,wo\_\hspace{0.1em}ind(R,[X,Y,T]))],[X,Y],Tsev).
\end{tabbing}\end{sf}

 {\bf equality rule:} This rule describes the value of the induction term
 under certain assumptions.
 \end{description}
  
  
 \section{Membership and Equality}
 \inv{membership type scheme} \inv{equality type scheme}
  
 $Membership$ and $equality$ are type schemes which have been
 introduced to keep the
 theoretical system closed. For each term $A$ and $T$,
 $A \;in \;T$ is a type
 if $T$ is a type  and $A$ is a member of $T$.
 Analogous $A=B\;in\;T$ is a type for
 any type $T$ and arbitrary elements $A$ and $B$ of $T$.
 The membership and equality terms are inhabited by axiom,
 if there is a proof for membership or equality.
 In this section only the \emph{catch all} rules
 for membership and equality are given. The domain specific rules,
 which exploit the particular structure of the subterms,
 are given in the sections corresponding to the type of
 those subterms.
  
 \subsection{Type Formation}
  
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} in A),H==$>$u(I) \mbox{\it ext} (X in A), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), ==$>$A \mbox{\it ext} X ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 Any membership term over an arbitrary type $A$ is a type. 
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(X in A) in u(I), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), ==$>$X in A ]):-\\[-0.15ex]
\hspace{2em}noequal(X).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The membership term $X\;in\;A$ is a type if $A$ is a type and
 $X$ is a member of $A$.
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro({\verb`~`} = {\verb`~`} in A),H==$>$u(I) \mbox{\it ext} (X=Y in A), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), ==$>$A \mbox{\it ext} X, ==$>$A \mbox{\it ext} Y ]):-\\[-0.15ex]
\hspace{2em}syntax(H,A).
\end{tabbing}\end{sf}

 {\bf refinement rule:}
 Any equality term over an arbitrary type $A$ is a type.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$(X=Y in A) in u(I), \\[-0.15ex]
\hspace{2em}[ ==$>$A in u(I), ==$>$X in A, ==$>$Y in A]):-!.
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The equality term $X=Y\;in\;A$ is a type, if $A$ is a type
 and $X$ and $Y$ are members of $A$.
 \end{enumerate}
  
 \subsection{Constructors}
  
 \begin{enumerate}
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(intro,H==$>$X in T,[]):-\\[-0.15ex]
\hspace{2em}noequal(X),decl(X:TT,H),$\alpha$(TT,T).
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 If a variable $X$ is declared to be of the type $T$ then it
 is a member of $T$, and the membership term refines to $axiom$.
  
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(\mbox{\it at}(I)),\_\hspace{0.1em}==$>$X=XX in T, [ ==$>$T in u(I), ==$>$X in T ]):-\\[-0.15ex]
\hspace{2em}$\alpha$(X,XX),level(I),$\backslash$+((T=u(J),I=$<$J)).
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 The equality term $X=X'\;in\;T$ refines to axiom, if the two 
 terms $X$ and $X'$ are syntactically equivalent, i.e. if they are 
 identical except for possible renaming of bound variables,
 and if $T$ is a type and $X$ and/or $X'$ is a member of $T$. 
  
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$axiom in (X in A), [ ==$>$X in A]):- noequal(X).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The membership type $X\;in\;A$ is inhabited by axiom, if $X$ is a
 member of $A$.
  
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$axiom in (X=Y in A), [ ==$>$X=Y in A]).
\end{tabbing}\end{sf}

 {\bf membership rule:}
 The equality type $X=Y\;in\;A$ is inhabited by axiom, if $X$ is
 equal to $Y$ in $A$. 
 \end{enumerate}
  
 \section{Universes}
 \inv{universes}
  
 \subsection{Type Formation}
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(intro(u(I)),\_\hspace{0.1em}==$>$u(J) \mbox{\it ext} u(I),[]):- level(I),I$<$J.
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 Lower universes are realisations for higher universes.
  
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(intro,\_\hspace{0.1em}==$>$u(I) in u(J),[]):- I$<$J.
\end{tabbing}\end{sf}

 {\bf membership rule:}
 A lower universe is a member of a higher universe.
 \end{enumerate}
  
 \subsection{Constructors}
 \begin{enumerate}
 \item[$\bullet$]
 {\bf refinement rules} and {\bf membership rules:}
 The type formation rules in the preceding chapters may be
 considered as refinement and membership rules for constructors 
 in $u(i)$.
  
 \item[6]
\begin{sf}\begin{tabbing}
$\vdash$(intro(u(I)),\_\hspace{0.1em}==$>$T in u(J), [ ==$>$T in u(I) ]):-\\[-0.15ex]
\hspace{2em}level(I),I$<$J.
\end{tabbing}\end{sf}

 {\bf membership rule:}
 This rule describes the \emph{cumulativity} of the chain of universes.
 There is a derived rule which handels the case of a single
 variable being an element of a universe.
 \begin{description}
 \item[$\circ$] 
\begin{sf}\begin{tabbing}
$\vdash$(intro,H==$>$X in u(I), []):-\\[-0.15ex]
\hspace{2em}{\bf derived}, decl(X: u(J),H), J$<$I.
\end{tabbing}\end{sf}

 \end{description}
 \end{enumerate}
  
  
 \section{Miscellaneous}
 This section contains rules which are applicable in most situations,
 so it makes no sense to return the corresponding rule specifications
 in response to an enquiry of the form $apply(X)$.
 \begin{enumerate}
 \item[0]
\begin{sf}\begin{tabbing}
$\vdash$(X,\_\hspace{0.1em},\_\hspace{0.1em}):-var(X),!,fail.
\end{tabbing}\end{sf}

 \end{enumerate}
  
 \subsection{hypothesis}
 \begin{enumerate}
 \item[1]
\begin{sf}\begin{tabbing}
$\vdash$(hyp(V),H==$>$V in T,[]):-\\[-0.15ex]
\hspace{2em}atom(V),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}decl(V:TT,H),\\[-0.15ex]
\hspace{2em}$\alpha$(T,TT).\\[-0.15ex]
$\vdash$(hyp(X),H==$>$A in T \mbox{\it ext} X,[]):-\\[-0.15ex]
\hspace{2em}$\backslash$+ A = (\_\hspace{0.1em}=\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}decl(X:HT,H),\\[-0.15ex]
\hspace{2em}( HT = (AA in TT); HT = (AA=\_\hspace{0.1em} in TT); HT =(\_\hspace{0.1em}=AA in TT)),\\[-0.15ex]
\hspace{2em}$\alpha$(T,TT),\\[-0.15ex]
\hspace{2em}$\alpha$(A,AA).\\[-0.15ex]
$\vdash$(hyp(X),H==$>$A \mbox{\it ext} X,[]):-\\[-0.15ex]
\hspace{1em}decl(X:AA,H),$\alpha$(A,AA).\\[-0.7ex]

\end{tabbing}\end{sf}

 This rules enforces the direct application of a hypothesis
 for proving the current goal. In the standard mode of operation
 the hypothesis list is checked before any attempt to prove 
 a goal. But this test is switched off in the \emph{pure} mode.
 Therefore you can use the \emph{hyp} rule.
 Furthermore this rule simplifies the proof of membership
 goals if you have a suitable equality in the hypothesis list.
 \end{enumerate}
  
 \subsection{sequence}
 \begin{enumerate}
 \item[2]
\begin{sf}\begin{tabbing}
$\vdash$(seq(T,new[X]),H==$>$G \mbox{\it ext} lambda(X,E)of F,\\[-0.15ex]
\hspace{2em}[ ==$>$T \mbox{\it ext} F, [X:T]==$>$G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}syntax(H,T),free([X],H).
\end{tabbing}\end{sf}

 The \emph{seq}-rule provides some element of \emph{bottom up
 programming} or \emph{forward chaining} to the logic, which 
 allows a better global structuring of the proof tree and the
 synthesised programs. 
 \end{enumerate}
 \subsection{thinning}
 \begin{enumerate}
 \item[3]
\begin{sf}\begin{tabbing}
$\vdash$(thin(ToThin), H==$>$G \mbox{\it ext} E,\\[-0.15ex]
\hspace{2em}[ (-ThinL) ==$>$ G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}freevarsinterm( G, NotThin ),\\[-0.15ex]
\hspace{2em}extend\_\hspace{0.1em}thin( ToThin, H, NotThin, ThinL ).
\end{tabbing}\end{sf}

 \end{enumerate}
 \subsection{lemma}
 \begin{enumerate}
 \item[4]
\begin{sf}\begin{tabbing}
$\vdash$(lemma(T,new[X]),H==$>$G \mbox{\it ext} $\sigma$(E,[term\_\hspace{0.1em}of(T)],[X]), \\[-0.15ex]
\hspace{2em}[ [X:C]==$>$G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}free([X],H),!,$\vartheta_{\it theorem}$(T) =: P, $\vartheta_{\it thm}$ =:CT, functor(CT,N,\_\hspace{0.1em}), $\backslash$+ N=T, \\[-0.15ex]
\hspace{2em}($status_0$(P,complete); $status_0$(P,complete(because))),\\[-0.15ex]
\hspace{2em}P = $\pi$(\_\hspace{0.1em}==$>$C,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}).\\[-0.15ex]
$\vdash$(intro,\_\hspace{0.1em}==$>$term\_\hspace{0.1em}of(T) in Type, [] ) :-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(T) =: P,\\[-0.15ex]
\hspace{2em}P = $\pi$([]==$>$TT,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}($status_0$(P,complete); $status_0$(P,complete(because))),\\[-0.15ex]
\hspace{2em}$\alpha$(TT,Type).\\[-0.15ex]
/*\\[-0.15ex]
\hspace{0em}* veto-ed by Frankh, Andrew, and AlanS:\\[-0.15ex]
\hspace{0em}* $\vdash$(intro,\_\hspace{0.1em}==$>$(\{Name\} in Type), [ ==$>$(Body in Type) ]):-\\[-0.15ex]
\hspace{0em}*     atom(Name),\\[-0.15ex]
\hspace{0em}*     !,\\[-0.15ex]
\hspace{0em}*     cdef(Name) =: (\{Name\}$<$==$>$Body).\\[-0.15ex]
\hspace{0em}* $\vdash$(intro,\_\hspace{0.1em}==$>$(Tm in Type), [ ==$>$(ETm in Type) ]):-\\[-0.15ex]
\hspace{0em}*     Tm =.. [Name$\mid$Args],\\[-0.15ex]
\hspace{0em}*     cdef(Name) =: (Head$<$==$>$Body),\\[-0.15ex]
\hspace{0em}*     !,\\[-0.15ex]
\hspace{0em}*     Head =.. [Name$\mid$P],\\[-0.15ex]
\hspace{0em}*     s(Body,Args,P,ETm).\\[-0.15ex]
\hspace{0em}*/\\[-0.7ex]

\end{tabbing}\end{sf}

 The \emph{lemma}-rule gives access to external theorems,
 which have to be declared in the hypothesis list on the
 toplevel of this proof. 
 
 The converse \emph{intro} rule for extract term formation
 allows the type of an extract term to be deduced from the
 theorem it was extracted from.
 \end{enumerate} 
 \subsection{def} 
 \begin{enumerate} 
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(def(T,new[X]),H==$>$G \mbox{\it ext} E, \\[-0.15ex]
\hspace{2em}[ [X:term\_\hspace{0.1em}of(T)=Ex in C]==$>$G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}free([X],H), !, $\vartheta_{\it theorem}$(T) =: P,$status_0$(P,complete),\\[-0.15ex]
\hspace{2em}P=$\pi$(\_\hspace{0.1em} ==$>$ C,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}$extract$(P,Exx),polish(Exx,Ex).
\end{tabbing}\end{sf}

 The \emph{def}-rule explicitly provides access to the
 extract term of a theorem declared in the global hypothesis list.
 \end{enumerate}
  
 \subsection{explicit intro}
 \begin{enumerate}
 \item[5]
\begin{sf}\begin{tabbing}
$\vdash$(intro(explicit(X)),H==$>$T \mbox{\it ext} X, [ ==$>$X in T ]):-syntax(H,X).
\end{tabbing}\end{sf}

 {\bf realisation rule:}
 This rule allows to supply the extract term for the current
 goal explicitly. In many situations you are able to supply
 this term directly because of your programming or theorem
 proving experience. Furthermore this rule allows you 
 to simplify the proof structure by extracting a term from an(other) 
 proof tree and supplying this term directly as extract term.
 \end{enumerate}
  
 \subsection{substitution}
 \begin{enumerate}
 \item[7]
\begin{sf}\begin{tabbing}
$\vdash$(subst(\mbox{\it at}(I),over(Z,T),T1=T2 in T0),H==$>$TT1 \mbox{\it ext} E, \\[-0.15ex]
\hspace{2em}[ ==$>$T1=T2 in T0, ==$>$TT2 \mbox{\it ext} E, [Z:T0]==$>$T in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Z],H),s(T,[T1],[Z],TT),$\alpha$(TT,TT1),s(T,[T2],[Z],TT2),\\[-0.15ex]
\hspace{2em}syntax(H,T2 in T0),level(I).\\[-0.15ex]
$\vdash$(subst(\mbox{\it at}(I),hyp(N),over(Z,T),T1=T2 in T0),H==$>$G \mbox{\it ext} E,\\[-0.15ex]
\hspace{2em}[ ==$>$T1=T2 in T0, +([N:TT2])==$>$G \mbox{\it ext} E, [Z:T0]==$>$T in u(I) ]):-\\[-0.15ex]
\hspace{2em}free([Z],H),decl(N:TT1,H),\\[-0.15ex]
\hspace{2em}s(T,[T1],[Z],TT),$\alpha$(TT,TT1),s(T,[T2],[Z],TT2),\\[-0.15ex]
\hspace{2em}syntax(H,T2 in T0),level(I).
\end{tabbing}\end{sf}

 The \emph{substitution}-rule allows the partial substitution
 of multiple occurences of a subterm by another term.
 \end{enumerate}
  
 \subsection{direct computation}
 \begin{enumerate}
 \item[8]
\begin{sf}\begin{tabbing}
$\vdash$(compute(using(X)),\_\hspace{0.1em}==$>$G \mbox{\it ext} E, [ ==$>$GG \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag([],G,X),     \\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(X,GG),\\[-0.15ex]
\hspace{2em}$\backslash$+ X = GG.  \\[-0.15ex]
$\vdash$(compute(using(X),not(I)),\_\hspace{0.1em}==$>$G \mbox{\it ext} E, [ ==$>$GG \mbox{\it ext} E  ]):-\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag(I,G,X),     \\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(X,GG),\\[-0.15ex]
\hspace{2em}$\backslash$+ X = GG.\\[-0.15ex]
$\vdash$(compute(hyp(N),using(X)),H==$>$G \mbox{\it ext} E,\\[-0.15ex]
\hspace{4em}[ +([N:TT]) ==$>$G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}decl(N:T,H),\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag([],T,X),\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(X,TT),\\[-0.15ex]
\hspace{2em}$\backslash$+ X = TT.  \\[-0.15ex]
$\vdash$(compute(hyp(N),using(X),not(I)),H==$>$G \mbox{\it ext} E,\\[-0.15ex]
\hspace{4em}[ +([N:TT]) ==$>$G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}decl(N:T,H),\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag(I,T,X),\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(X,TT),\\[-0.15ex]
\hspace{2em}$\backslash$+ X = TT.  \\[-0.7ex]
\\[-0.15ex]
$\vdash$(compute(X),\_\hspace{0.1em}==$>$G \mbox{\it ext} E, [ ==$>$GG \mbox{\it ext} E ]):- \\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}old(X,G,GG).\\[-0.15ex]
$\vdash$(compute(hyp(N),X),H==$>$G \mbox{\it ext} E, \\[-0.15ex]
\hspace{3em}[+([N:TT])==$>$G \mbox{\it ext} E  ]):-\\[-0.15ex]
\hspace{3em}decl(N:T,H), compute\_\hspace{0.1em}old(X,T,TT).
\end{tabbing}\end{sf}

 \item[9]
\begin{sf}\begin{tabbing}
$\vdash$(normalise,\_\hspace{0.1em}==$>$G \mbox{\it ext} E, [ ==$>$GG \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}normalise([],G,GG),\\[-0.15ex]
\hspace{2em}$\backslash$+ G = GG.  \\[-0.15ex]
$\vdash$(normalise(not(I)),\_\hspace{0.1em}==$>$G \mbox{\it ext} E, [ ==$>$GG \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}normalise(I,G,GG),\\[-0.15ex]
\hspace{2em}$\backslash$+ G = GG.\\[-0.15ex]
$\vdash$(normalise(hyp(N)),H==$>$G \mbox{\it ext} E,\\[-0.15ex]
\hspace{4em}[ +([N:TT]) ==$>$G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}decl(N:T,H),\\[-0.15ex]
\hspace{2em}normalise([], T, TT ),\\[-0.15ex]
\hspace{2em}$\backslash$+ T = TT.  \\[-0.15ex]
$\vdash$(normalise(hyp(N),not(I)),H==$>$G \mbox{\it ext} E,\\[-0.15ex]
\hspace{4em}[ +([N:TT]) ==$>$G \mbox{\it ext} E ]):-\\[-0.15ex]
\hspace{2em}decl(N:T,H),\\[-0.15ex]
\hspace{2em}normalise(I, T, TT ),\\[-0.15ex]
\hspace{2em}$\backslash$+ T = TT.  \\[-0.7ex]
\\[-0.7ex]

\end{tabbing}\end{sf}

 The \emph{compute}-rule allows the parallel manipulation of
 different subterms by means of rewriting operations. The subterms
 are specified using tag frames. A \emph{tag frame} is a term with the
 same structure as the original term, where several subterms
 are replaced by tags of the form $[[...]]$. A \emph{tag} describes
 the operations which have to be performed on the original subterm of
 the same position. There are the following operations available:
 \begin{itemize}
 \item
 multiple application of rewrite rules $[[n]]$ ($n$-times, 
 if $n$$>$$0$, or iterative as far as possible for $n=0$);
 \item
 \emph{folding} and \emph{unfolding} of definitions specified by
 tagged terms of the form
 $[[fold(d)]]$ and $[[unfold(d)]]$ or $[[unfold]]$ respectively;
 \item 
 \emph{simplification}, i.e. substitution of the subterm with
 the result of the evaluation of the subterm in the form
 $[[simplify]]$; and
 \item
 \emph{equality rule application} in the form $[[R]]$,
 where $R$ is the specification of a rule applyable to a
 goal of the form $t=t' in T$ where $t$ matches with the
 original subterm and $t'$ gives the rewriting or vice versa
 in the case of inverse rule application $[[inv(R)]]$.
 \end{itemize}
 \end{enumerate}
  
 \subsection{equality and arith}
 \emph{equality} is supplied as elementary
 inference rule as in the Nuprl system. The similar \emph{arith}
 rule is not implemented. Nevertheless both
 should be better treated via tactics with the same functionality
 as soon as possible.
 
 \begin{enumerate}
 \item[10]
\begin{sf}\begin{tabbing}
$\vdash$(equality,H==$>$A=B in T, [ ==$>$A in T, ==$>$B in T ]):-\\[-0.15ex]
\hspace{1em}${\it decide}_{=}$(A=B in T,H).
\end{tabbing}\end{sf}

 \item[11]
%  $\vdash$(arith,H==>G \mbox{\it ext} E,S):- ${\it decide}_{\it arith}$(H==>G,E,S).
\begin{sf}\begin{tabbing}
$\vdash$(arith,H==$>$G \mbox{\it ext} E,S) :- fail.
\end{tabbing}\end{sf}

 \end{enumerate}
 \section{Shorthands}
 \begin{description}
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(reduce(left,D),H==$>$X=Y in T, [ ==$>$XX=Y in T $\mid$ S ]):-\\[-0.15ex]
\hspace{2em}$\vdash$(reduce(D),H==$>$X=XX in T, S).\\[-0.15ex]
$\vdash$(reduce(right,D),H==$>$X=Y in T, [ ==$>$X=YY in T $\mid$ S ]):-\\[-0.15ex]
\hspace{2em}$\vdash$(reduce(D),H==$>$Y=YY in T, S).
\end{tabbing}\end{sf}

 These rules allow a partial reduction of one side of
 an equality. One could get the same effect using the
 more general compute rule.
 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(simplify,P,S):-$\vdash$(compute([[simplify]]),P,S).
\end{tabbing}\end{sf}

 A simplified user interface for the simplification of terms.
 \item[$\circ$]
 
 These final rules extend the simple rules dealing with introduction,reducing
  goals of the form $t_{1}=t_{2} in T$ to those of the form: $t in T$.
\begin{sf}\begin{tabbing}
$\vdash$(intro,H==$>$(T1  = T2 in Type), SubGoals ) :-\\[-0.15ex]
\hspace{2em}functor(T1,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}functor(T2,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}$\vdash$(intro,H==$>$T1 in Type, SubGoals1),\\[-0.15ex]
\hspace{2em}$\vdash$(intro,H==$>$T2 in Type, SubGoals2),\\[-0.15ex]
\hspace{2em}equal\_\hspace{0.1em}combine( SubGoals1, SubGoals2, SubGoals).\\[-0.15ex]
$\vdash$(intro(A),H==$>$(T1  = T2 in Type), SubGoals ) :-\\[-0.15ex]
\hspace{2em}functor(T1,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}functor(T2,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}$\vdash$(intro(A),H==$>$T1 in Type, SubGoals1),\\[-0.15ex]
\hspace{2em}$\vdash$(intro(A),H==$>$T2 in Type, SubGoals2),\\[-0.15ex]
\hspace{2em}equal\_\hspace{0.1em}combine( SubGoals1, SubGoals2, SubGoals).\\[-0.15ex]
$\vdash$(intro(A,B),H==$>$(T1  = T2 in Type), SubGoals ) :-\\[-0.15ex]
\hspace{2em}functor(T1,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}functor(T2,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}$\vdash$(intro(A,B),H==$>$T1 in Type, SubGoals1),\\[-0.15ex]
\hspace{2em}$\vdash$(intro(A,B),H==$>$T2 in Type, SubGoals2),\\[-0.15ex]
\hspace{2em}equal\_\hspace{0.1em}combine( SubGoals1, SubGoals2, SubGoals).\\[-0.15ex]
$\vdash$(intro(A,B,C),H==$>$(T1  = T2 in Type), SubGoals ) :-\\[-0.15ex]
\hspace{2em}functor(T1,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}functor(T2,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}$\vdash$(intro(A,B,C),H==$>$T1 in Type, SubGoals1),\\[-0.15ex]
\hspace{2em}$\vdash$(intro(A,B,C),H==$>$T2 in Type, SubGoals2),\\[-0.15ex]
\hspace{2em}equal\_\hspace{0.1em}combine( SubGoals1, SubGoals2, SubGoals).
\end{tabbing}\end{sf}

 \item[$\circ$]
\begin{sf}\begin{tabbing}
$\vdash$(R,P,S):-\\[-0.15ex]
\hspace{2em}R=..[F$\mid$T], $\backslash$+ append([at(\_\hspace{0.1em})],\_\hspace{0.1em},T),\\[-0.15ex]
\hspace{2em}member(F,[intro,elim,subst]),\\[-0.15ex]
\hspace{2em}$\vartheta_{\it universe}$=:I,RR=..[F,at(I)$\mid$T],\\[-0.15ex]
\hspace{2em}$\vdash$(RR,P,S).\\[-0.15ex]
$\vdash$(R,P,S):-\\[-0.15ex]
\hspace{2em}R=..[F$\mid$T], $\backslash$+ append(\_\hspace{0.1em},[new(\_\hspace{0.1em})],T),\\[-0.15ex]
\hspace{2em}member(F,[intro,elim,decide,equality,unroll,compute,seq,lemma,def]),\\[-0.15ex]
\hspace{2em}append(T,[new(\_\hspace{0.1em})],TT),RR=..[F$\mid$TT],\\[-0.15ex]
\hspace{2em}$\vdash$(RR,P,S).\\[-0.7ex]

\end{tabbing}\end{sf}

 The last two rules describe the automatic generation of $at(..)$
 and $new[...]$ parameters in rule specifications.
 \item[$\circ$]
 
\begin{sf}\begin{tabbing}
$\vdash$(because,\_\hspace{0.1em}==$>$\_\hspace{0.1em} \mbox{\it ext} atom(incomplete),[]).
\end{tabbing}\end{sf}

 
  - a blatant cheat.
 
 \ulinv{equal\_combine}
\begin{sf}\begin{tabbing}
equal\_\hspace{0.1em}combine( [],[],[]).\\[-0.15ex]
equal\_\hspace{0.1em}combine( [==$>$T1 in T$\mid$Rest1], [==$>$T2 in T$\mid$Rest2], [==$>$ T1 in T$\mid$RestC] ) :-\\[-0.15ex]
\hspace{2em}$\alpha$( T1, T2 ),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}equal\_\hspace{0.1em}combine( Rest1, Rest2, RestC ).\\[-0.15ex]
equal\_\hspace{0.1em}combine( [==$>$T1 in T$\mid$Rest1], [==$>$T2 in T$\mid$Rest2], [==$>$ T1=T2 in T$\mid$RestC] ) :-\\[-0.15ex]
\hspace{2em}equal\_\hspace{0.1em}combine( Rest1, Rest2, RestC ).\\[-0.15ex]
equal\_\hspace{0.1em}combine( [[H1$\mid$T1]==$>$G1$\mid$Rest1], [[H2$\mid$T2]==$>$G2$\mid$Rest2],[[H1$\mid$TT]==$>$GG$\mid$RestC])\\[-0.15ex]
\hspace{1em}:- $\alpha$( H1,H2 ), !,\\[-0.15ex]
\hspace{2em}equal\_\hspace{0.1em}combine( [T1==$>$G1$\mid$Rest1],[T2==$>$G2$\mid$Rest2], [TT==$>$GG$\mid$RestC] ).\\[-0.15ex]
/* we can't simply drop non-convertible declarations!\\[-0.15ex]
equal\_\hspace{0.1em}combine( [[\_\hspace{0.1em}$\mid$T1]==$>$G1$\mid$Rest1], [[\_\hspace{0.1em}$\mid$T2]==$>$G2$\mid$Rest2],[TT==$>$GG$\mid$RestC])\\[-0.15ex]
\hspace{1em}:- equal\_\hspace{0.1em}combine( [T1==$>$G1$\mid$Rest1],[T2==$>$G2$\mid$Rest2], [TT==$>$GG$\mid$RestC] ).\\[-0.15ex]
*/\\[-0.15ex]
equal\_\hspace{0.1em}combine( [[]==$>$G1$\mid$Rest1], [[]==$>$G2$\mid$Rest2],[[]==$>$GG$\mid$RestC])\\[-0.15ex]
\hspace{1em}:- equal\_\hspace{0.1em}combine( [==$>$G1$\mid$Rest1],[==$>$G2$\mid$Rest2], [==$>$GG$\mid$RestC] ).
\end{tabbing}\end{sf}

 \end{description}
  
 \chapter{Tactics}
 
 \section{Mark and Copy}
 $mark(file)$ and $copy(file)$ allow copying of arbitrary parts
 of the proof tree. $mark$ and $copy$ might be considered as examples
 of built in tactics, thei do not use any hidden predicate. 
 This example should encourage
 you in writing your own tactics more suitable for your applications.
 $mark$ writes to the file specified in its argument
 a sequence of Prolog clauses of the form  $?-apply(t)$,
 $?-up$, and $?-down(i)$, which allows later the straightforward 
 reconstruction of the proof tree below the current focus. 
 The $mark$ file may be executed directly 
 from $copy(file)$ as well as from the standard $consult(file)$.
 $mark$ and $copy$ are a simple way of copying proof structures
 from one proof to another, as well as a tool for reproving 
 (parts) of the current proof, and saving intermediate
 states of a subproof, when you decide to try another way of 
 proving. Due to the fact, that the proof is saved in a
 quite readable ASCII file, you have the opportunity of 
 modifying your proof tree using your favourite text editor.
 \ulinv{mark}
\begin{sf}\begin{tabbing}
mark(X):-atom(X), tell(X), markf(0), told,!.
\end{tabbing}\end{sf}

 \ulinv{copy}
\begin{sf}\begin{tabbing}
copy(X):-consult(X).
\end{tabbing}\end{sf}

 \ulinv{markf}
\begin{sf}\begin{tabbing}
markf(T):-refinement(R),\\[-0.15ex]
\hspace{5em}( var(R);\\[-0.15ex]
\hspace{6em}writeclause(T,(apply(R)-$>$true;abort)),\\[-0.15ex]
\hspace{7em}TT is T+2, down(N),refinement(Q), $\backslash$+ var(Q),\\[-0.15ex]
\hspace{7em}writeclause(TT,down(N)),markf(TT),writeclause(TT,up),fail;\\[-0.15ex]
\hspace{6em}! \\[-0.15ex]
\hspace{5em}),!.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{writeclause}
\begin{sf}\begin{tabbing}
writeclause(N,X):-tab(N),write\_\hspace{0.1em}term((?-X),[quoted(true)]),write('.'),nl.\\[-0.15ex]
\hspace{0em}
\end{tabbing}\end{sf}

 \section{Equality and Arithmetic}
 
 One of the open research questions is the proper reorganization
 of the \emph{arith} and \emph{equality} rules as tactics.
 We have all preconditions fulfilled by extending the rule
 base by the appropriate primitive inference rules. To get
 an efficient working version of the system, both rules
 are still hard wired (as in the original Nuprl system).
 This section gives the source code for these inference rules,
 which you only should consider as an initial step.  
 
 \subsection{Decision Procedure for Equalities}
 The decision procedure for equalities $A=B\; in \;T$ considers 
 the reflexivity, symmetry and transitivity of the equality
 relation under $T$ and all types which are convertible with $T$.
 The decision procedure works in three steps: first all
 equalities over types $T'$ which are convertible to T are
 collected into a list, and then the list $L$ of all elements which
 are equal to $A$ under this restricted set of equalities
 is computed and then is checked whether B is convertible to an 
 element of this list.
 \small
 \ulinv{decideequal}
\begin{sf}\begin{tabbing}
${\it decide}_{=}$(A=B in T,H):-\\[-0.15ex]
\hspace{2em}$\chi_{=}$(T,H,H0), allequals([A],H0,L),!,member(BB,L),$\alpha$(BB,B).\\[-0.15ex]
\hspace{0em}
\end{tabbing}\end{sf}

 \ulinv{allequals}
\begin{sf}\begin{tabbing}
allequals(L1,T,L2):-equals(L1,T,L),(L=L1,L2=L; allequals(L,T,L2)),!.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{equals}
\begin{sf}\begin{tabbing}
equals(A,[],A).\\[-0.15ex]
equals(A,[B=C in \_\hspace{0.1em}$\mid$T],L):-\\[-0.15ex]
\hspace{2em}member(B,A),$\backslash$+ member(C,A),!,equals([C$\mid$A],T,L).\\[-0.15ex]
equals(A,[B=C in \_\hspace{0.1em}$\mid$T],L):-\\[-0.15ex]
\hspace{2em}member(C,A),$\backslash$+ member(B,A),!,equals([B$\mid$A],T,L).\\[-0.15ex]
equals(A,[\_\hspace{0.1em}$\mid$T],L):-equals(A,T,L).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{extractequal}
\begin{sf}\begin{tabbing}
$\chi_{=}$(\_\hspace{0.1em},[],[]).\\[-0.15ex]
$\chi_{=}$(T,[\_\hspace{0.1em}:A=B in TT$\mid$H],[A=B in TT$\mid$HH]):-$\alpha$(T,TT),$\chi_{=}$(T,H,HH).\\[-0.15ex]
$\chi_{=}$(T,[A\#B$\mid$H],HH):-$\chi_{=}$(T,[A,B$\mid$H],HH).\\[-0.15ex]
$\chi_{=}$(T,[\_\hspace{0.1em}$\mid$H],HH):-$\chi_{=}$(T,H,HH).
\end{tabbing}\end{sf}

 \normalsize 
 \subsection{Decision Procedure for Arithmetic Properties}  
 

% To Be Written!

% \chapter{Miscellaneous}
 \section{Syntax Checker for Type Theoretical Terms}
 \sloppypar
 The $syntax(H,X)$ predicate may be used to check the syntactic
 structure of a type theoretic term with respect to the 
 declarations available in the hypothesis list H. 
 It does not do any parsing,
 but simply checks the structure of a Prolog term. So, errors which
 appear already on the Prolog level may cause syntax error in
 the Prolog read routine. In the case of syntactic errors,
 $syntax(H,X)$ fails and generates error messages on standard output,
 otherwise it succeeds silently.
 $\tau_{var}$(X) checks whether the parameter is a proper type theoretic
 variable.
 A type theoretic variable consists of a sequence of letters, digits
 and underscores beginning with a small letter, or a sequence of the
 characters \hbox{``$+-*\backslash$/\^{}$<>$=`\verb`~`:.?@\#\$\&''}.
 \ulinv{syntax}
\begin{sf}\begin{tabbing}
syntax(H==$>$G):-syntax0([],H==$>$G).  \\[-0.15ex]
syntax(\_\hspace{0.1em},X):-var(X),!, direction=:backwards, !.\\[-0.15ex]
syntax(\_\hspace{0.1em},X):-var(X),!, direction=:forwards, !, fail.\\[-0.15ex]
syntax(\_\hspace{0.1em},new [\_\hspace{0.1em}$\mid$\_\hspace{0.1em}]):-!,fail.\\[-0.15ex]
syntax(\_\hspace{0.1em},at(\_\hspace{0.1em})):-!,fail.\\[-0.15ex]
syntax(H,over(Z,T)):-$\tau_{var}$(Z),syntax([Z:\_\hspace{0.1em}$\mid$H],T).\\[-0.15ex]
syntax(H,X):-errors:=0,$\tau$(H,X),errors=:I,!,I=:=0.\\[-0.15ex]
syntax(H,V,X):-errors:=0,$\tau'$(H,V,X),errors=:I,!,I=:=0.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{syntax0}
\begin{sf}\begin{tabbing}
syntax0(H,[]==$>$G):-syntax(H,G).\\[-0.15ex]
syntax0(H,[D$<$==$>$P$\mid$HH]==$>$G):-\\[-0.15ex]
\hspace{4em}D=..[F$\mid$A],free([F],H),$\tau'$(H,A,P),syntax0([D$<$==$>$P$\mid$H],HH==$>$G).\\[-0.15ex]
syntax0(H,[T:(HL==$>$G \mbox{\it ext} E)$\mid$HH]==$>$GG):-\\[-0.15ex]
\hspace{4em}free([T],H),$\tau$(H,G),$\tau$(H,E),syntax0([T:(HL==$>$G \mbox{\it ext} E)$\mid$H],HH==$>$GG).\\[-0.15ex]
syntax0(H,[T:(HL==$>$G)$\mid$HH]==$>$GG):-\\[-0.15ex]
\hspace{4em}free([T],H),$\tau$(H,G),syntax0([T:(HL==$>$G)$\mid$H],HH==$>$GG).\\[-0.7ex]
\\[-0.15ex]
\hspace{0em}
\end{tabbing}\end{sf}

 \ulinv{ttt}
\begin{sf}\begin{tabbing}
$\tau$(H,X):-var(X),!,$\tau$(H,'prolog variable not allowed').\\[-0.15ex]
$\tau$(\_\hspace{0.1em},u(I)):-level(I),!.\\[-0.15ex]
$\tau$(\_\hspace{0.1em},I):-integer(I),!.\\[-0.15ex]
$\tau$(\_\hspace{0.1em},atom(X)):-atom(X),!.\\[-0.15ex]
$\tau$(\_\hspace{0.1em},{\verb`~`}):-fail.\\[-0.15ex]
$\tau$(H,X):-$\tau_{var}$(X),decl(X:\_\hspace{0.1em},H).\\[-0.7ex]
\\[-0.15ex]
$\tau$(\_\hspace{0.1em},X):- atomic(X), member(X,[atom,void,pnat,int,axiom,nil,unary,unit]),!.\\[-0.15ex]
$\tau$(H,X):- X=..[F,A], member(F,[any,s,inl,inr,list,-]),$\tau$(H,A),!.\\[-0.15ex]
$\tau$(H,X):- X=..[F,A,B], member(F,[$<$,$<$*,\&,::,\#,=$>$,$\backslash$,of,+,-,*,/,mod]),\\[-0.15ex]
\hspace{3em}$\tau$(H,A),$\tau$(H,B),!.\\[-0.15ex]
$\tau$(H,X):- \\[-0.15ex]
\hspace{2em}X=..[F,A,B,S,T], \\[-0.15ex]
\hspace{2em}member(F,[atom\_\hspace{0.1em}eq,int\_\hspace{0.1em}eq,pnat\_\hspace{0.1em}eq,less,pless]), \\[-0.15ex]
\hspace{2em}$\tau$(H,A),$\tau$(H,B),$\tau$(H,S),$\tau$(H,T),!.\\[-0.7ex]
\\[-0.15ex]
$\tau$(H,C:A\#B):-$\tau$(H,A),$\tau'$(H,[C],B),!.\\[-0.15ex]
$\tau$(H,C:A=$>$B):-$\tau$(H,A),$\tau'$(H,[C],B),!.\\[-0.15ex]
$\tau$(H,A///[U,V,B]):-$\tau$(H,A),$\tau'$(H,[U,V],B),!.\\[-0.15ex]
$\tau$(H,\{C:A$\backslash$B\}):-$\tau$(H,A),$\tau'$(H,[C],B),!.\\[-0.15ex]
$\tau$(H,\{A$\backslash$B\}):-$\tau$(H,A$\backslash$B),!.\\[-0.15ex]
$\tau$(H,lambda(A,B)):-$\tau'$(H,[A],B),!.\\[-0.15ex]
$\tau$(H,rec(A,T)):-$\tau'$(H,[A],T),!.\\[-0.15ex]
$\tau$(H,A=B in T):-$\tau$(H,A),$\tau$(H,B),$\tau$(H,T),!.\\[-0.15ex]
$\tau$(H,A in T):-$\tau$(H,A),$\tau$(H,T),!.\\[-0.15ex]
$\tau$(H,acc(A,B)):-$\tau$(H,A),$\tau$(H,B).\\[-0.7ex]
\\[-0.15ex]
$\tau$(H,spread(A,[U,V,W])):-$\tau$(H,A),$\tau'$(H,[U,V],W),!.\\[-0.15ex]
$\tau$(H,decide(A,[U,S],[V,T])):-$\tau$(H,A),$\tau'$(H,[U],S),$\tau'$(H,[V],T),!.\\[-0.15ex]
$\tau$(H,p\_\hspace{0.1em}ind(A,B,[U,V,T])):-$\tau$(H,A),$\tau$(H,B),$\tau'$(H,[U,V],T),!.\\[-0.15ex]
$\tau$(H,cv\_\hspace{0.1em}ind(A,[U,V,T])):-$\tau$(H,A),$\tau'$(H,[U,V],T),!.\\[-0.15ex]
$\tau$(H,ind(A,[P,Q,S],B,[U,V,T])):-$\tau$(H,A), $\tau'$(H,[P,Q],S), $\tau$(H,B), $\tau'$(H,[U,V],T),!.\\[-0.15ex]
$\tau$(H,list\_\hspace{0.1em}ind(A,B,[U,V,W,T])):-\\[-0.15ex]
\hspace{2em}$\tau$(H,A),$\tau$(H,B), $\tau'$(H,[U,V,W],T),!.\\[-0.15ex]
$\tau$(H,rec\_\hspace{0.1em}ind(A,[U,V,T])):- $\tau$(H,A),$\tau'$(H,[U,V],T),!.\\[-0.15ex]
$\tau$(H,wo\_\hspace{0.1em}ind(A,[U,V,T])):- $\tau$(H,A),$\tau'$(H,[U,V],T),!.\\[-0.15ex]
$\tau$(\_\hspace{0.1em},term\_\hspace{0.1em}of(T)):- $\vartheta_{\it theorem}$(T) =: \_\hspace{0.1em}.\\[-0.15ex]
$\tau$(H,X):-X=..[F$\mid$A],$\backslash$+ F=\{\},cdef(F) =: (XX$<$==$>$\_\hspace{0.1em}),XX=..[F$\mid$AA],$\tau$(H,A,AA),!.\\[-0.15ex]
$\tau$(\_\hspace{0.1em},\{Name\}):- atom(Name),cdef(Name) =: (\{Name\}$<$==$>$\_\hspace{0.1em}),!.\\[-0.15ex]
$\tau$(H,Unknown) :-				\% try to load from a library\\[-0.15ex]
\hspace{2em}autoload\_\hspace{0.1em}defs\_\hspace{0.1em}ass2(yes),\\[-0.15ex]
\hspace{2em}once((Unknown = \{F\};			\% function constants only\\[-0.15ex]
	  Unknown = term\_\hspace{0.1em}of(F);			\% synths\\[-0.15ex]
	  Unknown =.. [F$\mid$[\_\hspace{0.1em}$\mid$\_\hspace{0.1em}]],\\[-0.15ex]
	  $\backslash$+ oyster\_\hspace{0.1em}functor(F))),\\[-0.15ex]
\hspace{2em}$\backslash$+ lib\_\hspace{0.1em}present(def(F)),			\% circularity is possible\\[-0.15ex]
\hspace{2em}(autoloading\_\hspace{0.1em}def(F) -$>$ (nl,write('Looping in autoload: aborting!'),nl,fail);\\[-0.15ex]
\hspace{2em}true),\\[-0.15ex]
\hspace{2em}assert(autoloading\_\hspace{0.1em}def(F)),\\[-0.15ex]
\hspace{2em}lib\_\hspace{0.1em}load(def(F)),\\[-0.15ex]
\hspace{2em}writef('  [ Autoloaded def(\%t) ]$\backslash$n',[F]),\\[-0.15ex]
\hspace{2em}$\tau$(H,Unknown),				\% start again.    \\[-0.15ex]
\hspace{2em}retractall(autoloading\_\hspace{0.1em}def(F)).\\[-0.15ex]
\hspace{2em}\\[-0.15ex]
$\tau$(\_\hspace{0.1em},X):- nl,write('syntax error: '),write(X), errors=:I,J is I+1,errors:=J.\\[-0.15ex]
$\tau$(\_\hspace{0.1em},[],[]).\\[-0.15ex]
$\tau$(H,[A$\mid$T],[\_\hspace{0.1em}$\mid$TT]):-$\tau$(H,A),$\tau$(H,T,TT).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{tttl}
\begin{sf}\begin{tabbing}
$\tau'$(H,V,A) :- remove(V,{\verb`~`},VV), is\_\hspace{0.1em}set(VV), $\tau''$(H,VV,A). \% same as check\_\hspace{0.1em}set?
\end{tabbing}\end{sf}

 \ulinv{ttl1}
\begin{sf}\begin{tabbing}
$\tau''$(H,[],A):-$\tau$(H,A).\\[-0.15ex]
$\tau''$(H,[U$\mid$T],A):-$\tau_{var}$(U),$\tau''$([U:dummy$\mid$H],T,A).\\[-0.7ex]
\\[-0.15ex]
remove([],\_\hspace{0.1em},[]).\\[-0.15ex]
remove([X$\mid$T],X,D) :- remove(T,X,D).\\[-0.15ex]
remove([H$\mid$T],X,[H$\mid$D]) :- remove(T,X,D).\\[-0.7ex]

\end{tabbing}\end{sf}

 \inv{$\tau_{var}$}
\begin{sf}\begin{tabbing}
$\tau_{var}$(X):-\\[-0.15ex]
\hspace{2em}atom(X),\\[-0.15ex]
\hspace{2em}oyster\_\hspace{0.1em}functors( OF ),\\[-0.15ex]
\hspace{2em}member(X, OF),\\[-0.15ex]
\hspace{2em}!, fail.\\[-0.15ex]
$\tau_{var}$(X):- atom(X).\\[-0.7ex]
\\[-0.15ex]
oyster\_\hspace{0.1em}functor(F) :-\\[-0.15ex]
\hspace{2em}oyster\_\hspace{0.1em}functors(Fs),\\[-0.15ex]
\hspace{2em}member(F,Fs).\\[-0.15ex]
oyster\_\hspace{0.1em}functors( [ atom, void, pnat, int, axiom, nil, ext, ==$>$, $<$==$>$, :, =$>$, \#, \\[-0.15ex]
\hspace{6em}$\backslash$, ///, {\verb`~`}$>$, in, =, $<$, $<$=, +, -, *, /, mod, \&, ::, of, list,\\[-0.15ex]
\hspace{6em}lambda, rec, spread, decide, p\_\hspace{0.1em}ind, ind, list\_\hspace{0.1em}ind, rec\_\hspace{0.1em}ind,\\[-0.15ex]
\hspace{6em}acc, wo\_\hspace{0.1em}ind, cv\_\hspace{0.1em}ind, inr, inl,
\end{tabbing}\end{sf}

            s,u, % these ought to be here too? (img)
\begin{sf}\begin{tabbing}
\hspace{6em}unit, unary, term\_\hspace{0.1em}of, '.'] ).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{fairly\_nonalphanum}
\begin{sf}\begin{tabbing}
fairly\_\hspace{0.1em}nonalphanum([]).\\[-0.15ex]
fairly\_\hspace{0.1em}nonalphanum([X$\mid$Y]):-
\end{tabbing}\end{sf}

  %  member(X,"+-*\/^<>=`~:.?@#$&"),
\begin{sf}\begin{tabbing}
\hspace{2em}member(X,[43,45,42,92,47,94,60,62,61,96,126,58,46,63,64,35,36,38]),\\[-0.15ex]
\hspace{2em}fairly\_\hspace{0.1em}nonalphanum(Y).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{idtail}
\begin{sf}\begin{tabbing}
idtail([]).\\[-0.15ex]
idtail([H$\mid$T]):-(small\_\hspace{0.1em}letter(H);capital\_\hspace{0.1em}letter(H);digit(H);underscore(H)),idtail(T).
\end{tabbing}\end{sf}

  
 \section{Pretty Printer for Type Theoretic Terms}
 $writeterm(T)$ and $writeterm(n,T)$ are the standard output 
 predicates for type theoretic terms, where $n$ stands for
 any initial indentation. $writeterm0(T)$ and $writeterm0(n,T)$
 respectively write a compressed version of the term.
 Pretty printing requires an estimation of the string length of
 the output. To avoid multiple computation of that string length,
 the output term is first attributed with length information
 using the $weight$ predicate. 
 $weight(X,Y)$ yields a tree $Y$ with the same structure as $X$, 
 but attributed with the estimated print length of $X$,
 as for example in  $weight(a+b,w(w(a,1)+w(bb,2),6))$.
 This process of computing the output size is quite expensive,
 and should be subject to further optimisation.
 $fringe(n,X,XX)$ yields a term of limited depth $n$, the top level
 nodes of which are equivalent to X, omitted subterms are replaced
 by  '...' .
  
 \ulinv{writeterm}
\begin{sf}\begin{tabbing}
writeterm(N,X):-vars:=0,copy(X,Y),weight(Y,W),prepare(Y,Z),$\omega$(N,Z,W),nl.\\[-0.15ex]
writeterm(X):-writeterm(0,X).
\end{tabbing}\end{sf}

 \ulinv{writeterm0}
\begin{sf}\begin{tabbing}
writeterm0(N,X):-$\vartheta_{\it fringe}$=:0, writeterm(N,X).\\[-0.15ex]
writeterm0(N,X):-$\vartheta_{\it fringe}$=:F, fringe(F,X,Y),writeterm(N,Y).\\[-0.15ex]
writeterm0(X):-writeterm0(0,X).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{wdecl}
\begin{sf}\begin{tabbing}
$\omega$(S,X,w(\_\hspace{0.1em},W)):-$\vartheta_{\it screensize}$=:N,S+W$<$N-10,print(X),!.\\[-0.15ex]
$\omega$(S,X,W):-$\vartheta_{\it screensize}$=:N,0.6*N$<$S,SS is S-N//2,$\omega$(SS,X,W),!.\\[-0.7ex]
\\[-0.15ex]
$\omega$(S,C:A\#B,w(w(\_\hspace{0.1em},CC):w(AA\#BB,\_\hspace{0.1em}),\_\hspace{0.1em})):- \\[-0.15ex]
\hspace{2em}$\vartheta_{\it shift}$=:N,S1 is S+CC+1, S2 is S+N,\\[-0.15ex]
\hspace{2em}print(C),write(':'),$\omega'$(S1,A,AA),write('\#'),nl,tab(S2), $\omega$(S2,B,BB),!.\\[-0.15ex]
$\omega$(S,C:A=$>$B,w(w(\_\hspace{0.1em},CC):w(AA=$>$BB,\_\hspace{0.1em}),\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it shift}$=:N,S1 is S+CC+1, S2 is S+N,\\[-0.15ex]
\hspace{2em}print(C),write(':'),$\omega'$(S1,A,AA),write('=$>$'),nl,tab(S2),$\omega$(S2,B,BB),!.\\[-0.15ex]
$\omega$(S,C:A$\backslash$B,w(w(\_\hspace{0.1em},CC):w(AA$\backslash$BB,\_\hspace{0.1em}),\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it shift}$=:N,S1 is S+CC+1, S2 is S+N,\\[-0.15ex]
\hspace{2em}print(C),write(':'),$\omega'$(S1,A,AA),write('$\backslash$$\backslash$'),nl,tab(S2), $\omega$(S2,B,BB),!.\\[-0.15ex]
$\omega$(S,C:A,w(w(\_\hspace{0.1em},CC):AA,\_\hspace{0.1em})):-S1 is S+CC+1,\\[-0.15ex]
\hspace{2em}print(C),write(':'),$\omega'$(S1,A,AA),!.\\[-0.15ex]
$\omega$(S,A\#B,w(AA\#BB,\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}$\omega'$(S,A,AA),write('\#'),nl,tab(S), $\omega$(S,B,BB),!.\\[-0.15ex]
$\omega$(S,A=$>$B,w(AA=$>$BB,\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}$\omega'$(S,A,AA),write('=$>$'),S1 is S+2,nl,tab(S1), $\omega$(S1,B,BB),!.\\[-0.15ex]
$\omega$(S,X,W):-$\omega'$(S,X,W).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{wterm}
\begin{sf}\begin{tabbing}
$\omega'$(\_\hspace{0.1em},X,\_\hspace{0.1em}) :- portray(X),!.\\[-0.15ex]
$\omega'$(S,C:A\#B,W):-par($\omega$(S,C:A\#B,W)).\\[-0.15ex]
$\omega'$(S,C:A=$>$B,W):-par($\omega$(S,C:A=$>$B,W)).\\[-0.15ex]
$\omega'$(S,C:A,W):-par($\omega$(S,C:A,W)).\\[-0.7ex]
\\[-0.15ex]
$\omega'$(S,X,w(\_\hspace{0.1em},W)):-$\vartheta_{\it screensize}$=:N,S+W$<$N-10,par(write(X)),!.\\[-0.15ex]
$\omega'$(S,X,W):-$\vartheta_{\it screensize}$=:N,0.6*N$<$S,SS is S-N//2,$\omega'$(SS,X,W),!.\\[-0.7ex]
\\[-0.15ex]
$\omega'$(S,X,w(XX,\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}append(Y,[T],X),append(YY,[TT],XX), S1 is S+1,\\[-0.15ex]
\hspace{2em}write('['),weight(Y,w(\_\hspace{0.1em},Yw)),\\[-0.15ex]
\hspace{2em}( $\vartheta_{\it screensize}$=:N,S+Yw+2$>$N,$\omega''$(S1,Y,YY); $\omega''$(Y) ),\\[-0.15ex]
\hspace{2em}write(','),nl,tab(S1), $\omega'$(S1,T,TT),write(']'),!.\\[-0.15ex]
$\omega'$(S,lambda(X,F),w(lambda(\_\hspace{0.1em},FF),\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}write('lambda('),write(X),write(','),\\[-0.15ex]
\hspace{2em}S1 is S+2,nl,tab(S1),$\omega'$(S1,F,FF),write(')'),!.\\[-0.15ex]
$\omega'$(S,A\#B,w(AA\#BB,\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}$\omega'$(S,A,AA),write('\#'),nl,tab(S), $\omega'$(S,B,BB),!.\\[-0.15ex]
$\omega'$(S,A=$>$B,w(AA=$>$BB,\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}$\omega'$(S,A,AA),write('=$>$'),S1 is S+2,nl,tab(S1), $\omega'$(S1,B,BB),!.\\[-0.15ex]
$\omega'$(S,A=B in T,w(w(AA=BB,\_\hspace{0.1em}) in TT,\_\hspace{0.1em})):- \\[-0.15ex]
\hspace{2em}S1 is S+1,S2 is S+3,S3 is S+4,\\[-0.15ex]
\hspace{2em}write('('),$\omega'$(S1,A,AA),nl,tab(S),\\[-0.15ex]
\hspace{2em}write(' = '),$\omega'$(S2,B,BB),nl,tab(S),\\[-0.15ex]
\hspace{2em}write(' in '),$\omega'$(S3,T,TT),write(')'),!.\\[-0.15ex]
$\omega'$(S,A in T,w(AA in TT,\_\hspace{0.1em})):- S1 is S+1,S2 is S+4,\\[-0.15ex]
\hspace{2em}write('('),$\omega'$(S1,A,AA),nl,tab(S),\\[-0.15ex]
\hspace{2em}write(' in '),$\omega'$(S2,T,TT),write(')'),!.\\[-0.15ex]
$\omega'$(S,\{X\},w(\{XX\},\_\hspace{0.1em})):-S1 is S+1,\\[-0.15ex]
\hspace{2em}write('\{'),$\omega$(S1,X,XX),write('\}'),!.\\[-0.7ex]
\\[-0.15ex]
$\omega'$(\_\hspace{0.1em},u(I),\_\hspace{0.1em}):-write(u(I)),!.\\[-0.15ex]
$\omega'$(\_\hspace{0.1em},X,\_\hspace{0.1em}):-atom(X),write(X),!.\\[-0.15ex]
$\omega'$(\_\hspace{0.1em},X,\_\hspace{0.1em}):-integer(X),write(X),!.\\[-0.15ex]
$\omega'$(S,X,w(XX,\_\hspace{0.1em})):- \\[-0.15ex]
\hspace{2em}standardform(X),X=..[F$\mid$A], write(F),write('('),nl,tab(S),\\[-0.15ex]
\hspace{2em}XX=..[F$\mid$AA],$\omega''$(S,A,AA),write(')'),!.\\[-0.15ex]
$\omega'$(S,X,w(XX,\_\hspace{0.1em})):-\\[-0.15ex]
\hspace{2em}X=..[F,A,B], XX=..[F,AA,BB],\\[-0.15ex]
\hspace{2em}$\vartheta_{\it shift}$=:N,weight(F,w(\_\hspace{0.1em},Fw)),S1 is S+1,S2 is S+N+Fw+1,\\[-0.15ex]
\hspace{2em}write('('),$\omega'$(S1,A,AA),nl,tab(S),\\[-0.15ex]
\hspace{2em}tab(N),write(F),write(' '),$\omega'$(S2,B,BB),write(')'),!.\\[-0.15ex]
$\omega'$(\_\hspace{0.1em},X,\_\hspace{0.1em}):-par(write(X)).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{wterml}
\begin{sf}\begin{tabbing}
$\omega''$([X]):-write(X).\\[-0.15ex]
$\omega''$([X$\mid$Y]):-write(X),write(','),$\omega''$(Y).\\[-0.15ex]
$\omega''$(S,[X],[XX]):-$\omega'$(S,X,XX).\\[-0.15ex]
$\omega''$(S,[X$\mid$Y],[XX$\mid$YY]):-$\omega'$(S,X,XX),write(','),nl,tab(S),$\omega''$(S,Y,YY).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{standardform}
\begin{sf}\begin{tabbing}
standardform(X):-var(X),!.\\[-0.15ex]
standardform([]):-!.\\[-0.15ex]
standardform([\_\hspace{0.1em}$\mid$\_\hspace{0.1em}]):-!.\\[-0.15ex]
standardform(X):-atom(X).\\[-0.15ex]
standardform(X):-integer(X),0=$<$X.\\[-0.15ex]
standardform(u(\_\hspace{0.1em})).\\[-0.15ex]
standardform(X):- functor(X,F,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{1em}$\backslash$+ member(F, [==$>$,:,=$>$,\#,$\backslash$,///,\{\},in,=,$<$,+,-,*,/,mod,\&,::,of,list,\\[-0.15ex]
\hspace{4em}then,or,repeat,complete,try]).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{par}
\begin{sf}\begin{tabbing}
par(write(X)):-standardform(X),print(X),!.\\[-0.15ex]
par($\omega'$(S,X,W)):-standardform(X),$\omega'$(S,X,W),!.\\[-0.15ex]
par($\omega$(S,X,W)):-standardform(X),$\omega$(S,X,W),!.\\[-0.7ex]
\\[-0.15ex]
par(write(X)):-write('('),print(X),write(')'),!.\\[-0.15ex]
par(X):-X=..[F,S,T,W],SS is S+1,XX=..[F,SS,T,W],write('('),call(XX),write(')').\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{weight}
\begin{sf}\begin{tabbing}
weight(X,w(X,2)):-var(X),!,vars=:I,II is I+1,vars:=II,X=var(II),var(II):=0.\\[-0.15ex]
weight(X,w(X,Xw)):-atom(X),atom\_\hspace{0.1em}codes(X,Y),length(Y,Xw),!.\\[-0.15ex]
weight(X,w(X,1)):-integer(X),X$<$10,!.\\[-0.15ex]
weight(X,w(X,Xw)):-integer(X),Y is (X//10),weight(Y,w(Y,Yw)),Xw is Yw+1,!.\\[-0.15ex]
weight([],w([],2)):-!.\\[-0.15ex]
weight([X],w([w(XX,Xw)],W)):-weight(X,w(XX,Xw)),W is Xw+2,!.\\[-0.15ex]
weight([X$\mid$Y],w([w(XX,Xw)$\mid$YY],W)):-weight(X,w(XX,Xw)),weight(Y,w(YY,Yw)),W is Xw+Yw+1,!.\\[-0.15ex]
weight(X,w(XX,Xw)):-\\[-0.15ex]
\hspace{2em}X=..[F$\mid$A],weight(F,w(F,Fw)),length(A,LA),\\[-0.15ex]
\hspace{2em}weight(A,w(AA,Aw)),XX=..[F$\mid$AA],Xw is Fw+Aw-LA+1.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{prepare}
\begin{sf}\begin{tabbing}
prepare(var(I),'\_\hspace{0.1em}'):-var(I)=:0,!.\\[-0.15ex]
prepare(var(I),V):-decimal(I,L),underscore(U),atom\_\hspace{0.1em}codes(V,[U$\mid$L]),!.\\[-0.15ex]
prepare(atom(A),atom(AA)):-atom\_\hspace{0.1em}codes(A,L),quote(L,LL),atom\_\hspace{0.1em}codes(AA,LL).\\[-0.15ex]
prepare([],[]):-!.\\[-0.15ex]
prepare([H$\mid$T],[HH$\mid$TT]):-!,prepare(H,HH),prepare(T,TT).\\[-0.15ex]
prepare(X,XX):-X=..[F$\mid$A],prepare(A,AA),XX=..[F$\mid$AA].\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{quote}
\begin{sf}\begin{tabbing}
quote([],[X,X]):-apostroph(X).\\[-0.15ex]
quote([X$\mid$T],[X,X$\mid$TT]):-apostroph(X),quote(T,TT).\\[-0.15ex]
quote([Y$\mid$T],[X,Y$\mid$TT]):- $\backslash$+ apostroph(Y),quote(T,[X$\mid$TT]).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{fringe}
\begin{sf}\begin{tabbing}
fringe(\_\hspace{0.1em},X,X):-var(X),!.\\[-0.15ex]
fringe(\_\hspace{0.1em},X,X):-atom(X),!.\\[-0.15ex]
fringe(\_\hspace{0.1em},X,X):-integer(X),!.\\[-0.15ex]
fringe(\_\hspace{0.1em},u(I),u(I)):-!.\\[-0.15ex]
fringe(\_\hspace{0.1em},[],[]):-!.\\[-0.15ex]
fringe(S,[T],[TT]):-fringe(S,T,TT),!.\\[-0.15ex]
fringe(S,[X$\mid$Y],[XX$\mid$YY]):-fringe(S,X,XX),fringe(S,Y,YY),!.\\[-0.15ex]
fringe(S,X,XX):-\\[-0.15ex]
\hspace{1em}0$<$S,X=..[F$\mid$A],SS is S-1,fringe(SS,A,AA),XX=..[F$\mid$AA],!.\\[-0.15ex]
fringe(\_\hspace{0.1em},\_\hspace{0.1em},'\_\hspace{0.1em}\_\hspace{0.1em}\_\hspace{0.1em}').
\end{tabbing}\end{sf}

  
 \section{Substitutions}
 A substitution is described by the predicate $s(t,[y,...],[x,...],t')$
 which states the fact, that the term $t'$ may be obtained from t
 by substituting all occurrences of the variables $x,...$ by the
 corresponding subterms $y,...$ renaming bound variables in
 conflicting situations. Substitutions are performed simultaneously.
 \ulinv{s}
\begin{sf}\begin{tabbing}
s(V1,V2,V3,V4) :- var(V1),var(V2),var(V3),var(V4),!,fail.\\[-0.15ex]
s(Tm, New, Old, SubdTm ) :-\\[-0.15ex]
\hspace{2em}(bagof(Free, Sub\^{}(nonvar(New), member(Sub,New), freevarsinterm(Sub,Free)), Frees), !\\[-0.15ex]
\hspace{2em}; Frees = []),\\[-0.15ex]
\hspace{2em}freevarsinterm(Tm,ExtraFrees),\\[-0.15ex]
\hspace{2em}union([ExtraFrees$\mid$Frees], SubFrees), \\[-0.15ex]
\hspace{2em}pairing\_\hspace{0.1em}of(Old, New, Insts),\\[-0.15ex]
\hspace{2em}$\sigma$(Tm, Insts, SubFrees, [], SubdTm).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{pairing\_of}
\begin{sf}\begin{tabbing}
pairing\_\hspace{0.1em}of([H1$\mid$T1], [H2$\mid$T2], [(H1 - H2)$\mid$T3]) :- pairing\_\hspace{0.1em}of(T1, T2, T3).\\[-0.15ex]
pairing\_\hspace{0.1em}of([],[],[]).\\[-0.7ex]

\end{tabbing}\end{sf}

 If term is one which is to be substituted, then  replace it, as long as it is
 not a variable which is bound:
 \ulinv{substituted}
\begin{sf}\begin{tabbing}
$\sigma$(Var,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},Var) :- var(Var),!.\\[-0.15ex]
$\sigma$(Term,  \_\hspace{0.1em} , \_\hspace{0.1em} , Bound, Term) :- member(Term,Bound),!.\\[-0.15ex]
$\sigma$(Term, Insts, \_\hspace{0.1em} , Bound, Instd) :-\\[-0.15ex]
\hspace{2em}member((Term - Instd), Insts), !, $\backslash$+ member(Term, Bound).\\[-0.15ex]
$\sigma$($\sigma$(Term,New,Old),Insts,Subfrees,Bound,SS) :-\\[-0.15ex]
\hspace{2em}s(Term,New,Old,TT),$\sigma$(TT,Insts,Subfrees,Bound,SS).\\[-0.15ex]
$\sigma$(atom(Name),\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},atom(Name)).\\[-0.15ex]
$\sigma$(term\_\hspace{0.1em}of(Name),\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},term\_\hspace{0.1em}of(Name)).\\[-0.15ex]
$\sigma$(\{Name\},\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},\{Name\}) :- atom(Name).\\[-0.15ex]
$\sigma$(\{Var:Type$\backslash$Pred\}, Insts, SubFrees, Bound, \{Avar:Stype$\backslash$Spred\}) :-\\[-0.15ex]
\hspace{2em}member(Var, SubFrees), $\sigma$(Type, Insts, SubFrees, Bound, Stype),\\[-0.15ex]
\hspace{2em}modify(Var, Avar), $\backslash$+ member(Avar, SubFrees), !,\\[-0.15ex]
\hspace{2em}$\sigma$(Pred, [(Var-Avar)$\mid$Insts], [Avar$\mid$SubFrees], Bound, Spred).\\[-0.15ex]
$\sigma$(\{Var:Type$\backslash$Pred\}, Insts, SubFrees, Bound, \{Var:Stype$\backslash$Spred\}) :-\\[-0.15ex]
\hspace{2em}$\sigma$(Type, Insts, SubFrees, Bound, Stype),\\[-0.15ex]
\hspace{2em}$\sigma$(Pred, Insts, SubFrees, [Var$\mid$Bound], Spred).\\[-0.15ex]
$\sigma$((Var:Type\#Pred), Insts, SubFrees, Bound, (Avar:Stype\#Spred)) :-\\[-0.15ex]
\hspace{2em}member(Var, SubFrees), $\sigma$(Type, Insts, SubFrees, Bound, Stype),\\[-0.15ex]
\hspace{2em}modify(Var, Avar), $\backslash$+ member(Avar, SubFrees),\\[-0.15ex]
\hspace{2em}!, $\sigma$(Pred, [(Var-Avar)$\mid$Insts], [Avar$\mid$SubFrees], Bound, Spred).\\[-0.15ex]
$\sigma$((Var:Type\#Pred), Insts, SubFrees, Bound, (Var:Stype\#Spred)) :-\\[-0.15ex]
\hspace{2em}$\sigma$(Type, Insts, SubFrees, Bound, Stype),\\[-0.15ex]
\hspace{2em}$\sigma$(Pred, Insts, SubFrees, [Var$\mid$Bound], Spred).\\[-0.15ex]
$\sigma$((Var:Type=$>$Pred), Insts, SubFrees, Bound, (Avar:Stype=$>$Spred)) :-\\[-0.15ex]
\hspace{2em}member(Var, SubFrees),!, $\sigma$(Type, Insts, SubFrees, Bound, Stype),\\[-0.15ex]
\hspace{2em}modify(Var, Avar), $\backslash$+ member(Avar, SubFrees),!,\\[-0.15ex]
\hspace{2em}$\sigma$(Pred, [(Var-Avar)$\mid$Insts], [Avar$\mid$SubFrees], Bound, Spred).\\[-0.15ex]
$\sigma$((Var:Type=$>$Pred), Insts, SubFrees, Bound, (Var:Stype=$>$Spred)) :-\\[-0.15ex]
\hspace{2em}!,$\sigma$(Type, Insts, SubFrees, Bound, Stype),\\[-0.15ex]
\hspace{2em}$\sigma$(Pred, Insts, SubFrees, [Var$\mid$Bound], Spred).\\[-0.15ex]
$\sigma$(lambda(Var,Pred), Insts, SubFrees, Bound, lambda(Avar,Spred)) :-\\[-0.15ex]
\hspace{2em}member(Var, SubFrees), modify(Var, Avar), $\backslash$+ member(Avar, SubFrees),\\[-0.15ex]
\hspace{2em}!, $\sigma$(Pred, [(Var-Avar)$\mid$Insts], [Avar$\mid$SubFrees], Bound, Spred).\\[-0.15ex]
$\sigma$(lambda(Var,Pred), Insts, SubFrees, Bound, lambda(Var,Spred)) :-\\[-0.15ex]
\hspace{2em}$\sigma$(Pred, Insts, SubFrees, [Var$\mid$Bound], Spred).\\[-0.15ex]
$\sigma$(rec(Var,Pred), Insts, SubFrees, Bound, rec(Avar,Spred)) :-\\[-0.15ex]
\hspace{2em}member(Var, SubFrees), modify(Var, Avar), $\backslash$+ member(Avar, SubFrees),\\[-0.15ex]
\hspace{2em}!, $\sigma$(Pred, [(Var-Avar)$\mid$Insts], [Avar$\mid$SubFrees], Bound, Spred).\\[-0.15ex]
$\sigma$(rec(Var,Pred), Insts, SubFrees, Bound, rec(Var,Spred)) :-\\[-0.15ex]
\hspace{2em}$\sigma$(Pred, Insts, SubFrees, [Var$\mid$Bound], Spred).\\[-0.15ex]
$\sigma$([Bind], Insts, SubFrees, Bound, [SBind]) :-\\[-0.15ex]
\hspace{2em}!, $\sigma$(Bind, Insts, SubFrees, Bound, SBind).\\[-0.15ex]
$\sigma$([{\verb`~`}$\mid$Binding], Insts, SubFrees, Bound, [{\verb`~`}$\mid$SBinding]) :-\\[-0.15ex]
\hspace{2em}!, $\sigma$(Binding, Insts, SubFrees, Bound, SBinding).\\[-0.15ex]
$\sigma$([Var$\mid$Bind], Insts, SubFrees, Bound, [Avar$\mid$SBind]) :-\\[-0.15ex]
\hspace{2em}member(Var, SubFrees), modify(Var, Avar), $\backslash$+ member(Avar, SubFrees),\\[-0.15ex]
\hspace{2em}!, $\sigma$(Bind, [(Var-Avar)$\mid$Insts], [Avar$\mid$SubFrees], Bound, SBind).\\[-0.15ex]
$\sigma$([Var$\mid$Bind], Insts, SubFrees, Bound, [Var$\mid$SBind]) :-\\[-0.15ex]
\hspace{2em}!, $\sigma$(Bind, Insts, SubFrees, [Var$\mid$Bound], SBind).
\end{tabbing}\end{sf}

 If no binding required, and not something to be substituted simply 
 substitute its arguments (if any):
\begin{sf}\begin{tabbing}
$\sigma$(Term, \_\hspace{0.1em}, \_\hspace{0.1em}, \_\hspace{0.1em}, Term) :- atomic(Term), !.
\end{tabbing}\end{sf}

 For compound terms, iterate over consituent parts of either first
 or last argument, depending on which one is instantiated,
 but exclude iteration over compound terms that have been treated as
 special cases above.
\begin{sf}\begin{tabbing}
$\sigma$(Term, Insts, SubFrees, Bound, STerm) :-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(Term),\\[-0.15ex]
\hspace{2em}Term =.. [Funct$\mid$Args],\\[-0.15ex]
\hspace{2em}$\backslash$+ member(Funct, [su,atom,term\_\hspace{0.1em}of,\{\},:,lambda,rec,{\verb`~`}]),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}$\sigma'$(Args, Insts, SubFrees, Bound, SArgs),\\[-0.15ex]
\hspace{2em}(var(STerm) -$>$\\[-0.15ex]
\hspace{2em}($\backslash$+ $\backslash$+ unify(STerm,SArgs),\\[-0.15ex]
\hspace{3em}STerm =.. [Funct$\mid$SArgs]);\\[-0.15ex]
\hspace{2em}(STerm =.. STermStruct,\\[-0.15ex]
\hspace{3em}unify(STermStruct, [Funct$\mid$SArgs]))).\\[-0.15ex]
$\sigma$(Term, Insts, SubFrees, Bound, STerm) :-\\[-0.15ex]
\hspace{2em}$\backslash$+ var(STerm),\\[-0.15ex]
\hspace{2em}STerm =.. [SFunct$\mid$SArgs],\\[-0.15ex]
\hspace{2em}$\backslash$+ member(SFunct, [su,atom,term\_\hspace{0.1em}of,\{\},:,lambda,rec,{\verb`~`}]),\\[-0.15ex]
\hspace{2em}$\sigma'$(Args, Insts, SubFrees, Bound, SArgs),\\[-0.15ex]
\hspace{2em}(var(Term) -$>$\\[-0.15ex]
\hspace{2em}($\backslash$+ $\backslash$+ unify(Term,Args),\\[-0.15ex]
\hspace{3em}Term =.. [SFunct$\mid$Args]);\\[-0.15ex]
\hspace{2em}(Term =.. TermStruct,\\[-0.15ex]
\hspace{3em}unify(TermStruct, [SFunct$\mid$Args]))).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{substitutedlist}
\begin{sf}\begin{tabbing}
$\sigma'$([],\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},[]).\\[-0.15ex]
$\sigma'$([H$\mid$T], Insts, SubFrees, Bound, [HH$\mid$TT]) :-\\[-0.15ex]
\hspace{2em}$\sigma$(H,Insts, SubFrees, Bound, HH),\\[-0.15ex]
\hspace{2em}$\sigma'$(T, Insts, SubFrees, Bound, TT).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{slist}
\begin{sf}\begin{tabbing}
slist([],\_\hspace{0.1em},\_\hspace{0.1em},[]).\\[-0.15ex]
slist([H$\mid$T],Y,X,[HH$\mid$TT]) :- s(H,Y,X,HH), slist(T,Y,X,TT).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{shyp}
\begin{sf}\begin{tabbing}
shyp(H0,H==$>$G,Y,X,HH==$>$GG):-shyp(H0,H,Y,X,HH),s(G,Y,X,GG),!.\\[-0.15ex]
shyp(\_\hspace{0.1em},[],\_\hspace{0.1em},\_\hspace{0.1em},[]).\\[-0.15ex]
shyp(H,[\_\hspace{0.1em}:D$\mid$T],Y,X,TT):- s(D,Y,X,DD),$\alpha$(D,DD),!,shyp(H,T,Y,X,TT).\\[-0.15ex]
shyp(H,[\_\hspace{0.1em}:D$\mid$T],Y,X,[VV:DD$\mid$TT]):-\\[-0.15ex]
\hspace{1em}s(D,Y,X,DD),free([VV],H,HH),!,shyp(HH,T,Y,X,TT).\\[-0.15ex]
shyp(H,[\_\hspace{0.1em}:D$\mid$T],Y,X,[VV:DD$\mid$TT]):-\\[-0.15ex]
\hspace{1em}s(D,Y,X,DD),free([VV],H,HH),!,shyp(HH,T,Y,X,TT).\\[-0.15ex]
shyp(H,[\_\hspace{0.1em}$\mid$T],Y,X,TT):-shyp(H,T,Y,X,TT).\\[-0.7ex]

\end{tabbing}\end{sf}

 \section{Free variables}
 A variable is free in a term if it is a subterm of the term, and is
 not bound by the product, subset, or function types, or in a lambda
 or decision or induction term.
 $freevarinterm(Term, Var)$ succeeds if $Var$ is free in $Term$, 
 $freevarsinterm(Term, Vars)$ succeeds if $Vars$ is the set of free variables
 in $Term$. $appears(X,Y)$ is a predicate which tests whether
 $X$ is a subterm of $Y$ or not. It may be used for generating
 subterms of a certain pattern. $modify(v,v')$ modifies the
 variable name $v$ by appending an underscore. 
 \ulinv{freevarsinterm}
\begin{sf}\begin{tabbing}
freevarsinterm(Tm, Vars) :- setof(Var, freevarinterm(Tm,Var), Vars), !.\\[-0.15ex]
freevarsinterm(\_\hspace{0.1em}, []).\\[-0.7ex]

\end{tabbing}\end{sf}

 A Prolog Variable:
 \ulinv{freevarinterm}
\begin{sf}\begin{tabbing}
freevarinterm(X, \_\hspace{0.1em}) :- var(X), !, fail.
\end{tabbing}\end{sf}

 Atomic terms non-atomic in prolog
\begin{sf}\begin{tabbing}
freevarinterm(term\_\hspace{0.1em}of(\_\hspace{0.1em}),\_\hspace{0.1em}) :- !,fail.\\[-0.15ex]
freevarinterm(atom(\_\hspace{0.1em}),\_\hspace{0.1em})  :- !,fail.\\[-0.15ex]
freevarinterm(\{N\},\_\hspace{0.1em}) :- atom(N),!,fail.
\end{tabbing}\end{sf}

 The binding term from decision or induction terms:
\begin{sf}\begin{tabbing}
freevarinterm([H$\mid$T], Var) :- \\[-0.15ex]
\hspace{2em}!, append(BoundVars, [Term], [H$\mid$T]), freevarinterm(Term, Var),\\[-0.15ex]
\hspace{2em}$\backslash$+ member(Var, BoundVars).
\end{tabbing}\end{sf}

 The binding types:
\begin{sf}\begin{tabbing}
freevarinterm((\_\hspace{0.1em}:T1\#\_\hspace{0.1em}), Var) :- freevarinterm(T1,Var).\\[-0.15ex]
freevarinterm((V:\_\hspace{0.1em}\#T2), Var) :- !, freevarinterm(T2,Var), $\backslash$+ Var = V.\\[-0.15ex]
freevarinterm((\_\hspace{0.1em}:T1=$>$\_\hspace{0.1em}), Var) :- freevarinterm(T1,Var).\\[-0.15ex]
freevarinterm((V:\_\hspace{0.1em}=$>$T2), Var) :- !, freevarinterm(T2,Var), $\backslash$+ Var = V.\\[-0.15ex]
freevarinterm((\{\_\hspace{0.1em}:T1$\backslash$\_\hspace{0.1em}\}), Var) :- freevarinterm(T1,Var).\\[-0.15ex]
freevarinterm((\{V:\_\hspace{0.1em}$\backslash$T2\}), Var) :- !, freevarinterm(T2,Var), $\backslash$+ Var = V.\\[-0.15ex]
freevarinterm(rec(V,T), Var) :- !, freevarinterm(T, Var), $\backslash$+ V = Var.
\end{tabbing}\end{sf}

 lambda term:
\begin{sf}\begin{tabbing}
freevarinterm(lambda(V,T), Var) :- !, freevarinterm(T, Var), $\backslash$+ V = Var.\\[-0.15ex]
freevarinterm(Var,Var) :- $\tau_{var}$(Var).
\end{tabbing}\end{sf}

 Non-binding connectives etc:
\begin{sf}\begin{tabbing}
freevarinterm(Tm, Var) :- Tm =.. [\_\hspace{0.1em}$\mid$Args], member(Arg,Args), freevarinterm(Arg, Var).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{appears}
\begin{sf}\begin{tabbing}
appears(\_\hspace{0.1em},X):-var(X),!,fail.\\[-0.15ex]
appears(Y,X):-$\alpha$(Y,X),!.\\[-0.15ex]
appears(\_\hspace{0.1em},[]):-!,fail.\\[-0.15ex]
appears(Y,[H$\mid$T]):-!,( appears(Y,H); appears(Y,T) ).\\[-0.15ex]
appears(Y,X):-X=..[F$\mid$A],(F==Y ; appears(Y,A)).\\[-0.15ex]
\hspace{0em}
\end{tabbing}\end{sf}

 \ulinv{modify}
\begin{sf}\begin{tabbing}
modify(X,Y):-atom\_\hspace{0.1em}codes(X,XX),underscore(Z),append(XX,[Z],YY),atom\_\hspace{0.1em}codes(Y,YY).\\[-0.15ex]
modify(X,Z):-modify(X,Y),modify(Y,Z).
\end{tabbing}\end{sf}

 \section{Convertible Terms}
 Two types are called convertible if they are identical except possibly
 for renaming of bound variables. The scope of implicitly bound 
 variables
 (as for example inside induction terms) is always given as a Prolog 
 list, the last element of which is the term under consideration.
 This identifies \verb|X:A=>B| and \verb|A=>B| where X does not occur
 free in B.
 \ulinv{convertible}
\begin{sf}\begin{tabbing}
$\alpha$(X,Y):-(var(X);var(Y)),X=Y,!.\\[-0.15ex]
$\alpha$(X,Y):- ground(X), ground(Y), X=Y, !.\\[-0.15ex]
$\alpha$(X,Y):-(atom(X);atom(Y)),X=Y,!.\\[-0.15ex]
$\alpha$(X,Y):-(integer(X);integer(Y)),X=Y,!.\\[-0.15ex]
$\alpha$([X,T],[XX,TT]):- free([V],[X:dummy,T:dummy,XX:dummy,TT:dummy]),\\[-0.15ex]
\hspace{1em}s(T,[V],[X],T0),s(TT,[V],[XX],TT0),!,$\alpha$(T0,TT0).\\[-0.15ex]
$\alpha$([X,Y,T],[XX,YY,TT]):-\\[-0.15ex]
	free([U,V],[X:dummy,Y:dummy,T:dummy,XX:dummy,YY:dummy,TT:dummy]),\\[-0.15ex]
\hspace{1em}s(T,[U,V],[X,Y],T0),s(TT,[U,V],[XX,YY],TT0),!,$\alpha$(T0,TT0).\\[-0.15ex]
$\alpha$([X,Y,Z,T],[XX,YY,ZZ,TT]):-\\[-0.15ex]
	free([U,V,W],\\[-0.15ex]
\hspace{0em}[X:dummy,Y:dummy,Z:dummy,T:dummy,XX:dummy,YY:dummy,ZZ:dummy,TT:dummy]),\\[-0.15ex]
s(T,[U,V,W],[X,Y,Z],T0),s(TT,[U,V,W],[XX,YY,ZZ],TT0),!,$\alpha$(T0,TT0).
\end{tabbing}\end{sf}

  
\begin{sf}\begin{tabbing}
$\alpha$(rec(X,A),rec(XX,AA)):-!,$\alpha$([X,A],[XX,AA]).\\[-0.15ex]
$\alpha$(lambda(X,A),lambda(XX,AA)):-!,$\alpha$([X,A],[XX,AA]).
\end{tabbing}\end{sf}

  
\begin{sf}\begin{tabbing}
$\alpha$(X:A\#B,XX:AA\#BB):-!,$\alpha$(A,AA),$\alpha$([X,B],[XX,BB]).\\[-0.15ex]
$\alpha$(X:A=$>$B,XX:AA=$>$BB):-!,$\alpha$(A,AA),$\alpha$([X,B],[XX,BB]).\\[-0.15ex]
$\alpha$(X:A=$>$B,AA=$>$BB):-!,$\backslash$+ freevarinterm(B,X),$\alpha$(A=$>$B,AA=$>$BB).\\[-0.15ex]
$\alpha$(A=$>$B,X:AA=$>$BB):-!,$\backslash$+ freevarinterm(BB,X),$\alpha$(A=$>$B,AA=$>$BB).\\[-0.15ex]
$\alpha$(\{X:A$\backslash$B\},\{XX:AA$\backslash$BB\}):-!,$\alpha$(A,AA),$\alpha$([X,B],[XX,BB]).\\[-0.15ex]
$\alpha$(A=B in T,AA=BB in TT):-!,$\alpha$(T,TT), ($\alpha$(A,AA),$\alpha$(B,BB); $\alpha$(A,BB),$\alpha$(B,AA)),!.\\[-0.15ex]
$\alpha$(A in T, AA=BB in TT):-$\alpha$(T,TT), $\alpha$(A,AA),$\alpha$(AA,BB).\\[-0.15ex]
$\alpha$(AA=BB in TT, A in T):-$\alpha$(T,TT), $\alpha$(A,AA),$\alpha$(AA,BB).
\end{tabbing}\end{sf}

  
\begin{sf}\begin{tabbing}
$\alpha$(X,XX):-X=..[F$\mid$A],XX=..[F$\mid$AA],$\alpha'$(A,AA).
\end{tabbing}\end{sf}

 \ulinv{convertlist}
\begin{sf}\begin{tabbing}
$\alpha'$([],[]).\\[-0.15ex]
$\alpha'$([A$\mid$L],[AA$\mid$LL]):-$\alpha$(A,AA),$\alpha'$(L,LL).
\end{tabbing}\end{sf}

  
 \small
 \section{Support for Peano Natural Numbers}
 Simple support functions for peano natural numbers..
 \ulinv{pnat,pless,s\_subterm,s\_strip}
\begin{sf}\begin{tabbing}
pnat( s(X) ) :- pnat(X).\\[-0.15ex]
pnat( 0 ).\\[-0.15ex]
pnat( X ) :- nonvar(X),!,fail.\\[-0.15ex]
pdecide(s(X),s(Y),R) :-\\[-0.15ex]
\hspace{2em}pdecide(X,Y,R).\\[-0.15ex]
pdecide(0,0,equal).\\[-0.15ex]
pdecide(0,s(\_\hspace{0.1em}),less).\\[-0.15ex]
pdecide(s(\_\hspace{0.1em}),0,more).\\[-0.15ex]
pless( X,Y ) :- pdecide(X,Y,less).\\[-0.7ex]
\\[-0.15ex]
s\_\hspace{0.1em}subterm( S, S ) :- !.\\[-0.15ex]
s\_\hspace{0.1em}subterm( s(T), S ) :-\\[-0.15ex]
\hspace{2em}s\_\hspace{0.1em}subterm( T , S).\\[-0.7ex]
\\[-0.15ex]
s\_\hspace{0.1em}strip( s(A)$<$*s(B), AA$<$*BB ) :-\\[-0.15ex]
\hspace{2em}s\_\hspace{0.1em}strip( A$<$*B, AA$<$*BB ),\\[-0.15ex]
\hspace{2em}!.\\[-0.15ex]
s\_\hspace{0.1em}strip( L,L ).\\[-0.7ex]

\end{tabbing}\end{sf}

 \section{Legality of Recursive Types}
 Implements restrictions as in NuPRL
 \ulinv{illegal\_rec\_type} \ulinv{appears\_in}
\begin{sf}\begin{tabbing}
illegal\_\hspace{0.1em}rec\_\hspace{0.1em}type(rec(Z,T)) :-\\[-0.15ex]
\hspace{4em}( occurs\_\hspace{0.1em}in\_\hspace{0.1em}dom(Z,T);\\[-0.15ex]
\hspace{5em}occurs\_\hspace{0.1em}in\_\hspace{0.1em}fn\_\hspace{0.1em}app(Z,T);\\[-0.15ex]
\hspace{5em}occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) ),\\[-0.15ex]
\hspace{5em}write(' Illegal recursive type ! '), nl.\\[-0.7ex]
\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}dom(Z,T) :- appears\_\hspace{0.1em}in( X=$>$\_\hspace{0.1em} , T ),\\[-0.15ex]
\hspace{11em}appears\_\hspace{0.1em}in( Z, X ).\\[-0.7ex]
\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}fn\_\hspace{0.1em}app(Z,T) :- appears\_\hspace{0.1em}in(\_\hspace{0.1em} of X,T),\\[-0.15ex]
\hspace{12em}appears\_\hspace{0.1em}in(Z,X).\\[-0.7ex]
\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(p\_\hspace{0.1em}ind(X,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(Z,X).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(cv\_\hspace{0.1em}ind(X,\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(Z,X).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(ind(X,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(Z,X).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(list\_\hspace{0.1em}ind(X,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(Z,X).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(rec\_\hspace{0.1em}ind(X,\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(Z,X).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(atom\_\hspace{0.1em}eq(X,Y,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,[X,Y]).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(int\_\hspace{0.1em}eq(X,Y,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,[X,Y]).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(less(X,Y,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,[X,Y]).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(atom\_\hspace{0.1em}eq(X,Y,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,[X,Y]).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(pnat\_\hspace{0.1em}eq(X,Y,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,[X,Y]).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(pless(X,Y,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,[X,Y]).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(decide(X,\_\hspace{0.1em},\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(Z,X).\\[-0.15ex]
occurs\_\hspace{0.1em}in\_\hspace{0.1em}elim\_\hspace{0.1em}form(Z,T) :- \\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(spread(X,\_\hspace{0.1em}),T),\\[-0.15ex]
\hspace{6em}appears\_\hspace{0.1em}in(Z,X).\\[-0.7ex]
\\[-0.15ex]
appears\_\hspace{0.1em}in(Z,Z).\\[-0.15ex]
appears\_\hspace{0.1em}in(Z,F) :- F=..[\_\hspace{0.1em}$\mid$T], appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,T).\\[-0.15ex]
appears\_\hspace{0.1em}in\_\hspace{0.1em}list(\_\hspace{0.1em},[]) :- !,fail.\\[-0.15ex]
appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,[H$\mid$T]) :- (appears\_\hspace{0.1em}in(Z,H) ; appears\_\hspace{0.1em}in\_\hspace{0.1em}list(Z,T)).\\[-0.7ex]
\\[-0.7ex]

\end{tabbing}\end{sf}

 \section{Type Checking}
 Although in the given logical framework the type checking 
 problem in general is not decidable, there are a lot of cases
 appearing in every day proofs, where the type property 
 may be derived automatically.
 $type(X,H,T)$ is a predicate which computes for a small class
 of terms $X$ the type $T$ under the assumptions $H$.
 $type0(...)$ is a more
 general predicate checking the consistency of type information.
 \ulinv{type}
\begin{sf}\begin{tabbing}
type(V,H,T):-atom(V),decl(V:rec(Z,TT),H),s(TT,[rec(Z,TT)],[Z],T),!.\\[-0.15ex]
type(V,H,T):-atom(V),decl(V:T,H),!.\\[-0.15ex]
type(atom(\_\hspace{0.1em}),\_\hspace{0.1em},atom).\\[-0.15ex]
type(I,\_\hspace{0.1em},int):-integer(I).\\[-0.15ex]
type(X of Y,H,T):-type(X,H,TT=$>$T),type0(Y,H,TT).\\[-0.15ex]
type(X::Y,H,T list):-type(X,H,T),type0(Y,H,T list).\\[-0.15ex]
type(X\&Y,H,T\#TT):-type(X,H,T),type(Y,H,TT).\\[-0.15ex]
type(X,\_\hspace{0.1em},int):-functor(X,F,2),member(F,[+,-,*,/,mod]).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{type0}
\begin{sf}\begin{tabbing}
type0(X,H,T):-type(X,H,T).\\[-0.15ex]
type0(nil,\_\hspace{0.1em},\_\hspace{0.1em} list).\\[-0.15ex]
type0(inl(X),H,T$\backslash$\_\hspace{0.1em}):-type(X,H,T).\\[-0.15ex]
type0(inr(X),H,\_\hspace{0.1em}$\backslash$T):-type(X,H,T).
\end{tabbing}\end{sf}

 \section{Rewrite Rules}
 Term rewriting $X \mapsto Y$ is described by the $\varphi(X,Y)$ predicate.
 \ulinv{rewrite}
\begin{sf}\begin{tabbing}
$\varphi$(X,X) :- var(X), !.\\[-0.15ex]
$\varphi$(lambda(X,B) of (A),Z):-s(B,[A],[X],Z).\\[-0.15ex]
$\varphi$(spread(X\&Y,[U,V,T]),Z):-s(T,[X,Y],[U,V],Z).\\[-0.15ex]
$\varphi$(decide(inl(A),[X,S],\_\hspace{0.1em}),Z):-s(S,[A],[X],Z).\\[-0.15ex]
$\varphi$(decide(inr(A),\_\hspace{0.1em},[X,S]),Z):-s(S,[A],[X],Z).\\[-0.15ex]
$\varphi$(list\_\hspace{0.1em}ind(nil,X,\_\hspace{0.1em}),X).\\[-0.15ex]
$\varphi$(list\_\hspace{0.1em}ind(A::B,S,[X,Y,U,T]),Z):- s(T,[A,B,list\_\hspace{0.1em}ind(B,S,[X,Y,U,T])],[X,Y,U],Z).\\[-0.15ex]
$\varphi$(p\_\hspace{0.1em}ind(0,X,\_\hspace{0.1em}),X).\\[-0.15ex]
$\varphi$(p\_\hspace{0.1em}ind(s(A),B,[X,Y,T]),Z):-s(T,[A,p\_\hspace{0.1em}ind(A,B,[X,Y,T])],[X,Y],Z).\\[-0.15ex]
$\varphi$(cv\_\hspace{0.1em}ind(R,[H,I,T]),Z):-\\[-0.15ex]
\hspace{2em}genvar(V),$\backslash$+ appears(V,[H,I,T,R]),\\[-0.15ex]
\hspace{2em}s(T,[R,lambda(V,cv\_\hspace{0.1em}ind(V,[H,I,T]))],[H,I],Z),!.\\[-0.15ex]
$\varphi$(wo\_\hspace{0.1em}ind(R,[H,I,T]),Z):-\\[-0.15ex]
\hspace{2em}genvar(V),$\backslash$+ appears(V,[H,I,T,R]),\\[-0.15ex]
\hspace{2em}s(T,[R,lambda(V,wo\_\hspace{0.1em}ind(V,[H,I,T]))],[H,I],Z),!.\\[-0.15ex]
$\varphi$(rec\_\hspace{0.1em}ind(R,[H,I,T]),Z):-\\[-0.15ex]
\hspace{2em}genvar(V),$\backslash$+\\[-0.15ex]
\hspace{2em}appears(V,[H,I,T,R]),s(T,[lambda(V,rec\_\hspace{0.1em}ind(V,[H,I,T])),R],[H,I],Z),!.\\[-0.15ex]
$\varphi$(pnat\_\hspace{0.1em}eq(A,B,S,\_\hspace{0.1em}),S):- pdecide(A,B,equal).\\[-0.15ex]
$\varphi$(pnat\_\hspace{0.1em}eq(A,B,\_\hspace{0.1em},T),T):- pdecide(A,B,R), $\backslash$+ R = equal.\\[-0.15ex]
$\varphi$(pless(A,B,S,\_\hspace{0.1em}),S):- pdecide(A,B,less).\\[-0.15ex]
$\varphi$(pless(A,B,\_\hspace{0.1em},T),T):- pdecide(A,B,R), $\backslash$+ R = less.\\[-0.15ex]
$\varphi$(ind(N,[X,Y,Z],B,S),T):- \\[-0.15ex]
\hspace{2em}integer(N),N$<$0,NN is N+1,s(Z,[N,ind(NN,[X,Y,Z],B,S)],[X,Y],T).\\[-0.15ex]
$\varphi$(ind(0,\_\hspace{0.1em},B,\_\hspace{0.1em}),B).\\[-0.15ex]
$\varphi$(ind(N,S,B,[U,V,W]),T):- \\[-0.15ex]
\hspace{2em}integer(N),N$>$0,NN is N-1,s(W,[N,ind(NN,S,B,[U,V,W])],[U,V],T).\\[-0.15ex]
$\varphi$(atom\_\hspace{0.1em}eq(atom(A),atom(B),S,\_\hspace{0.1em}),S):-A=B.\\[-0.15ex]
$\varphi$(atom\_\hspace{0.1em}eq(atom(A),atom(B),\_\hspace{0.1em},T),T):-A$\backslash$==B.\\[-0.15ex]
$\varphi$(int\_\hspace{0.1em}eq(A,B,S,\_\hspace{0.1em}),S):-integer(A),integer(B),A=B.\\[-0.15ex]
$\varphi$(int\_\hspace{0.1em}eq(A,B,\_\hspace{0.1em},T),T):-integer(A),integer(B),A=$\backslash$=B.\\[-0.15ex]
$\varphi$(less(A,B,S,\_\hspace{0.1em}),S):-integer(A),integer(B),A$<$B.\\[-0.15ex]
$\varphi$(less(A,B,\_\hspace{0.1em},T),T):-integer(A),integer(B),A$>$=B.\\[-0.15ex]
$\varphi$(-A, Z):-integer(A),Z is -A.\\[-0.15ex]
$\varphi$(0+B,B):-!.\\[-0.15ex]
$\varphi$(A+0,A):-!.\\[-0.15ex]
$\varphi$(A+B,Z):-integer(A),integer(B),Z is A+B.\\[-0.15ex]
$\varphi$(A-B,Z):-integer(A),integer(B),Z is A-B.\\[-0.15ex]
$\varphi$(A-0,A):-!.\\[-0.15ex]
$\varphi$(0*\_\hspace{0.1em},0):-!.\\[-0.15ex]
$\varphi$(\_\hspace{0.1em}*0,0):-!.\\[-0.15ex]
$\varphi$(1*B,B):-!.\\[-0.15ex]
$\varphi$(A*1,A):-!.\\[-0.15ex]
$\varphi$(A*B,Z):-integer(A),integer(B),Z is A*B.\\[-0.15ex]
$\varphi$(A/1,A):-!.\\[-0.15ex]
$\varphi$(A/B,Z):-integer(A),integer(B),Z is A//B.\\[-0.15ex]
$\varphi$(A mod B,Z):-integer(A),integer(B),Z is A mod B.\\[-0.15ex]
$\varphi$(term\_\hspace{0.1em}of(T),TT) :-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(T) =: P,
\end{tabbing}\end{sf}

%% The following restriction prevents extraction from incomplete proofs:
%%   $status_0$(P,complete),
\begin{sf}\begin{tabbing}
\hspace{2em}$extract$(P,TTraw),polish(TTraw,TT).\\[-0.15ex]
$\varphi$(\{F\},TT) :-\\[-0.15ex]
\hspace{2em}cdef(F) =: (\{F\}$<$==$>$TT).\\[-0.15ex]
$\varphi$(T,TT) :-\\[-0.15ex]
\hspace{2em}T=..[F$\mid$A],\\[-0.15ex]
\hspace{2em}$\backslash$+ F = \{\},\\[-0.15ex]
\hspace{2em}cdef(F) =: (T1$<$==$>$T2),\\[-0.15ex]
\hspace{2em}T1=..[F$\mid$P],\\[-0.15ex]
\hspace{2em}s(T2,A,P,TT).\\[-0.7ex]
\\[-0.15ex]
$\varphi$(0,X,Z):-$\varphi$(X,Y),!,$\varphi$(0,Y,Z).\\[-0.15ex]
$\varphi$(0,X,X).\\[-0.15ex]
$\varphi$(1,X,Z):-$\varphi$(X,Z).\\[-0.15ex]
$\varphi$(N,X,Z):-integer(N),N$>$1,NN is N-1,$\varphi$(X,Y),$\varphi$(NN,Y,Z).\\[-0.7ex]

\end{tabbing}\end{sf}

  
 \section{Evaluation}
 The evaluation predicate $eval(X,Y)$ allows the direct execution 
 of extract terms or user supplied terms $X$ in the Prolog environment,
 yielding the result value as second parameter $Y$. A typical example
 for using the evaluator is in defining executable Prolog predicates
 using the extract terms derived from a theorem proven inside Oyster.
 Evaluating a term requires first the evaluation of each subterm and 
 then rewriting of the resulting term. 
 It is useful to apply $eval$ at least once after extracting the
 term and running it, just in the sense of a partial evaluator.
 \ulinv{eval}
\begin{sf}\begin{tabbing}
eval(X,X) :- var(X),!.\\[-0.15ex]
eval(lambda(X,B) of (A),R):-eval(B,[A],[X],R),!.\\[-0.15ex]
eval(X of Y, R) :- eval(X, XX), $\backslash$+(X=XX), eval(XX of Y, R), !.\\[-0.7ex]
\\[-0.15ex]
eval(spread(A,[U,V,T]),R):-\\[-0.15ex]
\hspace{2em}eval(A,AA),\\[-0.15ex]
\hspace{2em}(AA=(X\&Y),eval(T,[X,Y],[U,V],R);\\[-0.15ex]
\hspace{3em}R=spread(AA,[U,V,T])\\[-0.15ex]
\hspace{2em}),!.\\[-0.7ex]
\\[-0.15ex]
eval(decide(A,[X,S],[Y,T]),C):-\\[-0.15ex]
\hspace{1em}eval(A,AA),\\[-0.15ex]
\hspace{1em}(AA=inl(B),eval(S,[B],[X],C);\\[-0.15ex]
\hspace{2em}AA=inr(B),eval(T,[B],[Y],C);\\[-0.15ex]
\hspace{2em}C=decide(AA,[X,S],[Y,T])\\[-0.15ex]
\hspace{1em}),!.\\[-0.7ex]
\\[-0.15ex]
eval(list\_\hspace{0.1em}ind(L,S,[X,Y,U,T]),C):-\\[-0.15ex]
\hspace{1em}eval(L,LL),\\[-0.15ex]
\hspace{1em}(LL=nil,eval(S,C);\\[-0.15ex]
\hspace{2em}LL=A::B,eval(T,[A,B,list\_\hspace{0.1em}ind(B,S,[X,Y,U,T])],[X,Y,U],C);\\[-0.15ex]
\hspace{2em}evalcond(U,T,TT),C=list\_\hspace{0.1em}ind(L,S,[X,Y,U,TT])\\[-0.15ex]
\hspace{1em}),!.\\[-0.7ex]
\\[-0.15ex]
eval(p\_\hspace{0.1em}ind(N,S,[X,Y,T]),C):-\\[-0.15ex]
\hspace{1em}eval(N,NN),\\[-0.15ex]
\hspace{1em}(NN=0,eval(S,C);\\[-0.15ex]
\hspace{2em}NN=s(A),eval(T,[A,p\_\hspace{0.1em}ind(A,S,[X,Y,T])],[X,Y],C);\\[-0.15ex]
\hspace{2em}evalcond(Y,T,TT),C=p\_\hspace{0.1em}ind(NN,S,[X,Y,TT])\\[-0.15ex]
\hspace{1em}),!.\\[-0.7ex]
\\[-0.15ex]
eval(cv\_\hspace{0.1em}ind(N,[X,Y,T]),C):-\\[-0.15ex]
\hspace{1em}eval(N,NN),\\[-0.15ex]
\hspace{1em}(pnat(NN),genvar(V), $\backslash$+ appears(V,[N,X,Y,T]),\\[-0.15ex]
\hspace{2em}eval(T,[NN,lambda(V,cv\_\hspace{0.1em}ind(V,[X,Y,T]))],[X,Y],C);\\[-0.15ex]
\hspace{2em}evalcond(Y,T,TT),C=cv\_\hspace{0.1em}ind(NN,[X,Y,TT])\\[-0.15ex]
\hspace{1em}),!.\\[-0.7ex]
\\[-0.15ex]
eval(wo\_\hspace{0.1em}ind(N,[X,Y,T]),C):-\\[-0.15ex]
	$\backslash$+var(N),eval(N,Nx),\\[-0.15ex]
	genvar(V),$\backslash$+appears(V,[X,Y,T,Nx]),\\[-0.15ex]
	s(T,[Nx,lambda(V,wo\_\hspace{0.1em}ind(V,[X,Y,T]))],[X,Y],Cx),\\[-0.15ex]
	eval(Cx,C),!.\\[-0.7ex]
\\[-0.15ex]
eval(atom\_\hspace{0.1em}eq(A,B,S,T),R):-\\[-0.15ex]
\hspace{1em}eval(A,atom(X)),eval(B,atom(Y)), (X=Y-$>$eval(S,R);eval(T,R)),!.\\[-0.15ex]
eval(int\_\hspace{0.1em}eq(A,B,S,T),R):-\\[-0.15ex]
\hspace{1em}eval(A,X),eval(B,Y),integer(X),integer(Y),(X=Y,eval(S,R);eval(T,R)),!.\\[-0.15ex]
eval(less(A,B,S,T),R):-\\[-0.15ex]
\hspace{1em}eval(A,X),eval(B,Y),integer(X),integer(Y),(X$<$Y,eval(S,R);eval(T,R)),!.\\[-0.15ex]
eval(pnat\_\hspace{0.1em}eq(A,B,S,T),RR):-\\[-0.15ex]
\hspace{1em}eval(A,X),eval(B,Y),pdecide(X,Y,R),\\[-0.15ex]
\hspace{1em}(R=equal,eval(S,RR);eval(T,RR)),!.\\[-0.15ex]
eval(pless(A,B,S,T),RR):-\\[-0.15ex]
\hspace{1em}eval(A,X),eval(B,Y),pdecide(X,Y,R),\\[-0.15ex]
\hspace{1em}(R=less,eval(S,RR);eval(T,RR)),!.\\[-0.7ex]
\\[-0.15ex]
eval(-A, Z):-eval(A,X),$\varphi$(-X,Z),!.\\[-0.15ex]
eval(A+B,Z):-eval(A,X),eval(B,Y),$\varphi$(X+Y,Z),!.\\[-0.15ex]
eval(A-B,Z):-eval(A,X),eval(B,Y),$\varphi$(X-Y,Z),!.\\[-0.15ex]
eval(A*B,Z):-eval(A,X),eval(B,Y),$\varphi$(X*Y,Z),!.\\[-0.15ex]
eval(A/B,Z):-eval(A,X),eval(B,Y),$\varphi$(X/Y,Z),!.\\[-0.15ex]
eval(A mod B,Z):-eval(A,X),eval(B,Y),$\varphi$(X mod Y,Z),!.\\[-0.7ex]
\\[-0.15ex]
eval(ind(N,[X,Y,Z],B,[U,V,W]),T):- \\[-0.15ex]
\hspace{1em}eval(N,NN),\\[-0.15ex]
\hspace{1em}(integer(NN),NN$<$0,N0 is NN+1,eval(Z,[NN,ind(N0,[X,Y,Z],B,S)],[X,Y],T);\\[-0.15ex]
\hspace{2em}NN=0,eval(B,T);\\[-0.15ex]
\hspace{2em}integer(NN),NN$>$0,N0 is NN-1,eval(W,[NN,ind(N0,S,B,[U,V,W])],[U,V],T);\\[-0.15ex]
\hspace{2em}evalcond(Y,Z,ZZ),evalcond(V,W,WW),T=ind(NN,[X,Y,ZZ],B,[U,V,WW])\\[-0.15ex]
\hspace{1em}),!.\\[-0.7ex]
\\[-0.15ex]
eval(rec\_\hspace{0.1em}ind(R,[H,I,T]),Z):-\\[-0.15ex]
\hspace{1em}eval(R,RR),\\[-0.15ex]
\hspace{1em}genvar(V),$\backslash$+ appears(V,[H,I,T,RR]),\\[-0.15ex]
\hspace{1em}s(T,[lambda(V,rec\_\hspace{0.1em}ind(V,[H,I,T])),RR],[H,I],ZZ),\\[-0.15ex]
\hspace{1em}eval(ZZ,Z),!.\\[-0.7ex]
\\[-0.15ex]
eval(X,Y):-\\[-0.15ex]
\hspace{1em}X=..[F$\mid$A],hypothesis(D$<$==$>$E),D=..[F$\mid$B],eval(E,A,B,Y).\\[-0.7ex]
\\[-0.15ex]
eval(\{F\},Z) :-\\[-0.15ex]
\hspace{2em}atom(F),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}cdef(F) =: (\{F\}$<$==$>$TT),\\[-0.15ex]
\hspace{2em}eval(TT,ZZ),\\[-0.15ex]
\hspace{2em}eval(ZZ,Z).\\[-0.7ex]
\\[-0.15ex]
eval(T,Z) :-\\[-0.15ex]
\hspace{2em}T=..[F$\mid$A],\\[-0.15ex]
\hspace{2em}cdef(F) =: (T1$<$==$>$T2),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}T1=..[F$\mid$P],\\[-0.15ex]
\hspace{2em}evallist(A,B),\\[-0.15ex]
\hspace{2em}s(T2,B,P,ZZ),\\[-0.15ex]
\hspace{2em}eval(ZZ,Z).\\[-0.7ex]
\\[-0.15ex]
eval(term\_\hspace{0.1em}of(T),Z):-\\[-0.15ex]
\hspace{2em}$\vartheta_{\it theorem}$(T) =: P,\\[-0.15ex]
\hspace{2em}$extract$(P,Eraw),\\[-0.15ex]
\hspace{2em}$\backslash$+var(Eraw),\\[-0.15ex]
\hspace{2em}polish(Eraw,E),\\[-0.15ex]
\hspace{2em}eval(E,Z).\\[-0.7ex]
\\[-0.15ex]
eval(X,Y):-\\[-0.15ex]
\hspace{1em}X=..[F$\mid$A],\\[-0.15ex]
\hspace{1em}$\backslash$+ member(F,[atom,lambda,ind,list\_\hspace{0.1em}ind,rec\_\hspace{0.1em}ind,wo\_\hspace{0.1em}ind,pnat\_\hspace{0.1em}eq,atom\_\hspace{0.1em}eq,int\_\hspace{0.1em}eq,less,pless]),\\[-0.15ex]
\hspace{1em}evallist(A,B),Y=..[F$\mid$B],!.\\[-0.15ex]
eval(X,X).\\[-0.7ex]
\\[-0.15ex]
eval(T,L1,L2,TT) :- s(T,L1,L2,T1), eval(T1,TT).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{evallist}
\begin{sf}\begin{tabbing}
evallist([],[]).\\[-0.15ex]
evallist([X$\mid$XX],[Y$\mid$YY]):-eval(X,Y),evallist(XX,YY).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{evalcond}
\begin{sf}\begin{tabbing}
evalcond(V,T,T):-appears(V,T),!.\\[-0.15ex]
evalcond(\_\hspace{0.1em},T,TT):-eval(T,TT).
\end{tabbing}\end{sf}

 \section{Computation of tagged terms $[[t]]$}
 The compute rule has been generalised to get a simple user
 interface to all different kinds of possible and sound rewritings.
 The use of anonymous variables allows you to use partial
 specifications of the term structure.
 $compute(T,X,Y,H,S)$ describes the process of computing $X$
 guided by some \emph{tagged term} $T$ under the assumption of the
 \emph{hypotheses} $H$, which results in $Y$ and possibly a
 set of subgoals which have to be proven to satisfy this
 computation process.
 \ulinv{compute\_old}
\begin{sf}\begin{tabbing}
compute\_\hspace{0.1em}old(X,T,T):-var(X),!.\\[-0.7ex]
\\[-0.15ex]
compute\_\hspace{0.1em}old([[N]],T,TT):-integer(N),$\varphi$(N,T,TT).\\[-0.15ex]
compute\_\hspace{0.1em}old([[simplify]],T,TT):-eval(T,TT), $\backslash$+ T=TT,!.\\[-0.15ex]
compute\_\hspace{0.1em}old([[unfold]],T,TT) :-\\[-0.15ex]
\hspace{2em}$\varphi$(1,T,TT).\\[-0.15ex]
compute\_\hspace{0.1em}old([[expand]],T,TT) :-\\[-0.15ex]
\hspace{2em}$\varphi$(1,T,TT).\\[-0.15ex]
compute\_\hspace{0.1em}old([[fold(F)]],B,\{F\}) :-\\[-0.15ex]
	cdef(F)=:(\{F\}$<$==$>$B).\\[-0.15ex]
compute\_\hspace{0.1em}old([[fold(F)]],T,TT):-\\[-0.15ex]
\hspace{2em}cdef(F)=:(T1$<$==$>$T2),\\[-0.15ex]
\hspace{2em}T1=..[F$\mid$P],s(T2,X,P,T0),T0=T,s(T1,X,P,TT).\\[-0.7ex]
\\[-0.15ex]
compute\_\hspace{0.1em}old(T,X,XX):-\\[-0.15ex]
\hspace{2em}T=..[F$\mid$A],X=..[F$\mid$B],compute\_\hspace{0.1em}list\_\hspace{0.1em}old(A,B,BB),XX=..[F$\mid$BB].\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{compute\_list}
\begin{sf}\begin{tabbing}
compute\_\hspace{0.1em}list\_\hspace{0.1em}old([],[],[]).\\[-0.15ex]
compute\_\hspace{0.1em}list\_\hspace{0.1em}old([T$\mid$TT],[X$\mid$XX],[Y$\mid$YY]):-\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}old(T,X,Y),compute\_\hspace{0.1em}list\_\hspace{0.1em}old(TT,XX,YY).
\end{tabbing}\end{sf}

 \ulinv{compute\_using}
\begin{sf}\begin{tabbing}
compute\_\hspace{0.1em}using([[N,T]],TT):-\\[-0.15ex]
\hspace{2em}integer(N),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(T,CT),\\[-0.15ex]
\hspace{2em}$\varphi$(N,CT,TT).\\[-0.7ex]
\\[-0.15ex]
compute\_\hspace{0.1em}using([[unfold,T]],TT):-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(T,CT),\\[-0.15ex]
\hspace{2em}$\varphi$(1,CT,TT).\\[-0.15ex]
compute\_\hspace{0.1em}using([[fold(F),T]],TT):-\\[-0.15ex]
\hspace{2em}cdef(F)=:(T1$<$==$>$T2),T1=..[F$\mid$P],s(T2,X,P,T0),T0=T,s(T1,X,P,TT).\\[-0.15ex]
compute\_\hspace{0.1em}using([[unroll,T]],TT):-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(T,CT),\\[-0.15ex]
\hspace{2em}$\varphi$(1,CT,TT).\\[-0.7ex]
\\[-0.15ex]
compute\_\hspace{0.1em}using([[expand,T]],TT):-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}$\varphi$(1,T,TT).\\[-0.7ex]
\\[-0.15ex]
compute\_\hspace{0.1em}using([H$\mid$T], TT) :-\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}append( Vars, [Body], [H$\mid$T] ),\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using( Body, CBody ),\\[-0.15ex]
\hspace{2em}append( Vars, [CBody], TT ).\\[-0.15ex]
compute\_\hspace{0.1em}using([],\_\hspace{0.1em}):-!,fail.\\[-0.7ex]
\\[-0.15ex]
compute\_\hspace{0.1em}using(T,XX):-\\[-0.15ex]
\hspace{2em}imm\_\hspace{0.1em}subterms(T,A,F),\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}list(A,BB),\\[-0.15ex]
\hspace{2em}$\backslash$+ A = BB,\\[-0.15ex]
\hspace{2em}imm\_\hspace{0.1em}subterms(XX,BB,F),\\[-0.15ex]
\hspace{2em}!.\\[-0.15ex]
compute\_\hspace{0.1em}using(T,T).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{compute\_list} \ulinv{compute\_list\_save}
\begin{sf}\begin{tabbing}
compute\_\hspace{0.1em}list\_\hspace{0.1em}save( L,R ) :-\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}list( L,R),\\[-0.15ex]
\hspace{2em}$\backslash$+ L = R,\\[-0.15ex]
\hspace{2em}!.\\[-0.15ex]
compute\_\hspace{0.1em}list\_\hspace{0.1em}save( L,L ).\\[-0.7ex]
\\[-0.15ex]
compute\_\hspace{0.1em}list([],[]).\\[-0.15ex]
compute\_\hspace{0.1em}list([T$\mid$TT],[Y$\mid$YY]):-\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(T,Y),\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}list(TT,YY).\\[-0.7ex]
\\[-0.15ex]
normalise( Ilgl, T, NT ) :-\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag(Ilgl,T,TT),\\[-0.15ex]
\hspace{2em}$\backslash$+ T=TT,\\[-0.15ex]
\hspace{2em}compute\_\hspace{0.1em}using(TT,CT),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}normalise(Ilgl,CT,NT).\\[-0.15ex]
normalise(\_\hspace{0.1em},T,T).\\[-0.7ex]
\\[-0.7ex]
\\[-0.7ex]

\end{tabbing}\end{sf}

 
 \section{Generate / Check tagging for compute with using() clause}
 \ulinv{correct\_tag} \ulinv{compute}
 $correct\_tag(Ignore,Term, TaggedTerm)$ holds if TaggedTerm is a correct
 tagging of Term.  That is, if TaggedTerm is Term tagged in places
 where computation rules apply.   Where TaggedTerm is not bound, it becomes
 bound to Term with all legal tags that do not matching those in Ignore.
 
\begin{sf}\begin{tabbing}
correct\_\hspace{0.1em}tag( \_\hspace{0.1em}, Tm, \_\hspace{0.1em} ) :-\\[-0.15ex]
\hspace{2em}var(Tm),\\[-0.15ex]
\hspace{2em}!.\\[-0.15ex]
correct\_\hspace{0.1em}tag( Ilgl, Tm, TagTm ) :-\\[-0.15ex]
\hspace{2em}verify\_\hspace{0.1em}tagging( Ilgl, TagTm, Tm, Tagged ),\\[-0.15ex]
\hspace{2em}imm\_\hspace{0.1em}subterms( Tm, SubTms, TmId ),\\[-0.15ex]
\hspace{2em}imm\_\hspace{0.1em}subterms( Tagged, TagSubTms, TmId ),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag\_\hspace{0.1em}list( Ilgl, SubTms, TagSubTms ).\\[-0.7ex]
\\[-0.15ex]
correct\_\hspace{0.1em}tag\_\hspace{0.1em}list( Ilgl, [SubTm$\mid$RestSubTms], [TagSubTm$\mid$RestTagSubTms] ) :-\\[-0.15ex]
\hspace{2em}SubTm = [\_\hspace{0.1em}$\mid$\_\hspace{0.1em}],\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}append( Vars, [BoundSubTm], SubTm ),\\[-0.15ex]
\hspace{2em}append( Vars, [BoundTagSubTm], TagSubTm ),\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag( Ilgl, BoundSubTm, BoundTagSubTm ),\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag\_\hspace{0.1em}list( Ilgl, RestSubTms, RestTagSubTms ).\\[-0.15ex]
correct\_\hspace{0.1em}tag\_\hspace{0.1em}list( Ilgl, [SubTm$\mid$RestSubTms], [TagSubTm$\mid$RestTagSubTms] ) :-\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag( Ilgl, SubTm, TagSubTm ),\\[-0.15ex]
\hspace{2em}correct\_\hspace{0.1em}tag\_\hspace{0.1em}list( Ilgl, RestSubTms, RestTagSubTms ).\\[-0.15ex]
correct\_\hspace{0.1em}tag\_\hspace{0.1em}list( \_\hspace{0.1em}, [],[] ).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{verify\_tagging},\ulinv{verify\_unfold}
 Check\slash generate a legal tag for computing
 a non-canonical term.
\begin{sf}\begin{tabbing}
verify\_\hspace{0.1em}tagging( Ilgl, TagTm, Tm, Tagged ) :-\\[-0.15ex]
\hspace{2em}nonvar( TagTm ),\\[-0.15ex]
\hspace{2em}( ( TagTm = [[Tag,Tagged]],\\[-0.15ex]
\hspace{4em}!,\\[-0.15ex]
\hspace{4em}tag\_\hspace{0.1em}for( Ilgl, Tm, Tag )\\[-0.15ex]
\hspace{3em});\\[-0.15ex]
\hspace{3em}TagTm = Tagged\\[-0.15ex]
\hspace{2em}),\\[-0.15ex]
\hspace{2em}!.\\[-0.7ex]
\\[-0.15ex]
verify\_\hspace{0.1em}tagging( Ilgl, TagTm, Tm, Tagged ) :-\\[-0.15ex]
\hspace{2em}tag\_\hspace{0.1em}for( Ilgl, Tm, Tag ),\\[-0.15ex]
\hspace{2em}TagTm = [[Tag,Tagged]].\\[-0.7ex]
\\[-0.15ex]
verify\_\hspace{0.1em}tagging( \_\hspace{0.1em}, Tagged, \_\hspace{0.1em}, Tagged ).\\[-0.7ex]
\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{tag\_for}
 Non-canonical and defined terms and their appropriate tags
\begin{sf}\begin{tabbing}
tag\_\hspace{0.1em}for( Ilgl, Tm, Tag ) :-\\[-0.15ex]
\hspace{2em}tag\_\hspace{0.1em}for( Tm, GTag ),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}$\backslash$+ member( [GTag,Tm], Ilgl ),\\[-0.15ex]
\hspace{2em}( (Tag = GTag);\\[-0.15ex]
\hspace{3em}(integer(Tag),integer(GTag))\\[-0.15ex]
\hspace{2em}).\\[-0.7ex]
\\[-0.15ex]
tag\_\hspace{0.1em}for( (lambda(\_\hspace{0.1em},\_\hspace{0.1em}) of \_\hspace{0.1em} ), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( decide(inl(\_\hspace{0.1em}),\_\hspace{0.1em},\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( decide(inr(\_\hspace{0.1em}),\_\hspace{0.1em},\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( spread(\_\hspace{0.1em}\&\_\hspace{0.1em},\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( p\_\hspace{0.1em}ind(0,\_\hspace{0.1em},\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( p\_\hspace{0.1em}ind(s(\_\hspace{0.1em}),\_\hspace{0.1em},\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( rec\_\hspace{0.1em}ind(A,\_\hspace{0.1em}), 1 ) :-\\[-0.15ex]
\hspace{2em}$\backslash$+ atom(A),\\[-0.15ex]
\hspace{2em}functor(A,F,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}member(F,[inl,inr,s,0,`\&`]),\\[-0.15ex]
\hspace{2em}!.\\[-0.15ex]
tag\_\hspace{0.1em}for( cv\_\hspace{0.1em}ind(A,\_\hspace{0.1em}), 1 ) :-\\[-0.15ex]
\hspace{2em}pnat(A),!.\\[-0.15ex]
tag\_\hspace{0.1em}for( wo\_\hspace{0.1em}ind(A,\_\hspace{0.1em}), 1 ) :-\\[-0.15ex]
\hspace{2em}$\backslash$+ atom(A),\\[-0.15ex]
\hspace{2em}functor(A,F,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}member(F,[inl,inr,s,0,`\&`]),\\[-0.15ex]
\hspace{2em}!.\\[-0.15ex]
tag\_\hspace{0.1em}for( cv\_\hspace{0.1em}ind(\_\hspace{0.1em},\_\hspace{0.1em}), unroll ).\\[-0.15ex]
tag\_\hspace{0.1em}for( wo\_\hspace{0.1em}ind(\_\hspace{0.1em},\_\hspace{0.1em}), unroll ).\\[-0.15ex]
tag\_\hspace{0.1em}for( rec\_\hspace{0.1em}ind(\_\hspace{0.1em},\_\hspace{0.1em}), unroll ).\\[-0.15ex]
tag\_\hspace{0.1em}for( rec(\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( atom\_\hspace{0.1em}eq(atom(\_\hspace{0.1em}),atom(\_\hspace{0.1em}),\_\hspace{0.1em},\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (\_\hspace{0.1em}+0), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (0+\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (0*\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (\_\hspace{0.1em}*0), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (1*\_\hspace{0.1em}), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (\_\hspace{0.1em}*1), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (\_\hspace{0.1em}-0), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( (\_\hspace{0.1em}/1), 1 ).\\[-0.15ex]
tag\_\hspace{0.1em}for( ind(A,\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em}), 1 ) :- integer(A).\\[-0.15ex]
tag\_\hspace{0.1em}for( (A + B), 1 ) :- integer(A),integer(B).\\[-0.15ex]
tag\_\hspace{0.1em}for( (A / B), 1 ) :- integer(A),integer(B).\\[-0.15ex]
tag\_\hspace{0.1em}for( (A * B), 1 ) :- integer(A),integer(B).\\[-0.15ex]
tag\_\hspace{0.1em}for( (A - B), 1 ) :- integer(A),integer(B).\\[-0.15ex]
tag\_\hspace{0.1em}for( (A mod B), 1 ) :- integer(A),integer(B).\\[-0.15ex]
tag\_\hspace{0.1em}for( less(A,B,\_\hspace{0.1em},\_\hspace{0.1em}), 1 ) :- integer(A),integer(B).\\[-0.15ex]
tag\_\hspace{0.1em}for( int\_\hspace{0.1em}eq(A,B,\_\hspace{0.1em},\_\hspace{0.1em}), 1 ) :- integer(A),integer(B).\\[-0.15ex]
tag\_\hspace{0.1em}for( pless(A,B,\_\hspace{0.1em},\_\hspace{0.1em}), 1 ) :- pdecide(A,B,\_\hspace{0.1em}).\\[-0.15ex]
tag\_\hspace{0.1em}for( pnat\_\hspace{0.1em}eq(A,B,\_\hspace{0.1em},\_\hspace{0.1em}), 1 ) :- pdecide(A,B,\_\hspace{0.1em}).\\[-0.7ex]
\\[-0.15ex]
tag\_\hspace{0.1em}for( term\_\hspace{0.1em}of(\_\hspace{0.1em}), expand ).\\[-0.15ex]
tag\_\hspace{0.1em}for( \{N\}, unfold ) :-\\[-0.15ex]
\hspace{2em}atom(N),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}(cdef(N) =: \_\hspace{0.1em}).\\[-0.15ex]
tag\_\hspace{0.1em}for( Tm, unfold ) :-\\[-0.15ex]
\hspace{2em}functor(Tm,N,\_\hspace{0.1em}),\\[-0.15ex]
\hspace{2em}cdef(N) =: \_\hspace{0.1em}.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{imm\_subterms}
 Break up\slash rebuild a term into\slash from its subterms and 
 a token identifying its kind.
\begin{sf}\begin{tabbing}
imm\_\hspace{0.1em}subterms( atom(A), [], atom(A) ) :-\\[-0.15ex]
\hspace{2em}!.\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( term\_\hspace{0.1em}of(Name), [], term\_\hspace{0.1em}of(Name) ) :-\\[-0.15ex]
\hspace{2em}!.\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( \{Name\}, [], \{Name\} ) :-\\[-0.15ex]
\hspace{2em}atom(Name),\\[-0.15ex]
\hspace{2em}!.\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( (V:T1\#T2), [T1,[V,T2]], 'b\#' ) :-	\% *** Deal with binding types\\[-0.15ex]
\hspace{2em}!.\\[-0.15ex]
imm\_\hspace{0.1em}subterms( (V:T1=$>$T2), [T1,[V,T2]], 'b=$>$' ) :- !.\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( (\{V:T1$\mid$T2\}), [T1,[V,T2]], 'b\{\}' ) :- !.\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( lambda(V,T),  [[V,T]], 'lambda' ) :- !. 	\% *** lambda term\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( rec(V,T),  [[V,T]], 'rec' ) :- !. 	\% *** lambda term\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( \{A$\mid$B\}, [A,B], 'n\{\}' ).\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( A in B, [A,B], 'in1' ).\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( A=B in C, [A,B,C], 'in2' ).\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms(Dterm, [], Dterm) :-\\[-0.15ex]
\hspace{2em}$\tau_{var}$(Dterm),\\[-0.15ex]
\hspace{2em}!.\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( Tm, Args, (Funct/Arity) ) :-\\[-0.15ex]
\hspace{2em}nonvar(Tm),\\[-0.15ex]
\hspace{2em}Tm =.. [Funct$\mid$Args],\\[-0.15ex]
\hspace{2em}length(Args,Arity).\\[-0.7ex]
\\[-0.15ex]
imm\_\hspace{0.1em}subterms( Tm, Args, (Funct/Arity) ) :-\\[-0.15ex]
\hspace{2em}var(Tm),\\[-0.15ex]
\hspace{2em}length(Args,Arity),\\[-0.15ex]
\hspace{2em}Tm =.. [Funct$\mid$Args].\\[-0.7ex]

\end{tabbing}\end{sf}

  
 \section{Manipulations of the hypothesis list}
 \ulinv{thin\_hyps} \ulinv{extend\_thin} \ulinv{replace\_hyps}  
 $thin\_hyps(ToThin, Hyps, ThinnedHyps)$ gives $Hyps$ after removing the
 hypothesis named in $ToThin$ as $ThinnedHyps$.
 
 $extend\_thin( ToThin, Hyps, ExtToThin$ gives in $ExtToThin$ all the
 hypotheses (by number) that need to be thinned from $Hyps$ as a 
 result of thinning those named in $ToThin$.
 
 $replace\_hyps( ToRepl, Hyps, ReplHyps )$ Gives in $ReplHyps$ the result
 of replacing in $Hyps$ those hypotheses with a hypothesis of the same
 name in $ToRepl$.
 
\begin{sf}\begin{tabbing}
thin\_\hspace{0.1em}hyps( ToThin, [(Name:\_\hspace{0.1em})$\mid$RestHyps], Thinned ) :-\\[-0.15ex]
\hspace{2em}member(Name,ToThin),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}thin\_\hspace{0.1em}hyps( ToThin, RestHyps, Thinned ).\\[-0.15ex]
thin\_\hspace{0.1em}hyps( ToThin, [Hyp$\mid$RestHyps], [Hyp$\mid$Thinned] ) :-\\[-0.15ex]
\hspace{2em}thin\_\hspace{0.1em}hyps( ToThin, RestHyps, Thinned ).\\[-0.15ex]
thin\_\hspace{0.1em}hyps( \_\hspace{0.1em}, [], [] ).\\[-0.7ex]
\\[-0.15ex]
extend\_\hspace{0.1em}thin( ToThin, [(Name:Body)$\mid$RestHyps], NotThin, ExtToThin ) :-\\[-0.15ex]
\hspace{2em}member(Name,NotThin),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}freevarsinterm( Body, Frees ),\\[-0.15ex]
\hspace{2em}union(NotThin,Frees,NextNotThin),\\[-0.15ex]
\hspace{2em}extend\_\hspace{0.1em}thin( ToThin, RestHyps, NextNotThin, ExtToThin ).\\[-0.15ex]
extend\_\hspace{0.1em}thin( ToThin, [(Name:Body)$\mid$RestHyps], NotThin, ExtToThin ) :-\\[-0.15ex]
\hspace{2em}freevarsinterm( Body, Frees ),\\[-0.15ex]
\hspace{2em}member( F, Frees ),\\[-0.15ex]
\hspace{2em}member( F, ToThin ),\\[-0.15ex]
\hspace{2em}union([Name],ToThin,NextToThin ),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}extend\_\hspace{0.1em}thin( NextToThin, RestHyps, NotThin, ExtToThin ).\\[-0.7ex]
\\[-0.15ex]
extend\_\hspace{0.1em}thin( ToThin, [\_\hspace{0.1em}$\mid$RestHyps], NotThin, ExtToThin ) :-\\[-0.15ex]
\hspace{2em}extend\_\hspace{0.1em}thin( ToThin, RestHyps, NotThin, ExtToThin ).\\[-0.15ex]
extend\_\hspace{0.1em}thin(  ToThin, [], NotThin, ExtToThin ) :-\\[-0.15ex]
\hspace{2em}subtract( ToThin, NotThin, ExtToThin ).\\[-0.7ex]
\\[-0.15ex]
replace\_\hspace{0.1em}hyps( ToReplace, [(Name:\_\hspace{0.1em})$\mid$RestHyps], [(Name:RBody)$\mid$RestRHyps] ) :-\\[-0.15ex]
\hspace{2em}member( (Name:RBody), ToReplace ),\\[-0.15ex]
\hspace{2em}!,\\[-0.15ex]
\hspace{2em}replace\_\hspace{0.1em}hyps( ToReplace, RestHyps, RestRHyps ).\\[-0.15ex]
replace\_\hspace{0.1em}hyps( ToReplace, [Hyp$\mid$RestHyps], [Hyp$\mid$RestRHyps] ) :-\\[-0.15ex]
\hspace{2em}replace\_\hspace{0.1em}hyps( ToReplace, RestHyps, RestRHyps ).\\[-0.15ex]
replace\_\hspace{0.1em}hyps( \_\hspace{0.1em},[], [] ).
\end{tabbing}\end{sf}

  
  
 \section{Utilities}
 \begin{itemize}
  
 \item
 List difference: $diff(X,Y,Z)$ computes the list $Z$ of all
 elements of $X$, which are not in $Y$.
 \ulinv{diff}
\begin{sf}\begin{tabbing}
diff([],\_\hspace{0.1em},[]).\\[-0.15ex]
diff([X$\mid$T],Y,TT):-member(X,Y),!,diff(T,Y,TT).\\[-0.15ex]
diff([X$\mid$T],Y,[X$\mid$TT]):-diff(T,Y,TT). \\[-0.7ex]

\end{tabbing}\end{sf}

 Sound unification
   unify(X, Y)
   is true when the two terms X and Y unify *with* the occurs check.
\begin{sf}\begin{tabbing}
unify(X,Y) :-\\[-0.15ex]
\hspace{2em}ground(X),!,\\[-0.15ex]
\hspace{2em}X = Y.\\[-0.15ex]
unify(X,Y) :-\\[-0.15ex]
\hspace{2em}ground(Y),!,\\[-0.15ex]
\hspace{2em}X = Y.\\[-0.15ex]
unify(X, Y) :-\\[-0.15ex]
\hspace{2em}(	nonvar(X), nonvar(Y) -$>$\\[-0.15ex]
	functor(X, F, N),\\[-0.15ex]
	functor(Y, F, N),\\[-0.15ex]
	unify(N, X, Y)\\[-0.15ex]
\hspace{2em};   nonvar(X) /* var(Y) */ -$>$\\[-0.15ex]
	free\_\hspace{0.1em}of\_\hspace{0.1em}var(Y, X),		\% Y does not occur in X\\[-0.15ex]
	Y = X\\[-0.15ex]
\hspace{2em};   nonvar(Y) /* var(X) */ -$>$\\[-0.15ex]
	free\_\hspace{0.1em}of\_\hspace{0.1em}var(X, Y),		\% X does not occur in Y\\[-0.15ex]
	X = Y\\[-0.15ex]
\hspace{2em};	/* var(X), var(Y) */\\[-0.15ex]
	X = Y				\% unify(X, X) despite X\\[-0.15ex]
\hspace{2em}).					\% occurring in X!\\[-0.7ex]
\\[-0.15ex]
unify(N, X, Y) :-\\[-0.15ex]
\hspace{2em}(	N $<$ 1 -$>$ true\\[-0.15ex]
\hspace{2em};	arg(N, X, Xn),\\[-0.15ex]
	arg(N, Y, Yn),\\[-0.15ex]
	unify(Xn, Yn),\\[-0.15ex]
	M is N-1,\\[-0.15ex]
	unify(M, X, Y)\\[-0.15ex]
\hspace{2em}).
\end{tabbing}\end{sf}

  
 \item
 generating new variables from the sequence $v0, v1, v2,...$.
 \ulinv{genvar}
\begin{sf}\begin{tabbing}
genvar(X):-var(X),!,genint(Y),decimal(Y,Z),atom\_\hspace{0.1em}codes(X,[118$\mid$Z]).\\[-0.15ex]
genvar(X):-$\tau_{var}$(X). 
\end{tabbing}\end{sf}

 \ulinv{genint}
\begin{sf}\begin{tabbing}
genint(0).\\[-0.15ex]
genint(X):-genint(Y),X is Y+1.\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{decimal}
\begin{sf}\begin{tabbing}
decimal(Y,[Z]):-Y$<$10,digit(Y,Z),!.\\[-0.15ex]
decimal(Y,Z):-Y1 is (Y//10), Y2 is (Y mod 10),\\[-0.15ex]
\hspace{2em}decimal(Y1,Z1),decimal(Y2,Z2),append(Z1,Z2,Z).
\end{tabbing}\end{sf}

  
 \item
 generate or check universe level
 \ulinv{level}
\begin{sf}\begin{tabbing}
level(I):-var(I),$\vartheta_{\it universe}$=:I,!.\\[-0.15ex]
level(I):-integer(I),0$<$I.
\end{tabbing}\end{sf}

  
 \item
 generate or check  free variables from hypothesis list
 \ulinv{free}
\begin{sf}\begin{tabbing}
free([],\_\hspace{0.1em}).\\[-0.15ex]
free([X$\mid$L],H):-var(X),!,genvar(X),freevar(X,H),free(L,[X:\_\hspace{0.1em}$\mid$H]),!.\\[-0.15ex]
free([X$\mid$L],H):-$\tau_{var}$(X),freevar(X,H),free(L,[X:\_\hspace{0.1em}$\mid$H]).\\[-0.7ex]
\\[-0.15ex]
free(X,H,HH):-free(X,H),extend(X,H,HH).
\end{tabbing}\end{sf}

 \ulinv{extend}
\begin{sf}\begin{tabbing}
extend([],H,H).\\[-0.15ex]
extend([X$\mid$T],H,[X:\_\hspace{0.1em}$\mid$HH]):-extend(T,H,HH).\\[-0.7ex]

\end{tabbing}\end{sf}

 \ulinv{freevar}
\begin{sf}\begin{tabbing}
freevar(X,H):-decl(X:\_\hspace{0.1em},H),!,fail.\\[-0.15ex]
freevar(X,H):-member(D$<$==$>$\_\hspace{0.1em},H),functor(D,X,\_\hspace{0.1em}),!,fail.\\[-0.15ex]
freevar(\_\hspace{0.1em},\_\hspace{0.1em}).
\end{tabbing}\end{sf}

  
 \item
 Checking whether an identifier is free in a problem,
 i.e. it is not declared neither in the current hypothesis list,
 nor in the nypothesis lists of any subproblem.
 \ulinv{notused}
\begin{sf}\begin{tabbing}
notused(\_\hspace{0.1em},S):-var(S),!.\\[-0.15ex]
notused(X,$\pi$(H==$>$\_\hspace{0.1em},\_\hspace{0.1em},\_\hspace{0.1em},S)):-free([X],H),notused(X,S).\\[-0.15ex]
notused(\_\hspace{0.1em},[]).\\[-0.15ex]
notused(X,[P \mbox{\it ext} \_\hspace{0.1em}$\mid$S]):-notused(X,P),notused(X,S).\\[-0.15ex]
notused(X,[P$\mid$S]):-notused(X,P),notused(X,S).
\end{tabbing}\end{sf}

  
 \item
 Declaration in hypothesis list
 \ulinv{decl}
\begin{sf}\begin{tabbing}
decl(X:D,H):-member(X:D,H).
\end{tabbing}\end{sf}

  
 \item
 copying Prolog terms for generating fresh variables.
 \ulinv{copy}
\begin{sf}\begin{tabbing}
copy(T,TT):-recorda(copyterm,T,R),recorded(copyterm,TT,R),erase(R).
\end{tabbing}\end{sf}

 \item
 Reading a term of given structure from an external file 
 \ulinv{readfile}
\begin{sf}\begin{tabbing}
readfile(F,X):- see(F),read(Y),X=Y,!,seen.\\[-0.15ex]
readfile(\_\hspace{0.1em},\_\hspace{0.1em}):- seen,nl,write('wrong structured file.'),nl,!,fail.
\end{tabbing}\end{sf}

 \item
 Tabbing; tab/1 is non-ISO; simulate it here
 \ulinv{tab}
\begin{sf}\begin{tabbing}
tab(N) :- on\_\hspace{0.1em}exception( E   , \_\hspace{0.1em} is N,\\[-0.15ex]
		    (   print( "bad argument to tab/1" ),\\[-0.15ex]
			throw(E) )\\[-0.15ex]
		      ),\\[-0.15ex]
\hspace{4em}( N $>$= 0 -$>$\\[-0.15ex]
	      ttab(N)\\[-0.15ex]
\hspace{5em}; (print( 'negative argument to tab/1'),\\[-0.15ex]
	     throw(neg\_\hspace{0.1em}arg)\\[-0.15ex]
\hspace{6em})\\[-0.15ex]
\hspace{4em}).\\[-0.15ex]
	  \\[-0.7ex]
\\[-0.15ex]
ttab(0).\\[-0.15ex]
ttab(N) :- N $>$ 0, put\_\hspace{0.1em}char( ' ' ), M is N-1, ttab(M).\\[-0.7ex]

\end{tabbing}\end{sf}

  
 \item
 Code dependent predicates
 \ulinv{small\_letter}
\begin{sf}\begin{tabbing}
small\_\hspace{0.1em}letter(X):-97=$<$X,X=$<$122.
\end{tabbing}\end{sf}

 \ulinv{capital\_letter}
\begin{sf}\begin{tabbing}
capital\_\hspace{0.1em}letter(X):-65=$<$X,X=$<$90.
\end{tabbing}\end{sf}

 \ulinv{digit}
\begin{sf}\begin{tabbing}
digit(X):-48=$<$X,X=$<$57.\\[-0.15ex]
digit(X,Y):-0=$<$X,X=$<$9,Y is X+48.
\end{tabbing}\end{sf}

 \ulinv{underscore}
\begin{sf}\begin{tabbing}
underscore(95).
\end{tabbing}\end{sf}

 \ulinv{apostroph}
\begin{sf}\begin{tabbing}
apostroph(39). 
\end{tabbing}\end{sf}

  
 \item
 Toggle a global variable on execution and backtracking: the global variable
 $Var$ is being set to $Val1$ on execution, and to $Val2$ on
 backtracking. Notice that $toggle/2$ does not give an extra
 backtrackpoint, since the second clause is forced to fail.
 \ulinv{toggle}
\begin{sf}\begin{tabbing}
toggle(Var, [Val1,\_\hspace{0.1em}]) :- Var:=Val1.\\[-0.15ex]
toggle(Var, [\_\hspace{0.1em},Val2]) :- Var:=Val2, fail.
\end{tabbing}\end{sf}

 \normalsize
 \end{itemize}
  
 \chapter*{References}
 
 \begin{description}
 
 \item[{[1]}]
 \begin{tabbing}
 Brouwer,L.E.J.:\\
 On the significance of the principle of excluded middle in
 mathematics, \\
 especially in function theory.\\
 \emph{J.f\"{u}r Reine und Angewandte Mathematik} {\bf 154} (1923),1-7
 \end{tabbing}
 
 \item[{[2]}]
 \begin{tabbing}
 Constable,R.L. et al:\\
  \emph{Implementing Mathematics with the
 Nuprl Proof Development System},\\
 Prentice Hall, Englewood Cliffs, 1986
 \end{tabbing}
 
 \item[{[3]}]
 \begin{tabbing}
 Heyting,A.: \\ 
 \emph{Intuitionism: An Introduction}, \\
 North-Holland, Amsterdam, 1956
 \end{tabbing}
 
 \item[{[4]}]
 \begin{tabbing}
 Kolmogorov,A.N.: \\
 Zur Deutung der intuitionistischen Logik.\\
 \emph{Mathematische Zeitschrift}, {\bf 35} (1932), 58-65
 \end{tabbing}
 
 \item[{[5]}]
 \begin{tabbing}
 Kowalski,R.: \\
 \emph{Logic for Problem Solving},\\
 North-Holland, New York, 1979
 \end{tabbing}
 
 \item[{[6]}]
 \begin{tabbing}
 Martin-L\"{o}f,P.: \\
 Constructive mathematics and computer programming,\\
 in: \emph{6th Int.Congress for Logic, Methodlogy of Science, and
 Philosophy}, \\
 North-Holland, Amsterdam, 1982, pp.153-175
 \end{tabbing}
 
 \item[{[7]}]
 \begin{tabbing}
 Martin-L\"{o}f,P.: \\
 \emph{Intuitionistic Type Theory},\\
 Bibliopolis, Napoli, 1984
 \end{tabbing}
 
 \item[{[8]}]
 \begin{tabbing}
 Russell,B.:\\
  Mathematical logic based on a theory of types.\\
 \emph{Am.J.of Math.} {\bf 30} (1908), pp. 222-262
 \end{tabbing}
 
 \end{description}
 
 \appendix
 
 \chapter{Examples}
 
 The aim of this appendix is to give a collection of examples
 which demonstrate different ways of using the Oyster system.
 These examples are not primarily intended as a tutorial, 
 but more as illustration of some aspects of the system.
 
 \section{Factorial }
 
 In this section we give two examples for deriving 
 the \emph{faktorial} function \verb'n!'. The first approach
 starts with a complete specification and in fact consists
 only of one main step supplying the full implementation.
 The second example shows how you can synthesise the
 factorial function from an underspecification (as a mapping 
 of the type \verb'int=>int').
 
 \subsection{Verification}
 
 \small\begin{verbatim}
 | ?- create_thm(fak,user).
 |: []==>fak:(int=>int)#
          fak of 0=1 in int#
          n:int=>0<n=>
             fak of n=n*fak of (n-1) in int.
 
 yes
 | ?- \end{verbatim}\normalsize
 In the beginning we have to select the theorem:
 \small\begin{verbatim}
 | ?- select(fak),display.
 fak : [] incomplete 
 ==> fak:(int=>int)#
     (fak of 0=1 in int)#
     n:int=>0<n=>fak of n=n*fak of (n-1)in int
 by _
 
 yes
 | ?- \end{verbatim}\normalsize
 The implementation step should be combined with a simplification.
 This makes the resulting subgoals more comprehensive:
 \small\begin{verbatim}
 | ?- intro(lambda(i,ind(i,[~,~,0],1,[i,f,i*f])))  
        then try simplify.
 
 yes
 | ?- display.
 fak : [] partial 
 ==> fak:(int=>int)#
     (fak of 0=1 in int)#
     n:int=>0<n=>fak of n=n*fak of (n-1)in int
 by intro(lambda(i,ind(i,[~,~,0],1,[i,f,i*f])))then try simplify
 
   [1] incomplete
   1. n:int
   2. v0:0<n
   ==> (ind(n,[~,~,0],1,[i,f,i*f])
      = (n*ind(n-1,[~,~,0],1,[i,f,i*f]))
      in int)
 
 yes
 | ?- \end{verbatim}\normalsize
 The pending subgoal can be resolved easily, if we use the
 appropriate \emph{reduction} rule for integer induction terms.
 \small\begin{verbatim}
 | ?- down(1),reduce(left,up),status.
 complete
 yes
 | ?- \end{verbatim}\normalsize
 At the end we have a look at the complete proof and its
 extract term:
 \small\begin{verbatim}
 |?- top,snapshot.
 fak : [] complete 
 ==> fak:(int=>int)#
     (fak of 0=1 in int)#
     n:int=>0<n=>fak of n=n*fak of (n-1)in int
 by intro(lambda(i,ind(i,[~,~,0],1,[i,f,i*f])))then try simplify
 
   [1] complete
   1. n:int
   2. v0:0<n
   ==> (ind(n,[~,~,0],1,[i,f,i*f])
      = (n*ind(n-1,[~,~,0],1,[i,f,i*f]))
      in int)
   by reduce(left,up)
 
 yes
 | ?- extract.
 lambda(i,ind(i,[~,~,0],1,[i,f,i*f]))
   & axiom
     & lambda(~,lambda(~,axiom))
 
 yes
 | ?- \end{verbatim}\normalsize
 To allow the direct execution of the Oyster program on
 the Prolog level we should generate a Prolog predicate,
 which evaluates the the function term:
 \small\begin{verbatim}
 | ?-extract(X& _),assert((fak(A,B):-eval(X of A,B))).
 
 yes
 | ?- \end{verbatim}\normalsize
 Running this Prolog predicate yields for example:
 \small\begin{verbatim}
 | ?- genint(I),fak(I,J),write(fak(I)=J),nl,I>9.
 fak(0)=1
 fak(1)=1
 fak(2)=2
 fak(3)=6
 fak(4)=24
 fak(5)=120
 fak(6)=720
 fak(7)=5040
 fak(8)=40320
 fak(9)=362880
 fak(10)=3628800
 
 yes
 | ?- \end{verbatim}\normalsize
 
 \subsection{Synthesis}
 
 \small\begin{verbatim}
 | ?- create_thm(fak,user).
 |: []==>int=>int.
 
 yes
 | ?- select(fak).
 
 yes
 | ?- \end{verbatim}\normalsize
 Program synthesis should be generally executed in the
 \emph{pure} mode. The troubles comes from the filter rule
 sitting in the beginning of the rule base, which simply checks,
 whether the current goal is already part of the hypothesis
 list. This rule guarantees in normal use the automatic recognition
 of induction hypotheses and makes the standard autotactic
 \emph{repeat intro} really smart, but for synthesis purposes
 you have to switch it off, because it would generate the most
 trivial program structure. If you want to synthesise an integer
 term, this rule would pick up the first variable declared to be
 of the type \emph{int} and yield this variable as implementation.
 In this example \emph{intro} would ``prove'' the goal completely 
 automatically, yielding the extract term \verb'lambda(v0,v0)'.
 \small\begin{verbatim}
 | ?- pure(intro).
 
 yes
 | ?- display.
 fak : [] partial 
 ==> int=>int
 by pure(intro)
 
   [1] incomplete
   1. v0:int
   ==> int
 
   [2] incomplete
   ==> int in u(1)
 
 
 yes
 | ?- pure(intro),extract.
 lambda(v0,_)
 
 yes
 | ?- \end{verbatim}\normalsize
 For pragmatic reasons it is useful to ignore all wellformedness
 goals during the synthesis process and tidy the proof tree up
 at the end. The interesting subgoal is the first one. Now we
 have to prove the existence of an integer starting from an
 integer \emph{v0} already known. If you have no idea how to continue,
 simply call \emph{apply(X)}, it will generate all rules applicable.
 \small\begin{verbatim}
 | ?- down(1).
 
 yes
 | ?- apply(X),write(X),nl,fail.
 intro
 intro(<integer>)
 intro(- ~)
 intro(~ + ~)
 intro(~ - ~)
 intro(~ * ~)
 intro(~ / ~)
 intro(~mod~)
 elim(v0,new [v1,v2,v3])
 
 no
 | ?- \end{verbatim}\normalsize
 The corresponding extract terms would be: $v0$ - the hypothesis
 directly available, arbitrary integer numbers (as supplied),
 compound terms
 with the top level operators $-$ (unary) or $+$, $-$, $*$, $/$, and
 $mod$ (binary) , or an integer induction term. We decide for the
 last one:  
 \small\begin{verbatim}
 | ?- pure(elim(v0)).
 
 yes
 | ?- display.
 fak : [1] partial 
 1. v0:int
 ==> int
 by pure(elim(v0))
 
   [1] incomplete
   2. v1:int
   3. v2:v1<0
   4. v3:int
   ==> int
 
   [2] incomplete
   ==> int
 
   [3] incomplete
   2. v1:int
   3. v2:0<v1
   4. v3:int
   ==> int
 
 yes
 | ?- extract.
 ind(v0,[v1,v3,_],_,[v1,v3,_])
 
 yes
 | ?- \end{verbatim}\normalsize
 Now we have to supply refinement terms for each of the three
 cases. The first one is trivial - for negative arguments we 
 are free to choose any value, but we have to supply one value,
 say $0$. Of course we could leave this case open and let it be filled
 in automatically by our tidying strategy at the end.
 For the zero case we choose $1$. For the main case we have the
 rough idea of choosing a term of the form  $n*f(n-1)$. The values
 for $n$ and $f(n-1)$ are available as $v1$ and $v3$, so we
 give a direct implementation of the form $v1*v3$:
 \small\begin{verbatim}
 | ?- down(1),pure(intro(0)),up.
 
 yes
 | ?- down(2),pure(intro(1)),up.
 
 yes
 | ?- down(3),pure(intro(explicit(v1*v3))),up.
 
 yes
 | ?- \end{verbatim}\normalsize
 At the end we have to ``tidy up'' and to prove all open wellformedness
 goals. In this simple case it would be enough to run around the
 proof tree, and try to apply the standard autotactic:
 \small\begin{verbatim}
 | ?- top,next,intro,fail.
 
 no 
 | ?- status.
 complete 
 yes
 | ?- \end{verbatim}\normalsize
 Considering the extract term, we get essentially the same
 as for the fully specified function, except that there is
 no additional component describing the proof of the properties:
 \small\begin{verbatim}
 | ?- extract.
 lambda(v0,ind(v0,[~,~,0],1,[v1,v3,v1*v3]))
 
 yes
 | ?- \end{verbatim}\normalsize
 If you are constructing fairly large programs, the normal strategy 
 of solution would be a combination between both approaches.
 The \emph{algorithmic idea} is an essential guideline for
 constructing good programs. That's why one could prefer to
 built a program by stepwise refinement (from time to time
 looking at the extract term) and then taking the extract term
 from that synthesising proof as input for the critical proof
 step of the verifying proof.
 
 \printindex
 \end{document}
% end ProTex
